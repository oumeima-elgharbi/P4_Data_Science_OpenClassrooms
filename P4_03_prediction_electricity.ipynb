{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "OpenClassrooms\n",
    "Project 4, Data Scientist\n",
    "Author : Oumeima EL GHARBI\n",
    "Date : August 2022"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Un notebook pour chaque prédiction (émissions de CO2 et consommation totale d’énergie) des différents tests de modèles mis au propre, dans lequel vous identifierez clairement le modèle final choisi.\n",
    "\n",
    "\n",
    "L’objectif est de te passer des relevés de consommation annuels futurs (attention à la fuite de données). Nous ferons de toute façon pour tout nouveau bâtiment un premier relevé de référence la première année, donc rien ne t'interdit d’en déduire des variables structurelles aux bâtiments, par exemple la nature et proportions des sources d’énergie utilisées..\n",
    "\n",
    "Fais bien attention au traitement des différentes variables, à la fois pour trouver de nouvelles informations (peut-on déduire des choses intéressantes d’une simple adresse ?) et optimiser les performances en appliquant des transformations simples aux variables (normalisation, passage au log, etc.).\n",
    "\n",
    "Mets en place une évaluation rigoureuse des performances de la régression, et optimise les hyperparamètres et le choix d’algorithmes de ML à l’aide d’une validation croisée."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "Tester les modèles suivants : **regression linéaire (avec différentes régularisation : Ridge, Lasso, Elastic), Random Forest, XGboost**\n",
    "Penser à comparer les performances des différents modèles : utiliser la **MAE** ( Mean Absolute Error)\n",
    "Penser également à optimiser les hyper paramètres de chaque modèle via **GridSearch**\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Evaluate :\n",
    "\n",
    "https://cloud.google.com/automl-tables/docs/evaluate?hl=fr\n",
    "\n",
    "\n",
    "KFOLD\n",
    "\n",
    "Entrée : données X (dimension nxp), étiquettes y (dimension n), nombre de folds k\n",
    "\n",
    "Couper [0, 1, ..., n-1] en k parties de taille (n/k). (La dernière partie sera un peu plus petite si n n'est pas un multiple de k)\n",
    "\n",
    "for i=0 to (k-1):\n",
    "    Former le jeu de test (X_test, y_test) en restreignant X et y aux indices contenus dans la i-ième partie.\n",
    "    Former le jeu d'entraînement (X_train, y_train) en restreignant X et y aux autres indices.\n",
    "    Entraîner l'algorithme sur le jeu d'entraînement\n",
    "    Utiliser le modèle ainsi obtenu pour prédire sur le jeu de test\n",
    "        Calculer l'erreur du modèle en comparant les étiquettes prédites aux vraies étiquettes contenues dans y_test\n",
    "\n",
    "Sortie : la valeur moyenne des erreurs calculées sur les k folds."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 1 modele de Regression (RL classsque / Elastic / ridig / laso\n",
    "# Random Forest\n",
    "# XGBOOST\n",
    "\n",
    "# var à rpedire tottal GHE Emssion last one to predict\n",
    "# cette var deped de la consommation des bateimenst (1) prediction sur elec, steam, naturalgas et un autre energie (2) et reutiliser pour predire"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Introduction"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Importing libraries"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%reset -f\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "%autosave 300"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os, warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings(action=\"once\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Loading dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "columns_to_categorize = [\"BuildingType\", \"PrimaryPropertyType\", \"Neighborhood\", \"ZipCode\", \"CouncilDistrictCode\", \"LargestPropertyUseType\", \"SecondLargestPropertyUseType\", \"ThirdLargestPropertyUseType\"]\n",
    "#  \"Neighborhood\",\n",
    "category_types = {column: 'category' for column in columns_to_categorize}\n",
    "print(\"This dictionary will be used when reading the csv file to assign a type to categorical features :\", category_types)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset_path = \"dataset/cleaned/2016_Building_Energy_Prediction.csv\"\n",
    "# we assign the categorical features with a categotical type\n",
    "data = pd.read_csv(dataset_path, dtype=category_types, sep=\",\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data.dtypes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# predict : Electricity\n",
    "# train / test\n",
    "# standardisation = retirer la moyen et div par ecart type (scaling : les var qn sur emem echelle\n",
    "# var categ : encoding (one hot encoder)\n",
    "\n",
    "# la fin Feature engineriing\n",
    "\n",
    "# 2) entrainer le smodels\n",
    "# perf\n",
    "# temps de calcul\n",
    "# graph pour montrer la perf de chaque modele(barplot)\n",
    "# obj : finir exploration / finir feature engineering\n",
    "# obj un premier noteboook propre (try max)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data.columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#features_for_prediction = [\"YearBuilt\",  \"BuildingType\",\"PrimaryPropertyType\", \"Neighborhood\", \"NumberofFloors\", \"PropertyGFATotal\", \"PropertyGFAParking\", \"SecondLargestPropertyUseTypeGFA\", \"ThirdLargestPropertyUseTypeGFA\"]\n",
    "\n",
    "features_for_prediction = [\"YearBuilt\", \"NumberofBuildings\", \"NumberofFloors\", \"LargestPropertyUseTypeGFA\", \"SecondLargestPropertyUseTypeGFA\", \"ThirdLargestPropertyUseTypeGFA\",\n",
    "                           \"BuildingType\",\"PrimaryPropertyType\", \"Neighborhood\", \"LargestPropertyUseType\", \"SecondLargestPropertyUseType\", \"ThirdLargestPropertyUseType\"]\n",
    "\n",
    "variable_to_predict = \"Log2-Electricity(kBtu)\"\n",
    "\n",
    "features_for_prediction.append(variable_to_predict)\n",
    "print(features_for_prediction)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data = data[features_for_prediction]\n",
    "\n",
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## I) Feature Engineering : preparing the vectors and matrices\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1) Separating training data and target vector"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# we create the data matrix / we only take the features\n",
    "X = data[data.columns[:-1]]\n",
    "\n",
    "# we create the target vector\n",
    "y = data[variable_to_predict].values # numpy array not a DataFrame anymore\n",
    "\n",
    "print(\"Shape of X :\", X.shape)\n",
    "print(\"Shape of y :\", y.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2) Separation train and test dataset\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"We have to separate the train / test sets before normalising the dataset.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# We create a training set and a test set (the test set contains 30% of the dataset)\n",
    "from sklearn import model_selection\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.3,  random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_test.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3) Normalization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"We separate categorical variables from numerical variables.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X.select_dtypes(['category','object']) # we don't have 'object' here but it is just in case.\n",
    "\n",
    "categorical_columns = X.select_dtypes(['category','object']).columns\n",
    "numerical_columns = X.select_dtypes(include='number').columns.drop(\"YearBuilt\")\n",
    "print(\"We won't normalise the year so we drop it from numerical_columns.\")\n",
    "\n",
    "print(\"Shape of categorical variables : \", categorical_columns.shape)\n",
    "print(\"Shape of numerical variables :\", numerical_columns.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 1) Data Standardisation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We have to standardize the variables before learning a **Ridge Regression**.\n",
    "Standardizing means that each variable will have a **standard deviation** equal to 1."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Numerical variables standardization\")\n",
    "print(\"We have :\", numerical_columns.shape[0], \"numerical features to standardize.\",end=\"\\n\\n\")\n",
    "\n",
    "print(numerical_columns)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "print(\"Dates standardisation : not\")\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "def convert_to_timestamp(date):\n",
    "    \"\"\"\n",
    "    Convert date objects to integers\n",
    "    :param date:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    try:\n",
    "        timestamp = datetime.timestamp(date)\n",
    "        print(\"timestamp =\", timestamp, type(timestamp))\n",
    "        print(\"OK :\", date, type(date))\n",
    "\n",
    "        return timestamp\n",
    "    except Exception as e:\n",
    "        print(\"Error :\", date, type(date))\n",
    "        print(e)\n",
    "\n",
    "def normalize_min_max(data_frame, columns_to_scale):\n",
    "    \"\"\"\n",
    "    Normalizes the dataframe for the wanted column(s) using min/max\n",
    "    :param data_frame:\n",
    "    :param columns_to_scale: (list)\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    df = data_frame.copy() # we will return a copy of our dataframe\n",
    "    df[columns_to_scale] = min_max_scaler.fit_transform(df[columns_to_scale])\n",
    "    return df\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% raw\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# We train / fit the scaler on the training set / Computes the mean and std to be used for later scaling.\n",
    "std_scale = StandardScaler().fit(X_train[numerical_columns])\n",
    "# We transform the training set and the testing set / Performs standardization by centering and scaling.\n",
    "X_train_std = X_train.copy()\n",
    "X_test_std = X_test.copy()\n",
    "\n",
    "X_train_std[numerical_columns] = std_scale.transform(X_train[numerical_columns])\n",
    "X_test_std[numerical_columns] = std_scale.transform(X_test[numerical_columns])\n",
    "\n",
    "print(\"Before\")\n",
    "display(X_train)\n",
    "print(\"After\")\n",
    "display(X_train_std)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def densite(df, lines=7, cols=4):\n",
    "    \"\"\"\n",
    "    Input : dataframe, lignes, colonnes\n",
    "    Output : grille des courbes de densités des variables numériques du dataframe\n",
    "    \"\"\"\n",
    "    df = df.select_dtypes(include='number').copy()\n",
    "\n",
    "    fig, ax = plt.subplots(lines, cols, figsize=(min(15, cols * 3), lines * 2))\n",
    "\n",
    "    for i, val in enumerate(df.columns.tolist()):\n",
    "        bp = sns.distplot(df[val], hist=False, ax=ax[i // cols, i % cols], kde_kws={'shade': True})\n",
    "        bp.set_title(\"skewness : \" + str(round(df[val].skew(), 1)), fontsize=12)\n",
    "        bp.set_yticks([])\n",
    "        imax = i\n",
    "\n",
    "    for i in range(imax + 1, lines * cols):\n",
    "        ax[i // cols, i % cols].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "print(\"We can check that the numerical variables have a Standard Normal distribution.\")\n",
    "densite(X_train[numerical_columns])\n",
    "\n",
    "print(\"IMPORT FUNCTIONS / DENSITE\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 2) Feature Encoding : One Hot Encoder"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Categorical variables featuring\")\n",
    "\n",
    "print(\"We have :\", categorical_columns.shape[0], \"categorical features to encode.\", end=\"\\n\\n\")\n",
    "print(categorical_columns)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X.dtypes # we check that we have categories"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X[categorical_columns].nunique()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train_std[categorical_columns]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Encoding the categorical features of the train set\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Now, we can use the One Hot Encoder.\")\n",
    "print(\"With the one hot encoder, we will get :\", sum([X[categorical_columns].nunique()[i] for i in range(len(categorical_columns))]), \"columns to encodes the categorical features.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 0) creating instance of one-hot-encoder\n",
    "one_hot_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False) # if sparse=True (by default), we need to add .toarray() to encoded_categorical_data\n",
    "\n",
    "# 1) Fit the encoder on the training set\n",
    "one_hot_encoder.fit(X_train_std[categorical_columns])\n",
    "\n",
    "# 2) we get the encoded numpy array\n",
    "encoded_categorical_data = one_hot_encoder.transform(X_train_std[categorical_columns])\n",
    "\n",
    "# 3) we make a list of the columns names\n",
    "encoded_categorical_data_names = one_hot_encoder.get_feature_names_out().tolist()\n",
    "print(\"We have indeed :\", len(encoded_categorical_data_names), \"labels after encoding the categorical variables.\")\n",
    "\n",
    "# 4) we recreate a dataframe with the column names and the numpy array\n",
    "X_train_encoded = pd.DataFrame(columns=encoded_categorical_data_names,\n",
    "                               data=encoded_categorical_data,\n",
    "                               index=X_train_std.index)\n",
    "display(X_train_encoded.sort_index())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 5) Concatenate the two dataframes for the training set\n",
    "\n",
    "print(\"We need to add YearBuilt to the list of features.\")\n",
    "numerical_columns.tolist()\n",
    "features_to_merge = numerical_columns.tolist().copy()\n",
    "features_to_merge.append(\"YearBuilt\")\n",
    "print(features_to_merge, end=\"\\n\\n\")\n",
    "\n",
    "print(\"ASK JEREMY : merge based on index ok ? or should I put back OSEBuildingID ??\")\n",
    "X_train_std_encoded = pd.merge(X_train_std[features_to_merge].sort_index(), X_train_encoded.sort_index(), left_index=True, right_index=True)\n",
    "display(X_train_std_encoded.sort_index())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Encoding the categorical features of the test set"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 5) One Hot Encoding on the testing set\n",
    "\n",
    "# 5.1) we get the encoded numpy array\n",
    "TEST_encoded_categorical_data = one_hot_encoder.transform(X_test_std[categorical_columns])\n",
    "\n",
    "print(\"ASK JEREMY for this method below ???\")\n",
    "# 5.2) we recreate a dataframe with the column names and the numpy array\n",
    "X_test_encoded = pd.DataFrame(columns=encoded_categorical_data_names,\n",
    "                               data=TEST_encoded_categorical_data,\n",
    "                               index=X_test_std.index)\n",
    "display(X_test_encoded.sort_index())\n",
    "\n",
    "print(\"ASK JEREMY : merge based on index ok ? or should I put back OSEBuildingID ??\")\n",
    "X_test_std_encoded = pd.merge(X_test_std[features_to_merge].sort_index(), X_test_encoded.sort_index(), left_index=True, right_index=True)\n",
    "display(X_test_std_encoded.sort_index())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Save\n",
    "X_train_std_encoded.to_csv(\"dataset/cleaned/electricity/X_train.csv\", index=False)\n",
    "X_test_std_encoded.to_csv(\"dataset/cleaned/electricity/X_test.csv\", index=False)\n",
    "y_train.to_csv(\"dataset/cleaned/electricity/y_train.csv\", index=False)\n",
    "y_test.to_csv(\"dataset/cleaned/electricity/y_test.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## II) Modelisation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"We can start now the modelling to predict the feature wanted.\")\n",
    "\n",
    "display(X_train_std_encoded)\n",
    "display(X_test_std_encoded)\n",
    "print(y_train.shape, y_test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"We rename X_train_std_encoded to X_train, the same for X_test.\")\n",
    "X_train = X_train_std_encoded.copy()\n",
    "X_test = X_test_std_encoded.copy()\n",
    "\n",
    "X_train\n",
    "X_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1) Linear modelling : Linear Regression / Ridge Regression / Lasso / Elastic Net\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_test.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1) Linear Regression : baseline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "# 0) We create a linear regression model\n",
    "lr = linear_model.LinearRegression()\n",
    "\n",
    "# 1) Training Linear Regression and Evaluating\n",
    "reg = lr.fit(X_train, y_train)\n",
    "\n",
    "prediction_score = lr.score(X_test, y_test)\n",
    "#print(\"Accuracy is : %.2f\" % (100 * prediction_score))\n",
    "print('Accuracy is : {:.0%}'.format(prediction_score))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# On récupère l'erreur de norme 2 sur le jeu de données test comme baseline\n",
    "y_pred = lr.predict(X_test)\n",
    "baseline_error = np.mean((y_pred - y_test) ** 2)\n",
    "\n",
    "#On obtient l'erreur quadratique ci-dessous\n",
    "print(baseline_error)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error,r2_score,mean_squared_error\n",
    "\n",
    "def run_experiment(model):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(\"R² : \", r2_score(y_test, y_pred))\n",
    "    print(\"MAE :\", mean_absolute_error(y_test,y_pred))\n",
    "    print(\"RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "\n",
    "run_experiment(lr)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Electricity prediction\")\n",
    "plt.plot(y_pred, y_test, \"ro\", markersize=4)\n",
    "plt.show()\n",
    "\n",
    "print(\"If the prediction was good, we would see a line which is not the case here .\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2) Linear Model : Ridge"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n_alphas = 50 #hyperparametre alpha\n",
    "alphas = np.logspace(-5, 5, n_alphas)\n",
    "\n",
    "ridge = linear_model.Ridge()\n",
    "\n",
    "coefs = []\n",
    "errors = []\n",
    "for a in alphas:\n",
    "    ridge.set_params(alpha=a)\n",
    "    ridge.fit(X_train, y_train)\n",
    "    coefs.append(ridge.coef_)\n",
    "    errors.append(np.mean((ridge.predict(X_test) - y_test) ** 2))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# observation du comportement de l'erreur\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.plot(alphas, errors, [10**-5, 10**5], [baseline_error, baseline_error])\n",
    "ax.set_xscale('log')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ax = plt.gca()\n",
    "\n",
    "ax.plot(alphas, errors)\n",
    "ax.set_xscale('log')\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('error')\n",
    "plt.axis('tight')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# index du min des erreurs\n",
    "np.argmin(errors)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# recupere l'erreur min\n",
    "errors[np.argmin(errors)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# recup alpha associé à cet erreur min\n",
    "alphas[np.argmin(errors)]\n",
    "# alphas[35]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# chemin de régularisation\n",
    "ax = plt.gca()\n",
    "ax.plot(alphas, coefs)\n",
    "ax.set_xscale('log')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ax = plt.gca()\n",
    "\n",
    "ax.plot(alphas, coefs)\n",
    "ax.set_xscale('log')\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('weights')\n",
    "plt.title('Ridge coefficients as a function of the regularization')\n",
    "plt.axis('tight')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "min(errors)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3) Linear Model : LASSO"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "n_alphas = 1000\n",
    "alphas = np.logspace(-5, 5, 50)\n",
    "\n",
    "lasso = linear_model.Lasso()\n",
    "\n",
    "coefs = []\n",
    "errors = []\n",
    "for a in alphas:\n",
    "    lasso.set_params(alpha=a)\n",
    "    lasso.fit(X_train, y_train)\n",
    "    coefs.append(lasso.coef_)\n",
    "    errors.append(np.mean((lasso.predict(X_test) - y_test) ** 2))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% raw\n"
    }
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "n_alphas = 50\n",
    "alphas = np.logspace(-10, 10, n_alphas)\n",
    "lasso = linear_model.Lasso(fit_intercept=False)\n",
    "\n",
    "\"\"\"\n",
    "fit_intercept : bool, default=True\n",
    "Whether to calculate the intercept for this model. If set to False, no intercept will be used in calculations (i.e. data is expected to be centered).\n",
    "\"\"\"\n",
    "\n",
    "coefs = []\n",
    "errors = []\n",
    "for a in alphas:\n",
    "    lasso.set_params(alpha=a)\n",
    "    lasso.fit(X_train, y_train)\n",
    "    coefs.append(lasso.coef_)\n",
    "    errors.append([baseline_error, np.mean((lasso.predict(X_test) - y_test) ** 2)])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% raw\n"
    }
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "# observation du comportement de l'erreur\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.plot(alphas, errors, [10**-5, 10**5], [baseline_error, baseline_error])\n",
    "ax.set_xscale('log')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% raw\n"
    }
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "# recupere l'erreur min\n",
    "errors[np.argmin(errors)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% raw\n"
    }
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "# recup alpha associé à cet erreur min\n",
    "alphas[np.argmin(errors)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% raw\n"
    }
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "# chemin de régularisation\n",
    "ax = plt.gca()\n",
    "ax.plot(alphas, coefs)\n",
    "ax.set_xscale('log')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% raw\n"
    }
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "ax = plt.gca()\n",
    "\n",
    "ax.plot(alphas, coefs)\n",
    "ax.set_xscale('log')\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('weights')\n",
    "plt.axis('tight')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% raw\n"
    }
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.matrix([-0.78768, -1.51760513, 0.74416271, -0.62288928])\n",
    "X = X.T\n",
    "print(X)\n",
    "\n",
    "y = np.matrix([-34.59703199, -30.79543532, 19.31018182, -19.44809959])\n",
    "y = y.T\n",
    "print(y)\n",
    "print(np.linalg.inv(X.T.dot(X)).dot(X.T))\n",
    "beta = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y)\n",
    "beta"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% raw\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4) Linear Model : Elastic Net"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "#rappel de la fonction de coût du elasticnet\n",
    "#1 / (2 * n_samples) * ||y - Xw||^2_2 + alpha * l1_ratio * ||w||_1 + 0.5 * alpha * (1 - l1_ratio) * ||w||^2_2\n",
    "\n",
    "parameters = {'tol' : [0.1,0.01,0.001,0.0001],\n",
    "              \"alpha\": [0.0001, 0.001, 0.01, 0.1, 1, 10, 100],  #alpha, coef qui multiplie le terme de pénalité)\n",
    "              \"l1_ratio\": np.arange(0.0, 1.0, 0.1)}#L1 ratio , =1 équivaut à un Lasso, 0 à un Ridge\n",
    "\n",
    "\n",
    "elastic_grid = GridSearchCV(estimator = ElasticNet(),\n",
    "                            param_grid = parameters,\n",
    "                            scoring = 'neg_mean_squared_error',\n",
    "                            cv=5,\n",
    "                            verbose=0\n",
    "                            )\n",
    "\n",
    "elastic_grid.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% raw\n"
    }
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "elastic_grid.best_params_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% raw\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "results = pd.DataFrame({})\n",
    "\n",
    "import math\n",
    "results = results.append(pd.DataFrame({\n",
    "    'Modèle' : ['Elasticnet Regression'],\n",
    "    'Score_RMSE' : [math.sqrt(mean_squared_error(elastic_grid.predict(X_test), y_test))]}),\n",
    "    ignore_index=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2) Ensemble learning methods"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1) Parallelized Implementation : Random Forest"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rfr = RandomForestRegressor(n_estimators=1000) # nb of trees 1000 for the forest"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "data": {
      "text/plain": "      NumberofBuildings  NumberofFloors  LargestPropertyUseTypeGFA  \\\n1             -0.108665       -0.499734                  -0.531541   \n2             -0.108665       -0.314688                  -0.431401   \n3             -0.108665        1.905866                   0.068770   \n4             -0.108665       -0.314688                  -0.431099   \n5             -0.108665       -0.129642                  -0.305071   \n...                 ...             ...                        ...   \n3124          -0.108665        0.055404                  -0.241025   \n3125          -0.108665       -0.499734                  -0.489641   \n3126           4.469907       -0.314688                  -0.530418   \n3128          -0.108665        0.055404                  -0.515493   \n3129          -0.108665       -0.499734                  -0.568009   \n\n      SecondLargestPropertyUseTypeGFA  ThirdLargestPropertyUseTypeGFA  \\\n1                           -0.141522                        0.134019   \n2                           -0.382358                       -0.207072   \n3                           -0.382358                       -0.207072   \n4                           -0.266691                       -0.207072   \n5                           -0.382358                       -0.207072   \n...                               ...                             ...   \n3124                        -0.382358                       -0.207072   \n3125                        -0.006164                       -0.046558   \n3126                         0.006725                        0.871936   \n3128                        -0.141054                       -0.039870   \n3129                        -0.162039                       -0.207072   \n\n      YearBuilt  BuildingType_Campus  BuildingType_Multifamily HR (10+)  \\\n1          1928                  0.0                                0.0   \n2          1925                  0.0                                0.0   \n3          1971                  0.0                                1.0   \n4          2001                  0.0                                0.0   \n5          1996                  0.0                                0.0   \n...         ...                  ...                                ...   \n3124       1925                  0.0                                0.0   \n3125       1927                  0.0                                0.0   \n3126       2001                  0.0                                0.0   \n3128       2001                  0.0                                0.0   \n3129       1911                  0.0                                0.0   \n\n      BuildingType_Multifamily LR (1-4)  BuildingType_Multifamily MR (5-9)  \\\n1                                   0.0                                0.0   \n2                                   1.0                                0.0   \n3                                   0.0                                0.0   \n4                                   1.0                                0.0   \n5                                   0.0                                0.0   \n...                                 ...                                ...   \n3124                                0.0                                1.0   \n3125                                0.0                                0.0   \n3126                                0.0                                0.0   \n3128                                0.0                                0.0   \n3129                                0.0                                0.0   \n\n      ...  ThirdLargestPropertyUseType_Refrigerated Warehouse  \\\n1     ...                                                0.0    \n2     ...                                                0.0    \n3     ...                                                0.0    \n4     ...                                                0.0    \n5     ...                                                0.0    \n...   ...                                                ...    \n3124  ...                                                0.0    \n3125  ...                                                0.0    \n3126  ...                                                0.0    \n3128  ...                                                0.0    \n3129  ...                                                0.0    \n\n      ThirdLargestPropertyUseType_Residence Hall/Dormitory  \\\n1                                                   0.0      \n2                                                   0.0      \n3                                                   0.0      \n4                                                   0.0      \n5                                                   0.0      \n...                                                 ...      \n3124                                                0.0      \n3125                                                0.0      \n3126                                                0.0      \n3128                                                0.0      \n3129                                                0.0      \n\n      ThirdLargestPropertyUseType_Restaurant  \\\n1                                        0.0   \n2                                        0.0   \n3                                        0.0   \n4                                        0.0   \n5                                        0.0   \n...                                      ...   \n3124                                     0.0   \n3125                                     0.0   \n3126                                     0.0   \n3128                                     0.0   \n3129                                     0.0   \n\n      ThirdLargestPropertyUseType_Retail Store  \\\n1                                          0.0   \n2                                          0.0   \n3                                          0.0   \n4                                          0.0   \n5                                          0.0   \n...                                        ...   \n3124                                       0.0   \n3125                                       1.0   \n3126                                       0.0   \n3128                                       0.0   \n3129                                       0.0   \n\n      ThirdLargestPropertyUseType_Social/Meeting Hall  \\\n1                                                 0.0   \n2                                                 0.0   \n3                                                 0.0   \n4                                                 0.0   \n5                                                 0.0   \n...                                               ...   \n3124                                              0.0   \n3125                                              0.0   \n3126                                              0.0   \n3128                                              0.0   \n3129                                              0.0   \n\n      ThirdLargestPropertyUseType_Strip Mall  \\\n1                                        0.0   \n2                                        0.0   \n3                                        0.0   \n4                                        0.0   \n5                                        0.0   \n...                                      ...   \n3124                                     0.0   \n3125                                     0.0   \n3126                                     0.0   \n3128                                     0.0   \n3129                                     0.0   \n\n      ThirdLargestPropertyUseType_Supermarket/Grocery Store  \\\n1                                                   0.0       \n2                                                   0.0       \n3                                                   0.0       \n4                                                   0.0       \n5                                                   0.0       \n...                                                 ...       \n3124                                                0.0       \n3125                                                0.0       \n3126                                                0.0       \n3128                                                0.0       \n3129                                                0.0       \n\n      ThirdLargestPropertyUseType_Swimming Pool  \\\n1                                           0.0   \n2                                           0.0   \n3                                           0.0   \n4                                           0.0   \n5                                           0.0   \n...                                         ...   \n3124                                        0.0   \n3125                                        0.0   \n3126                                        0.0   \n3128                                        0.0   \n3129                                        0.0   \n\n      ThirdLargestPropertyUseType_Vocational School  \\\n1                                               0.0   \n2                                               0.0   \n3                                               0.0   \n4                                               0.0   \n5                                               0.0   \n...                                             ...   \n3124                                            0.0   \n3125                                            0.0   \n3126                                            0.0   \n3128                                            0.0   \n3129                                            0.0   \n\n      ThirdLargestPropertyUseType_Worship Facility  \n1                                              0.0  \n2                                              0.0  \n3                                              0.0  \n4                                              0.0  \n5                                              0.0  \n...                                            ...  \n3124                                           0.0  \n3125                                           0.0  \n3126                                           0.0  \n3128                                           0.0  \n3129                                           0.0  \n\n[2191 rows x 189 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>NumberofBuildings</th>\n      <th>NumberofFloors</th>\n      <th>LargestPropertyUseTypeGFA</th>\n      <th>SecondLargestPropertyUseTypeGFA</th>\n      <th>ThirdLargestPropertyUseTypeGFA</th>\n      <th>YearBuilt</th>\n      <th>BuildingType_Campus</th>\n      <th>BuildingType_Multifamily HR (10+)</th>\n      <th>BuildingType_Multifamily LR (1-4)</th>\n      <th>BuildingType_Multifamily MR (5-9)</th>\n      <th>...</th>\n      <th>ThirdLargestPropertyUseType_Refrigerated Warehouse</th>\n      <th>ThirdLargestPropertyUseType_Residence Hall/Dormitory</th>\n      <th>ThirdLargestPropertyUseType_Restaurant</th>\n      <th>ThirdLargestPropertyUseType_Retail Store</th>\n      <th>ThirdLargestPropertyUseType_Social/Meeting Hall</th>\n      <th>ThirdLargestPropertyUseType_Strip Mall</th>\n      <th>ThirdLargestPropertyUseType_Supermarket/Grocery Store</th>\n      <th>ThirdLargestPropertyUseType_Swimming Pool</th>\n      <th>ThirdLargestPropertyUseType_Vocational School</th>\n      <th>ThirdLargestPropertyUseType_Worship Facility</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>-0.108665</td>\n      <td>-0.499734</td>\n      <td>-0.531541</td>\n      <td>-0.141522</td>\n      <td>0.134019</td>\n      <td>1928</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.108665</td>\n      <td>-0.314688</td>\n      <td>-0.431401</td>\n      <td>-0.382358</td>\n      <td>-0.207072</td>\n      <td>1925</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.108665</td>\n      <td>1.905866</td>\n      <td>0.068770</td>\n      <td>-0.382358</td>\n      <td>-0.207072</td>\n      <td>1971</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.108665</td>\n      <td>-0.314688</td>\n      <td>-0.431099</td>\n      <td>-0.266691</td>\n      <td>-0.207072</td>\n      <td>2001</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>-0.108665</td>\n      <td>-0.129642</td>\n      <td>-0.305071</td>\n      <td>-0.382358</td>\n      <td>-0.207072</td>\n      <td>1996</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3124</th>\n      <td>-0.108665</td>\n      <td>0.055404</td>\n      <td>-0.241025</td>\n      <td>-0.382358</td>\n      <td>-0.207072</td>\n      <td>1925</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3125</th>\n      <td>-0.108665</td>\n      <td>-0.499734</td>\n      <td>-0.489641</td>\n      <td>-0.006164</td>\n      <td>-0.046558</td>\n      <td>1927</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3126</th>\n      <td>4.469907</td>\n      <td>-0.314688</td>\n      <td>-0.530418</td>\n      <td>0.006725</td>\n      <td>0.871936</td>\n      <td>2001</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3128</th>\n      <td>-0.108665</td>\n      <td>0.055404</td>\n      <td>-0.515493</td>\n      <td>-0.141054</td>\n      <td>-0.039870</td>\n      <td>2001</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3129</th>\n      <td>-0.108665</td>\n      <td>-0.499734</td>\n      <td>-0.568009</td>\n      <td>-0.162039</td>\n      <td>-0.207072</td>\n      <td>1911</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>2191 rows × 189 columns</p>\n</div>"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "rfr = rfr.fit(X_train.values, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy -0.11 time 0.27s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import timeit\n",
    "\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "pred = rfr.predict(X_test.values)\n",
    "\n",
    "elapsed = timeit.default_timer() - start_time\n",
    "\n",
    "accuracy = rfr.score(X_test.values, y_test)\n",
    "\n",
    "print(\"accuracy {:.2f} time {:.2f}s\".format(accuracy, elapsed))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "(2191, 11)"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "model = SelectFromModel(rfr, prefit=True, threshold=0.01)\n",
    "X_train2 = model.transform(X_train.values)\n",
    "X_train2.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-0.49973446, -0.53154056, -0.14152203, ...,  0.        ,\n         0.        ,  0.        ],\n       [-0.31468828, -0.4314006 , -0.38235791, ...,  0.        ,\n         0.        ,  0.        ],\n       [ 1.90586576,  0.06876975, -0.38235791, ...,  0.        ,\n         0.        ,  0.        ],\n       ...,\n       [-0.31468828, -0.53041775,  0.00672492, ...,  0.        ,\n         0.        ,  0.        ],\n       [ 0.05540406, -0.51549261, -0.14105385, ...,  0.        ,\n         0.        ,  0.        ],\n       [-0.49973446, -0.56800903, -0.16203921, ...,  0.        ,\n         0.        ,  0.        ]])"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "rfr2 = RandomForestRegressor(n_estimators=1000) # nb of trees 1000 for the forest\n",
    "rfr2 = rfr.fit(X_train2, y_train)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² :  -0.10351319339504972\n",
      "MAE : 1.3727456535131668\n",
      "RMSE: 1.7673230612188662\n"
     ]
    },
    {
     "data": {
      "text/plain": "'\\nR² :  -0.036410020297567236\\nMAE : 1.3407748367227499\\nRMSE: 1.698681454232116\\n'"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_experiment(rfr)\n",
    "\n",
    "\"\"\"\n",
    "R² :  -0.036410020297567236\n",
    "MAE : 1.3407748367227499\n",
    "RMSE: 1.698681454232116\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "parameters = {\n",
    "    'n_estimators' : [10,50,100,300,500], #nombre d'arbres de décision\n",
    "    'min_samples_leaf' : [1,3,5,10], #nombre de feuilles minimales dans un noeud\n",
    "    'max_features': ['auto', 'sqrt'] #nombre de features observées pour chaque arbre\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% raw\n"
    }
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "rfr_search = GridSearchCV(RandomForestRegressor(),\n",
    "                          param_grid = parameters,\n",
    "                          #scoring='mean_squared_error',\n",
    "                          verbose=2,\n",
    "                          cv=5)\n",
    "\n",
    "rfr_search.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% raw\n"
    }
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "rfr_search.best_params_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% raw\n"
    }
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "import math\n",
    "results = results.append(pd.DataFrame({\n",
    "    'Modèle' : ['Random Forest Regressor'],\n",
    "    'Score_RMSE' : [math.sqrt(mean_squared_error(rfr_search.predict(X_test), y_test))]}),\n",
    "    ignore_index=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% raw\n"
    }
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "coefficients = abs(rfr_search.best_estimator_.feature_importances_)\n",
    "liste_coefs_rer = pd.concat((pd.DataFrame(X.columns, columns = ['Variable']),\n",
    "                             pd.DataFrame(coefficients, columns = ['Coefficient'])), axis = 1).sort_values(by='Coefficient', ascending = False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% raw\n"
    }
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.title('RandomForestRegressor - Importance des 20 premières Features')\n",
    "sns.barplot(y = liste_coefs_rer['Variable'].head(20),\n",
    "            x = liste_coefs_rer['Coefficient'].head(20))\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% raw\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2) Sequence Tree : XGBoost"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.matrix([-0.78768, -1.51760513, 0.74416271, -0.62288928])\n",
    "X = X.T\n",
    "print(X)\n",
    "\n",
    "y = np.matrix([-34.59703199, -30.79543532, 19.31018182, -19.44809959])\n",
    "y = y.T\n",
    "print(y)\n",
    "print(np.linalg.inv(X.T.dot(X)).dot(X.T))\n",
    "beta = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y)\n",
    "beta"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% raw\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Export des modèles pour réutilisation ultérieure\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Chargement des modèles\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Comparaison des modèles\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "plt.title('Comparaison des RMSE relatives des modèles (en %)')\n",
    "chart = sns.barplot(x = results['Modèle'],\n",
    "                    y = results['RMSE_%']*100)\n",
    "chart.set_xticklabels(labels = results['Modèle'],\n",
    "                      rotation=45,\n",
    "                      horizontalalignment='right',\n",
    "                      size=12,\n",
    "                      )\n",
    "ax = plt.gca()\n",
    "ax.set_ylim([0, 5])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% raw\n"
    }
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "plt.title('Temps d\\'exécution des algorithmes pour la prédiction \\n(jeu d\\'entrainement) - échelle logarithmique')\n",
    "sns.barplot(x=nom_modeles,\n",
    "            y = [5.32, 640, 2.14, 145])\n",
    "ax = plt.gca()\n",
    "ax.set_yscale('log')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% raw\n"
    }
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "sns.barplot(x = comparaison_score_melt['index'],\n",
    "            y = comparaison_score_melt['score'], hue = comparaison_score_melt['variable'])\n",
    "plt.title('Comparaison des performances des modèles (jeu de test)')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% raw\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### III) Evaluation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Vérification des prédictions\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Intérêt du Energy Star Score\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}