{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "OpenClassrooms\n",
    "Project 4, Data Scientist\n",
    "Author : Oumeima EL GHARBI\n",
    "Date : August 2022"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Un notebook pour chaque prédiction (émissions de CO2 et consommation totale d’énergie) des différents tests de modèles mis au propre, dans lequel vous identifierez clairement le modèle final choisi.\n",
    "\n",
    "\n",
    "L’objectif est de te passer des relevés de consommation annuels futurs (attention à la fuite de données). Nous ferons de toute façon pour tout nouveau bâtiment un premier relevé de référence la première année, donc rien ne t'interdit d’en déduire des variables structurelles aux bâtiments, par exemple la nature et proportions des sources d’énergie utilisées..\n",
    "\n",
    "Fais bien attention au traitement des différentes variables, à la fois pour trouver de nouvelles informations (peut-on déduire des choses intéressantes d’une simple adresse ?) et optimiser les performances en appliquant des transformations simples aux variables (normalisation, passage au log, etc.).\n",
    "\n",
    "Mets en place une évaluation rigoureuse des performances de la régression, et optimise les hyperparamètres et le choix d’algorithmes de ML à l’aide d’une validation croisée."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "Tester les modèles suivants : **regression linéaire (avec différentes régularisation : Ridge, Lasso, Elastic), Random Forest, XGboost**\n",
    "Penser à comparer les performances des différents modèles : utiliser la **MAE** ( Mean Absolute Error)\n",
    "Penser également à optimiser les hyper paramètres de chaque modèle via **GridSearch**\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Evaluate :\n",
    "\n",
    "https://cloud.google.com/automl-tables/docs/evaluate?hl=fr\n",
    "\n",
    "\n",
    "KFOLD\n",
    "\n",
    "Entrée : données X (dimension nxp), étiquettes y (dimension n), nombre de folds k\n",
    "\n",
    "Couper [0, 1, ..., n-1] en k parties de taille (n/k). (La dernière partie sera un peu plus petite si n n'est pas un multiple de k)\n",
    "\n",
    "for i=0 to (k-1):\n",
    "    Former le jeu de test (X_test, y_test) en restreignant X et y aux indices contenus dans la i-ième partie.\n",
    "    Former le jeu d'entraînement (X_train, y_train) en restreignant X et y aux autres indices.\n",
    "    Entraîner l'algorithme sur le jeu d'entraînement\n",
    "    Utiliser le modèle ainsi obtenu pour prédire sur le jeu de test\n",
    "        Calculer l'erreur du modèle en comparant les étiquettes prédites aux vraies étiquettes contenues dans y_test\n",
    "\n",
    "Sortie : la valeur moyenne des erreurs calculées sur les k folds."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# 1 modele de Regression (RL classsque / Elastic / ridig / laso\n",
    "# Random Forest\n",
    "# XGBOOST\n",
    "\n",
    "# var à rpedire tottal GHE Emssion last one to predict\n",
    "# cette var deped de la consommation des bateimenst (1) prediction sur elec, steam, naturalgas et un autre energie (2) et reutiliser pour predire"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Introduction"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Importing libraries"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "application/javascript": "IPython.notebook.set_autosave_interval(300000)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 300 seconds\n"
     ]
    }
   ],
   "source": [
    "%reset -f\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "%autosave 300"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Loading dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dictionary will be used when reading the csv file to assign a type to categorical features : {'BuildingType': 'category', 'PrimaryPropertyType': 'category', 'ZipCode': 'category', 'CouncilDistrictCode': 'category', 'LargestPropertyUseType': 'category', 'SecondLargestPropertyUseType': 'category', 'ThirdLargestPropertyUseType': 'category'}\n"
     ]
    }
   ],
   "source": [
    "columns_to_categorize = [\"BuildingType\", \"PrimaryPropertyType\", \"ZipCode\", \"CouncilDistrictCode\", \"LargestPropertyUseType\", \"SecondLargestPropertyUseType\", \"ThirdLargestPropertyUseType\"]\n",
    "#  \"Neighborhood\",\n",
    "category_types = {column: 'category' for column in columns_to_categorize}\n",
    "print(\"This dictionary will be used when reading the csv file to assign a type to categorical features :\", category_types)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "dataset_path = \"dataset/cleaned/2016_Building_Energy_Prediction.csv\"\n",
    "# we assign the categorical features with a categotical type\n",
    "data = pd.read_csv(dataset_path, dtype=category_types, sep=\",\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "(3131, 29)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "OSEBuildingID                         int64\nBuildingType                       category\nPrimaryPropertyType                category\nZipCode                            category\nCouncilDistrictCode                category\nNeighborhood                         object\nYearBuilt                             int64\nNumberofBuildings                   float64\nNumberofFloors                        int64\nPropertyGFATotal                      int64\nPropertyGFAParking                    int64\nPropertyGFABuilding(s)                int64\nLargestPropertyUseType             category\nLargestPropertyUseTypeGFA           float64\nSecondLargestPropertyUseType       category\nSecondLargestPropertyUseTypeGFA     float64\nThirdLargestPropertyUseType        category\nThirdLargestPropertyUseTypeGFA      float64\nENERGYSTARScore                     float64\nSiteEnergyUse(kBtu)                 float64\nSteamUse(kBtu)                      float64\nElectricity(kBtu)                   float64\nNaturalGas(kBtu)                    float64\nTotalGHGEmissions                   float64\nLog2-SiteEnergyUse(kBtu)            float64\nLog2-SteamUse(kBtu)                 float64\nLog2-Electricity(kBtu)              float64\nLog2-NaturalGas(kBtu)               float64\nLog2-TotalGHGEmissions              float64\ndtype: object"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# predict : Electricity\n",
    "# train / test\n",
    "# standardisation = retirer la moyen et div par ecart type (scaling : les var qn sur emem echelle\n",
    "# var categ : encoding (one hot encoder)\n",
    "\n",
    "# la fin Feature engineriing\n",
    "\n",
    "# 2) entrainer le smodels\n",
    "# perf\n",
    "# temps de calcul\n",
    "# graph pour montrer la perf de chaque modele(barplot)\n",
    "# obj : finir exploration / finir feature engineering\n",
    "# obj un premier noteboook propre (try max)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['OSEBuildingID', 'BuildingType', 'PrimaryPropertyType', 'ZipCode',\n       'CouncilDistrictCode', 'Neighborhood', 'YearBuilt', 'NumberofBuildings',\n       'NumberofFloors', 'PropertyGFATotal', 'PropertyGFAParking',\n       'PropertyGFABuilding(s)', 'LargestPropertyUseType',\n       'LargestPropertyUseTypeGFA', 'SecondLargestPropertyUseType',\n       'SecondLargestPropertyUseTypeGFA', 'ThirdLargestPropertyUseType',\n       'ThirdLargestPropertyUseTypeGFA', 'ENERGYSTARScore',\n       'SiteEnergyUse(kBtu)', 'SteamUse(kBtu)', 'Electricity(kBtu)',\n       'NaturalGas(kBtu)', 'TotalGHGEmissions', 'Log2-SiteEnergyUse(kBtu)',\n       'Log2-SteamUse(kBtu)', 'Log2-Electricity(kBtu)',\n       'Log2-NaturalGas(kBtu)', 'Log2-TotalGHGEmissions'],\n      dtype='object')"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['YearBuilt', 'BuildingType', 'PrimaryPropertyType', 'Neighborhood', 'NumberofFloors', 'PropertyGFATotal', 'PropertyGFAParking', 'SecondLargestPropertyUseTypeGFA', 'ThirdLargestPropertyUseTypeGFA', 'Log2-Electricity(kBtu)']\n"
     ]
    }
   ],
   "source": [
    "features_for_prediction = [\"YearBuilt\",  \"BuildingType\",\"PrimaryPropertyType\", \"Neighborhood\", \"NumberofFloors\", \"PropertyGFATotal\", \"PropertyGFAParking\", \"SecondLargestPropertyUseTypeGFA\", \"ThirdLargestPropertyUseTypeGFA\"]\n",
    "\n",
    "variable_to_predict = \"Log2-Electricity(kBtu)\"\n",
    "\n",
    "features_for_prediction.append(variable_to_predict)\n",
    "print(features_for_prediction)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "      YearBuilt          BuildingType          PrimaryPropertyType  \\\n0          1978  Multifamily LR (1-4)         Low-Rise Multifamily   \n1          1928        NonResidential                    Warehouse   \n2          1925  Multifamily LR (1-4)         Low-Rise Multifamily   \n3          1971  Multifamily HR (10+)        High-Rise Multifamily   \n4          2001  Multifamily LR (1-4)         Low-Rise Multifamily   \n...         ...                   ...                          ...   \n3126       2001        NonResidential           Mixed Use Property   \n3127       1907  Multifamily LR (1-4)         Low-Rise Multifamily   \n3128       2001        NonResidential  Small- and Mid-Sized Office   \n3129       1911        NonResidential                 Retail Store   \n3130       1938    Nonresidential COS           Mixed Use Property   \n\n          Neighborhood  NumberofFloors  PropertyGFATotal  PropertyGFAParking  \\\n0              central               3             20739                   0   \n1     greater duwamish               2             25955                   0   \n2     greater duwamish               3             25120                   0   \n3     greater duwamish              15             73898                   0   \n4     greater duwamish               3             36383                7030   \n...                ...             ...               ...                 ...   \n3126        lake union               3             41827                9226   \n3127        lake union               4             36660                   0   \n3128        lake union               5             33740                6010   \n3129        lake union               2             20516                   0   \n3130  greater duwamish               1             18258                   0   \n\n      SecondLargestPropertyUseTypeGFA  ThirdLargestPropertyUseTypeGFA  \\\n0                                 0.0                             0.0   \n1                              8745.0                          3060.0   \n2                                 0.0                             0.0   \n3                                 0.0                             0.0   \n4                              4200.0                             0.0   \n...                               ...                             ...   \n3126                          14128.0                          9680.0   \n3127                              0.0                             0.0   \n3128                           8762.0                          1500.0   \n3129                           8000.0                             0.0   \n3130                           8000.0                          1108.0   \n\n      Log2-Electricity(kBtu)  \n0                  19.638743  \n1                  20.216217  \n2                  18.213921  \n3                  21.038823  \n4                  19.327996  \n...                      ...  \n3126               21.217915  \n3127               18.981534  \n3128               20.300511  \n3129               18.015551  \n3130               18.722525  \n\n[3131 rows x 10 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>YearBuilt</th>\n      <th>BuildingType</th>\n      <th>PrimaryPropertyType</th>\n      <th>Neighborhood</th>\n      <th>NumberofFloors</th>\n      <th>PropertyGFATotal</th>\n      <th>PropertyGFAParking</th>\n      <th>SecondLargestPropertyUseTypeGFA</th>\n      <th>ThirdLargestPropertyUseTypeGFA</th>\n      <th>Log2-Electricity(kBtu)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1978</td>\n      <td>Multifamily LR (1-4)</td>\n      <td>Low-Rise Multifamily</td>\n      <td>central</td>\n      <td>3</td>\n      <td>20739</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>19.638743</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1928</td>\n      <td>NonResidential</td>\n      <td>Warehouse</td>\n      <td>greater duwamish</td>\n      <td>2</td>\n      <td>25955</td>\n      <td>0</td>\n      <td>8745.0</td>\n      <td>3060.0</td>\n      <td>20.216217</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1925</td>\n      <td>Multifamily LR (1-4)</td>\n      <td>Low-Rise Multifamily</td>\n      <td>greater duwamish</td>\n      <td>3</td>\n      <td>25120</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>18.213921</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1971</td>\n      <td>Multifamily HR (10+)</td>\n      <td>High-Rise Multifamily</td>\n      <td>greater duwamish</td>\n      <td>15</td>\n      <td>73898</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>21.038823</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2001</td>\n      <td>Multifamily LR (1-4)</td>\n      <td>Low-Rise Multifamily</td>\n      <td>greater duwamish</td>\n      <td>3</td>\n      <td>36383</td>\n      <td>7030</td>\n      <td>4200.0</td>\n      <td>0.0</td>\n      <td>19.327996</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3126</th>\n      <td>2001</td>\n      <td>NonResidential</td>\n      <td>Mixed Use Property</td>\n      <td>lake union</td>\n      <td>3</td>\n      <td>41827</td>\n      <td>9226</td>\n      <td>14128.0</td>\n      <td>9680.0</td>\n      <td>21.217915</td>\n    </tr>\n    <tr>\n      <th>3127</th>\n      <td>1907</td>\n      <td>Multifamily LR (1-4)</td>\n      <td>Low-Rise Multifamily</td>\n      <td>lake union</td>\n      <td>4</td>\n      <td>36660</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>18.981534</td>\n    </tr>\n    <tr>\n      <th>3128</th>\n      <td>2001</td>\n      <td>NonResidential</td>\n      <td>Small- and Mid-Sized Office</td>\n      <td>lake union</td>\n      <td>5</td>\n      <td>33740</td>\n      <td>6010</td>\n      <td>8762.0</td>\n      <td>1500.0</td>\n      <td>20.300511</td>\n    </tr>\n    <tr>\n      <th>3129</th>\n      <td>1911</td>\n      <td>NonResidential</td>\n      <td>Retail Store</td>\n      <td>lake union</td>\n      <td>2</td>\n      <td>20516</td>\n      <td>0</td>\n      <td>8000.0</td>\n      <td>0.0</td>\n      <td>18.015551</td>\n    </tr>\n    <tr>\n      <th>3130</th>\n      <td>1938</td>\n      <td>Nonresidential COS</td>\n      <td>Mixed Use Property</td>\n      <td>greater duwamish</td>\n      <td>1</td>\n      <td>18258</td>\n      <td>0</td>\n      <td>8000.0</td>\n      <td>1108.0</td>\n      <td>18.722525</td>\n    </tr>\n  </tbody>\n</table>\n<p>3131 rows × 10 columns</p>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[features_for_prediction]\n",
    "\n",
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## I) Feature Engineering : preparing the vectors and matrices\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1) Separating training data and target vector"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X : (3131, 9)\n",
      "Shape of y : (3131,)\n"
     ]
    }
   ],
   "source": [
    "# we create the data matrix / we only take the features\n",
    "X = data[data.columns[:-1]]\n",
    "\n",
    "# we create the target vector\n",
    "y = data[variable_to_predict].values # numpy array not a DataFrame anymore\n",
    "\n",
    "print(\"Shape of X :\", X.shape)\n",
    "print(\"Shape of y :\", y.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "      YearBuilt          BuildingType          PrimaryPropertyType  \\\n0          1978  Multifamily LR (1-4)         Low-Rise Multifamily   \n1          1928        NonResidential                    Warehouse   \n2          1925  Multifamily LR (1-4)         Low-Rise Multifamily   \n3          1971  Multifamily HR (10+)        High-Rise Multifamily   \n4          2001  Multifamily LR (1-4)         Low-Rise Multifamily   \n...         ...                   ...                          ...   \n3126       2001        NonResidential           Mixed Use Property   \n3127       1907  Multifamily LR (1-4)         Low-Rise Multifamily   \n3128       2001        NonResidential  Small- and Mid-Sized Office   \n3129       1911        NonResidential                 Retail Store   \n3130       1938    Nonresidential COS           Mixed Use Property   \n\n          Neighborhood  NumberofFloors  PropertyGFATotal  PropertyGFAParking  \\\n0              central               3             20739                   0   \n1     greater duwamish               2             25955                   0   \n2     greater duwamish               3             25120                   0   \n3     greater duwamish              15             73898                   0   \n4     greater duwamish               3             36383                7030   \n...                ...             ...               ...                 ...   \n3126        lake union               3             41827                9226   \n3127        lake union               4             36660                   0   \n3128        lake union               5             33740                6010   \n3129        lake union               2             20516                   0   \n3130  greater duwamish               1             18258                   0   \n\n      SecondLargestPropertyUseTypeGFA  ThirdLargestPropertyUseTypeGFA  \n0                                 0.0                             0.0  \n1                              8745.0                          3060.0  \n2                                 0.0                             0.0  \n3                                 0.0                             0.0  \n4                              4200.0                             0.0  \n...                               ...                             ...  \n3126                          14128.0                          9680.0  \n3127                              0.0                             0.0  \n3128                           8762.0                          1500.0  \n3129                           8000.0                             0.0  \n3130                           8000.0                          1108.0  \n\n[3131 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>YearBuilt</th>\n      <th>BuildingType</th>\n      <th>PrimaryPropertyType</th>\n      <th>Neighborhood</th>\n      <th>NumberofFloors</th>\n      <th>PropertyGFATotal</th>\n      <th>PropertyGFAParking</th>\n      <th>SecondLargestPropertyUseTypeGFA</th>\n      <th>ThirdLargestPropertyUseTypeGFA</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1978</td>\n      <td>Multifamily LR (1-4)</td>\n      <td>Low-Rise Multifamily</td>\n      <td>central</td>\n      <td>3</td>\n      <td>20739</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1928</td>\n      <td>NonResidential</td>\n      <td>Warehouse</td>\n      <td>greater duwamish</td>\n      <td>2</td>\n      <td>25955</td>\n      <td>0</td>\n      <td>8745.0</td>\n      <td>3060.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1925</td>\n      <td>Multifamily LR (1-4)</td>\n      <td>Low-Rise Multifamily</td>\n      <td>greater duwamish</td>\n      <td>3</td>\n      <td>25120</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1971</td>\n      <td>Multifamily HR (10+)</td>\n      <td>High-Rise Multifamily</td>\n      <td>greater duwamish</td>\n      <td>15</td>\n      <td>73898</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2001</td>\n      <td>Multifamily LR (1-4)</td>\n      <td>Low-Rise Multifamily</td>\n      <td>greater duwamish</td>\n      <td>3</td>\n      <td>36383</td>\n      <td>7030</td>\n      <td>4200.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3126</th>\n      <td>2001</td>\n      <td>NonResidential</td>\n      <td>Mixed Use Property</td>\n      <td>lake union</td>\n      <td>3</td>\n      <td>41827</td>\n      <td>9226</td>\n      <td>14128.0</td>\n      <td>9680.0</td>\n    </tr>\n    <tr>\n      <th>3127</th>\n      <td>1907</td>\n      <td>Multifamily LR (1-4)</td>\n      <td>Low-Rise Multifamily</td>\n      <td>lake union</td>\n      <td>4</td>\n      <td>36660</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3128</th>\n      <td>2001</td>\n      <td>NonResidential</td>\n      <td>Small- and Mid-Sized Office</td>\n      <td>lake union</td>\n      <td>5</td>\n      <td>33740</td>\n      <td>6010</td>\n      <td>8762.0</td>\n      <td>1500.0</td>\n    </tr>\n    <tr>\n      <th>3129</th>\n      <td>1911</td>\n      <td>NonResidential</td>\n      <td>Retail Store</td>\n      <td>lake union</td>\n      <td>2</td>\n      <td>20516</td>\n      <td>0</td>\n      <td>8000.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3130</th>\n      <td>1938</td>\n      <td>Nonresidential COS</td>\n      <td>Mixed Use Property</td>\n      <td>greater duwamish</td>\n      <td>1</td>\n      <td>18258</td>\n      <td>0</td>\n      <td>8000.0</td>\n      <td>1108.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>3131 rows × 9 columns</p>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2) Separation train and test dataset\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have to separate the train / test sets before normalising the dataset.\n"
     ]
    }
   ],
   "source": [
    "print(\"We have to separate the train / test sets before normalising the dataset.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# We create a training set and a test set (the test set contains 30% of the dataset)\n",
    "from sklearn import model_selection\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.3,  random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "(2191, 9)"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "(940, 9)"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3) Normalization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We separate categorical variables from numerical variables.\n"
     ]
    }
   ],
   "source": [
    "print(\"We separate categorical variables from numerical variables.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We won't normalise the year so we drop it from numerical_columns.\n",
      "Shape of categorical variables :  (3,)\n",
      "Shape of numerical variables : (5,)\n"
     ]
    }
   ],
   "source": [
    "X.select_dtypes(['category','object']) # we don't have 'object' here but it is just in case.\n",
    "\n",
    "categorical_columns = X.select_dtypes(['category','object']).columns\n",
    "numerical_columns = X.select_dtypes(include='number').columns.drop(\"YearBuilt\")\n",
    "print(\"We won't normalise the year so we drop it from numerical_columns.\")\n",
    "\n",
    "print(\"Shape of categorical variables : \", categorical_columns.shape)\n",
    "print(\"Shape of numerical variables :\", numerical_columns.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 1) Data Standardisation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We have to standardize the variables before learning a **Ridge Regression**.\n",
    "Standardizing means that each variable will have a **standard deviation** equal to 1."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical variables standardization\n",
      "We have : 5 numerical features to standardize.\n",
      "\n",
      "Index(['NumberofFloors', 'PropertyGFATotal', 'PropertyGFAParking',\n",
      "       'SecondLargestPropertyUseTypeGFA', 'ThirdLargestPropertyUseTypeGFA'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"Numerical variables standardization\")\n",
    "print(\"We have :\", numerical_columns.shape[0], \"numerical features to standardize.\",end=\"\\n\\n\")\n",
    "\n",
    "print(numerical_columns)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "print(\"Dates standardisation : not\")\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "def convert_to_timestamp(date):\n",
    "    \"\"\"\n",
    "    Convert date objects to integers\n",
    "    :param date:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    try:\n",
    "        timestamp = datetime.timestamp(date)\n",
    "        print(\"timestamp =\", timestamp, type(timestamp))\n",
    "        print(\"OK :\", date, type(date))\n",
    "\n",
    "        return timestamp\n",
    "    except Exception as e:\n",
    "        print(\"Error :\", date, type(date))\n",
    "        print(e)\n",
    "\n",
    "def normalize_min_max(data_frame, columns_to_scale):\n",
    "    \"\"\"\n",
    "    Normalizes the dataframe for the wanted column(s) using min/max\n",
    "    :param data_frame:\n",
    "    :param columns_to_scale: (list)\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    df = data_frame.copy() # we will return a copy of our dataframe\n",
    "    df[columns_to_scale] = min_max_scaler.fit_transform(df[columns_to_scale])\n",
    "    return df\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% raw\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before\n"
     ]
    },
    {
     "data": {
      "text/plain": "      YearBuilt          BuildingType          PrimaryPropertyType  \\\n2091       1922        NonResidential                        Hotel   \n2071       1930        NonResidential                        Hotel   \n964        1929    Nonresidential COS                        Other   \n2218       1970        NonResidential  Small- and Mid-Sized Office   \n2737       1929  Multifamily LR (1-4)         Low-Rise Multifamily   \n...         ...                   ...                          ...   \n3092       1986        NonResidential  Small- and Mid-Sized Office   \n1095       2012  Multifamily MR (5-9)         Mid-Rise Multifamily   \n1130       2014  Multifamily MR (5-9)         Mid-Rise Multifamily   \n1294       1998  Multifamily MR (5-9)         Mid-Rise Multifamily   \n860        1970  Multifamily MR (5-9)         Mid-Rise Multifamily   \n\n               Neighborhood  NumberofFloors  PropertyGFATotal  \\\n2091               downtown              11             92190   \n2071               downtown              20             98634   \n964               northeast               3             27908   \n2218             lake union               7             94002   \n2737  magnolia / queen anne               3             32908   \n...                     ...             ...               ...   \n3092  magnolia / queen anne               3             40067   \n1095              northeast               7             74421   \n1130                ballard               8            439262   \n1294                   east               5             33274   \n860   magnolia / queen anne               5             34480   \n\n      PropertyGFAParking  SecondLargestPropertyUseTypeGFA  \\\n2091               25200                          25200.0   \n2071               10043                          10043.0   \n964                    0                              0.0   \n2218                   0                          31348.0   \n2737                   0                              0.0   \n...                  ...                              ...   \n3092                   0                              0.0   \n1095                   0                              0.0   \n1130                   0                         181729.0   \n1294                   0                          12344.0   \n860                    0                              0.0   \n\n      ThirdLargestPropertyUseTypeGFA  \n2091                             0.0  \n2071                          5000.0  \n964                              0.0  \n2218                             0.0  \n2737                             0.0  \n...                              ...  \n3092                             0.0  \n1095                             0.0  \n1130                         16415.0  \n1294                             0.0  \n860                              0.0  \n\n[2191 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>YearBuilt</th>\n      <th>BuildingType</th>\n      <th>PrimaryPropertyType</th>\n      <th>Neighborhood</th>\n      <th>NumberofFloors</th>\n      <th>PropertyGFATotal</th>\n      <th>PropertyGFAParking</th>\n      <th>SecondLargestPropertyUseTypeGFA</th>\n      <th>ThirdLargestPropertyUseTypeGFA</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2091</th>\n      <td>1922</td>\n      <td>NonResidential</td>\n      <td>Hotel</td>\n      <td>downtown</td>\n      <td>11</td>\n      <td>92190</td>\n      <td>25200</td>\n      <td>25200.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2071</th>\n      <td>1930</td>\n      <td>NonResidential</td>\n      <td>Hotel</td>\n      <td>downtown</td>\n      <td>20</td>\n      <td>98634</td>\n      <td>10043</td>\n      <td>10043.0</td>\n      <td>5000.0</td>\n    </tr>\n    <tr>\n      <th>964</th>\n      <td>1929</td>\n      <td>Nonresidential COS</td>\n      <td>Other</td>\n      <td>northeast</td>\n      <td>3</td>\n      <td>27908</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2218</th>\n      <td>1970</td>\n      <td>NonResidential</td>\n      <td>Small- and Mid-Sized Office</td>\n      <td>lake union</td>\n      <td>7</td>\n      <td>94002</td>\n      <td>0</td>\n      <td>31348.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2737</th>\n      <td>1929</td>\n      <td>Multifamily LR (1-4)</td>\n      <td>Low-Rise Multifamily</td>\n      <td>magnolia / queen anne</td>\n      <td>3</td>\n      <td>32908</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3092</th>\n      <td>1986</td>\n      <td>NonResidential</td>\n      <td>Small- and Mid-Sized Office</td>\n      <td>magnolia / queen anne</td>\n      <td>3</td>\n      <td>40067</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1095</th>\n      <td>2012</td>\n      <td>Multifamily MR (5-9)</td>\n      <td>Mid-Rise Multifamily</td>\n      <td>northeast</td>\n      <td>7</td>\n      <td>74421</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1130</th>\n      <td>2014</td>\n      <td>Multifamily MR (5-9)</td>\n      <td>Mid-Rise Multifamily</td>\n      <td>ballard</td>\n      <td>8</td>\n      <td>439262</td>\n      <td>0</td>\n      <td>181729.0</td>\n      <td>16415.0</td>\n    </tr>\n    <tr>\n      <th>1294</th>\n      <td>1998</td>\n      <td>Multifamily MR (5-9)</td>\n      <td>Mid-Rise Multifamily</td>\n      <td>east</td>\n      <td>5</td>\n      <td>33274</td>\n      <td>0</td>\n      <td>12344.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>860</th>\n      <td>1970</td>\n      <td>Multifamily MR (5-9)</td>\n      <td>Mid-Rise Multifamily</td>\n      <td>magnolia / queen anne</td>\n      <td>5</td>\n      <td>34480</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>2191 rows × 9 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After\n"
     ]
    },
    {
     "data": {
      "text/plain": "      YearBuilt          BuildingType          PrimaryPropertyType  \\\n2091       1922        NonResidential                        Hotel   \n2071       1930        NonResidential                        Hotel   \n964        1929    Nonresidential COS                        Other   \n2218       1970        NonResidential  Small- and Mid-Sized Office   \n2737       1929  Multifamily LR (1-4)         Low-Rise Multifamily   \n...         ...                   ...                          ...   \n3092       1986        NonResidential  Small- and Mid-Sized Office   \n1095       2012  Multifamily MR (5-9)         Mid-Rise Multifamily   \n1130       2014  Multifamily MR (5-9)         Mid-Rise Multifamily   \n1294       1998  Multifamily MR (5-9)         Mid-Rise Multifamily   \n860        1970  Multifamily MR (5-9)         Mid-Rise Multifamily   \n\n               Neighborhood  NumberofFloors  PropertyGFATotal  \\\n2091               downtown        1.165681          0.028850   \n2071               downtown        2.831097          0.076627   \n964               northeast       -0.314688         -0.447747   \n2218             lake union        0.425496          0.042285   \n2737  magnolia / queen anne       -0.314688         -0.410676   \n...                     ...             ...               ...   \n3092  magnolia / queen anne       -0.314688         -0.357598   \n1095              northeast        0.425496         -0.102892   \n1130                ballard        0.610543          2.602097   \n1294                   east        0.055404         -0.407962   \n860   magnolia / queen anne        0.055404         -0.399021   \n\n      PropertyGFAParking  SecondLargestPropertyUseTypeGFA  \\\n2091            0.499697                         0.311646   \n2071            0.047235                        -0.105775   \n964            -0.252566                        -0.382358   \n2218           -0.252566                         0.480961   \n2737           -0.252566                        -0.382358   \n...                  ...                              ...   \n3092           -0.252566                        -0.382358   \n1095           -0.252566                        -0.382358   \n1130           -0.252566                         4.622429   \n1294           -0.252566                        -0.042406   \n860            -0.252566                        -0.382358   \n\n      ThirdLargestPropertyUseTypeGFA  \n2091                       -0.207072  \n2071                        0.350267  \n964                        -0.207072  \n2218                       -0.207072  \n2737                       -0.207072  \n...                              ...  \n3092                       -0.207072  \n1095                       -0.207072  \n1130                        1.622672  \n1294                       -0.207072  \n860                        -0.207072  \n\n[2191 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>YearBuilt</th>\n      <th>BuildingType</th>\n      <th>PrimaryPropertyType</th>\n      <th>Neighborhood</th>\n      <th>NumberofFloors</th>\n      <th>PropertyGFATotal</th>\n      <th>PropertyGFAParking</th>\n      <th>SecondLargestPropertyUseTypeGFA</th>\n      <th>ThirdLargestPropertyUseTypeGFA</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2091</th>\n      <td>1922</td>\n      <td>NonResidential</td>\n      <td>Hotel</td>\n      <td>downtown</td>\n      <td>1.165681</td>\n      <td>0.028850</td>\n      <td>0.499697</td>\n      <td>0.311646</td>\n      <td>-0.207072</td>\n    </tr>\n    <tr>\n      <th>2071</th>\n      <td>1930</td>\n      <td>NonResidential</td>\n      <td>Hotel</td>\n      <td>downtown</td>\n      <td>2.831097</td>\n      <td>0.076627</td>\n      <td>0.047235</td>\n      <td>-0.105775</td>\n      <td>0.350267</td>\n    </tr>\n    <tr>\n      <th>964</th>\n      <td>1929</td>\n      <td>Nonresidential COS</td>\n      <td>Other</td>\n      <td>northeast</td>\n      <td>-0.314688</td>\n      <td>-0.447747</td>\n      <td>-0.252566</td>\n      <td>-0.382358</td>\n      <td>-0.207072</td>\n    </tr>\n    <tr>\n      <th>2218</th>\n      <td>1970</td>\n      <td>NonResidential</td>\n      <td>Small- and Mid-Sized Office</td>\n      <td>lake union</td>\n      <td>0.425496</td>\n      <td>0.042285</td>\n      <td>-0.252566</td>\n      <td>0.480961</td>\n      <td>-0.207072</td>\n    </tr>\n    <tr>\n      <th>2737</th>\n      <td>1929</td>\n      <td>Multifamily LR (1-4)</td>\n      <td>Low-Rise Multifamily</td>\n      <td>magnolia / queen anne</td>\n      <td>-0.314688</td>\n      <td>-0.410676</td>\n      <td>-0.252566</td>\n      <td>-0.382358</td>\n      <td>-0.207072</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3092</th>\n      <td>1986</td>\n      <td>NonResidential</td>\n      <td>Small- and Mid-Sized Office</td>\n      <td>magnolia / queen anne</td>\n      <td>-0.314688</td>\n      <td>-0.357598</td>\n      <td>-0.252566</td>\n      <td>-0.382358</td>\n      <td>-0.207072</td>\n    </tr>\n    <tr>\n      <th>1095</th>\n      <td>2012</td>\n      <td>Multifamily MR (5-9)</td>\n      <td>Mid-Rise Multifamily</td>\n      <td>northeast</td>\n      <td>0.425496</td>\n      <td>-0.102892</td>\n      <td>-0.252566</td>\n      <td>-0.382358</td>\n      <td>-0.207072</td>\n    </tr>\n    <tr>\n      <th>1130</th>\n      <td>2014</td>\n      <td>Multifamily MR (5-9)</td>\n      <td>Mid-Rise Multifamily</td>\n      <td>ballard</td>\n      <td>0.610543</td>\n      <td>2.602097</td>\n      <td>-0.252566</td>\n      <td>4.622429</td>\n      <td>1.622672</td>\n    </tr>\n    <tr>\n      <th>1294</th>\n      <td>1998</td>\n      <td>Multifamily MR (5-9)</td>\n      <td>Mid-Rise Multifamily</td>\n      <td>east</td>\n      <td>0.055404</td>\n      <td>-0.407962</td>\n      <td>-0.252566</td>\n      <td>-0.042406</td>\n      <td>-0.207072</td>\n    </tr>\n    <tr>\n      <th>860</th>\n      <td>1970</td>\n      <td>Multifamily MR (5-9)</td>\n      <td>Mid-Rise Multifamily</td>\n      <td>magnolia / queen anne</td>\n      <td>0.055404</td>\n      <td>-0.399021</td>\n      <td>-0.252566</td>\n      <td>-0.382358</td>\n      <td>-0.207072</td>\n    </tr>\n  </tbody>\n</table>\n<p>2191 rows × 9 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We train / fit the scaler on the training set / Computes the mean and std to be used for later scaling.\n",
    "std_scale = StandardScaler().fit(X_train[numerical_columns])\n",
    "# We transform the training set and the testing set / Performs standardization by centering and scaling.\n",
    "X_train_std = X_train.copy()\n",
    "X_test_std = X_test.copy()\n",
    "\n",
    "X_train_std[numerical_columns] = std_scale.transform(X_train[numerical_columns])\n",
    "X_test_std[numerical_columns] = std_scale.transform(X_test[numerical_columns])\n",
    "\n",
    "print(\"Before\")\n",
    "display(X_train)\n",
    "print(\"After\")\n",
    "display(X_train_std)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We can check that the numerical variables have a Standard Normal distribution.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\seaborn\\distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\seaborn\\distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\seaborn\\distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\seaborn\\distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\seaborn\\distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORT FUNCTIONS / DENSITE\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 864x1008 with 28 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def densite(df, lines=7, cols=4):\n",
    "    \"\"\"\n",
    "    Input : dataframe, lignes, colonnes\n",
    "    Output : grille des courbes de densités des variables numériques du dataframe\n",
    "    \"\"\"\n",
    "    df = df.select_dtypes(include='number').copy()\n",
    "\n",
    "    fig, ax = plt.subplots(lines, cols, figsize=(min(15, cols * 3), lines * 2))\n",
    "\n",
    "    for i, val in enumerate(df.columns.tolist()):\n",
    "        bp = sns.distplot(df[val], hist=False, ax=ax[i // cols, i % cols], kde_kws={'shade': True})\n",
    "        bp.set_title(\"skewness : \" + str(round(df[val].skew(), 1)), fontsize=12)\n",
    "        bp.set_yticks([])\n",
    "        imax = i\n",
    "\n",
    "    for i in range(imax + 1, lines * cols):\n",
    "        ax[i // cols, i % cols].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "print(\"We can check that the numerical variables have a Standard Normal distribution.\")\n",
    "densite(X_train[numerical_columns])\n",
    "\n",
    "print(\"IMPORT FUNCTIONS / DENSITE\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 2) Feature Encoding : One Hot Encoder"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical variables featuring\n",
      "We have : 3 categorical features to encode.\n",
      "\n",
      "Index(['BuildingType', 'PrimaryPropertyType', 'Neighborhood'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"Categorical variables featuring\")\n",
    "\n",
    "print(\"We have :\", categorical_columns.shape[0], \"categorical features to encode.\", end=\"\\n\\n\")\n",
    "print(categorical_columns)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "YearBuilt                             int64\nBuildingType                       category\nPrimaryPropertyType                category\nNeighborhood                         object\nNumberofFloors                        int64\nPropertyGFATotal                      int64\nPropertyGFAParking                    int64\nSecondLargestPropertyUseTypeGFA     float64\nThirdLargestPropertyUseTypeGFA      float64\ndtype: object"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dtypes # we check that we have categories"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "BuildingType            8\nPrimaryPropertyType    23\nNeighborhood           13\ndtype: int64"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[categorical_columns].nunique()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "              BuildingType          PrimaryPropertyType           Neighborhood\n2091        NonResidential                        Hotel               downtown\n2071        NonResidential                        Hotel               downtown\n964     Nonresidential COS                        Other              northeast\n2218        NonResidential  Small- and Mid-Sized Office             lake union\n2737  Multifamily LR (1-4)         Low-Rise Multifamily  magnolia / queen anne\n...                    ...                          ...                    ...\n3092        NonResidential  Small- and Mid-Sized Office  magnolia / queen anne\n1095  Multifamily MR (5-9)         Mid-Rise Multifamily              northeast\n1130  Multifamily MR (5-9)         Mid-Rise Multifamily                ballard\n1294  Multifamily MR (5-9)         Mid-Rise Multifamily                   east\n860   Multifamily MR (5-9)         Mid-Rise Multifamily  magnolia / queen anne\n\n[2191 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>BuildingType</th>\n      <th>PrimaryPropertyType</th>\n      <th>Neighborhood</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2091</th>\n      <td>NonResidential</td>\n      <td>Hotel</td>\n      <td>downtown</td>\n    </tr>\n    <tr>\n      <th>2071</th>\n      <td>NonResidential</td>\n      <td>Hotel</td>\n      <td>downtown</td>\n    </tr>\n    <tr>\n      <th>964</th>\n      <td>Nonresidential COS</td>\n      <td>Other</td>\n      <td>northeast</td>\n    </tr>\n    <tr>\n      <th>2218</th>\n      <td>NonResidential</td>\n      <td>Small- and Mid-Sized Office</td>\n      <td>lake union</td>\n    </tr>\n    <tr>\n      <th>2737</th>\n      <td>Multifamily LR (1-4)</td>\n      <td>Low-Rise Multifamily</td>\n      <td>magnolia / queen anne</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3092</th>\n      <td>NonResidential</td>\n      <td>Small- and Mid-Sized Office</td>\n      <td>magnolia / queen anne</td>\n    </tr>\n    <tr>\n      <th>1095</th>\n      <td>Multifamily MR (5-9)</td>\n      <td>Mid-Rise Multifamily</td>\n      <td>northeast</td>\n    </tr>\n    <tr>\n      <th>1130</th>\n      <td>Multifamily MR (5-9)</td>\n      <td>Mid-Rise Multifamily</td>\n      <td>ballard</td>\n    </tr>\n    <tr>\n      <th>1294</th>\n      <td>Multifamily MR (5-9)</td>\n      <td>Mid-Rise Multifamily</td>\n      <td>east</td>\n    </tr>\n    <tr>\n      <th>860</th>\n      <td>Multifamily MR (5-9)</td>\n      <td>Mid-Rise Multifamily</td>\n      <td>magnolia / queen anne</td>\n    </tr>\n  </tbody>\n</table>\n<p>2191 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_std[categorical_columns]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Encoding the categorical features of the train set\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now, we can use the One Hot Encoder.\n",
      "With the one hot encoder, we will get : 44 columns to encodes the categorical features.\n"
     ]
    }
   ],
   "source": [
    "print(\"Now, we can use the One Hot Encoder.\")\n",
    "print(\"With the one hot encoder, we will get :\", sum([X[categorical_columns].nunique()[i] for i in range(len(categorical_columns))]), \"columns to encodes the categorical features.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have indeed : 44 labels after encoding the categorical variables.\n"
     ]
    },
    {
     "data": {
      "text/plain": "      BuildingType_Campus  BuildingType_Multifamily HR (10+)  \\\n1                     0.0                                0.0   \n2                     0.0                                0.0   \n3                     0.0                                1.0   \n4                     0.0                                0.0   \n5                     0.0                                0.0   \n...                   ...                                ...   \n3124                  0.0                                0.0   \n3125                  0.0                                0.0   \n3126                  0.0                                0.0   \n3128                  0.0                                0.0   \n3129                  0.0                                0.0   \n\n      BuildingType_Multifamily LR (1-4)  BuildingType_Multifamily MR (5-9)  \\\n1                                   0.0                                0.0   \n2                                   1.0                                0.0   \n3                                   0.0                                0.0   \n4                                   1.0                                0.0   \n5                                   0.0                                0.0   \n...                                 ...                                ...   \n3124                                0.0                                1.0   \n3125                                0.0                                0.0   \n3126                                0.0                                0.0   \n3128                                0.0                                0.0   \n3129                                0.0                                0.0   \n\n      BuildingType_NonResidential  BuildingType_Nonresidential COS  \\\n1                             1.0                              0.0   \n2                             0.0                              0.0   \n3                             0.0                              0.0   \n4                             0.0                              0.0   \n5                             1.0                              0.0   \n...                           ...                              ...   \n3124                          0.0                              0.0   \n3125                          1.0                              0.0   \n3126                          1.0                              0.0   \n3128                          1.0                              0.0   \n3129                          1.0                              0.0   \n\n      BuildingType_Nonresidential WA  BuildingType_SPS-District K-12  \\\n1                                0.0                             0.0   \n2                                0.0                             0.0   \n3                                0.0                             0.0   \n4                                0.0                             0.0   \n5                                0.0                             0.0   \n...                              ...                             ...   \n3124                             0.0                             0.0   \n3125                             0.0                             0.0   \n3126                             0.0                             0.0   \n3128                             0.0                             0.0   \n3129                             0.0                             0.0   \n\n      PrimaryPropertyType_Distribution Center  \\\n1                                         0.0   \n2                                         0.0   \n3                                         0.0   \n4                                         0.0   \n5                                         0.0   \n...                                       ...   \n3124                                      0.0   \n3125                                      0.0   \n3126                                      0.0   \n3128                                      0.0   \n3129                                      0.0   \n\n      PrimaryPropertyType_High-Rise Multifamily  ...  Neighborhood_downtown  \\\n1                                           0.0  ...                    0.0   \n2                                           0.0  ...                    0.0   \n3                                           1.0  ...                    0.0   \n4                                           0.0  ...                    0.0   \n5                                           0.0  ...                    0.0   \n...                                         ...  ...                    ...   \n3124                                        0.0  ...                    0.0   \n3125                                        0.0  ...                    0.0   \n3126                                        0.0  ...                    0.0   \n3128                                        0.0  ...                    0.0   \n3129                                        0.0  ...                    0.0   \n\n      Neighborhood_east  Neighborhood_greater duwamish  \\\n1                   0.0                            1.0   \n2                   0.0                            1.0   \n3                   0.0                            1.0   \n4                   0.0                            1.0   \n5                   0.0                            0.0   \n...                 ...                            ...   \n3124                1.0                            0.0   \n3125                0.0                            0.0   \n3126                0.0                            0.0   \n3128                0.0                            0.0   \n3129                0.0                            0.0   \n\n      Neighborhood_lake union  Neighborhood_magnolia / queen anne  \\\n1                         0.0                                 0.0   \n2                         0.0                                 0.0   \n3                         0.0                                 0.0   \n4                         0.0                                 0.0   \n5                         0.0                                 0.0   \n...                       ...                                 ...   \n3124                      0.0                                 0.0   \n3125                      1.0                                 0.0   \n3126                      1.0                                 0.0   \n3128                      1.0                                 0.0   \n3129                      1.0                                 0.0   \n\n      Neighborhood_north  Neighborhood_northeast  Neighborhood_northwest  \\\n1                    0.0                     0.0                     0.0   \n2                    0.0                     0.0                     0.0   \n3                    0.0                     0.0                     0.0   \n4                    0.0                     0.0                     0.0   \n5                    0.0                     1.0                     0.0   \n...                  ...                     ...                     ...   \n3124                 0.0                     0.0                     0.0   \n3125                 0.0                     0.0                     0.0   \n3126                 0.0                     0.0                     0.0   \n3128                 0.0                     0.0                     0.0   \n3129                 0.0                     0.0                     0.0   \n\n      Neighborhood_southeast  Neighborhood_southwest  \n1                        0.0                     0.0  \n2                        0.0                     0.0  \n3                        0.0                     0.0  \n4                        0.0                     0.0  \n5                        0.0                     0.0  \n...                      ...                     ...  \n3124                     0.0                     0.0  \n3125                     0.0                     0.0  \n3126                     0.0                     0.0  \n3128                     0.0                     0.0  \n3129                     0.0                     0.0  \n\n[2191 rows x 44 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>BuildingType_Campus</th>\n      <th>BuildingType_Multifamily HR (10+)</th>\n      <th>BuildingType_Multifamily LR (1-4)</th>\n      <th>BuildingType_Multifamily MR (5-9)</th>\n      <th>BuildingType_NonResidential</th>\n      <th>BuildingType_Nonresidential COS</th>\n      <th>BuildingType_Nonresidential WA</th>\n      <th>BuildingType_SPS-District K-12</th>\n      <th>PrimaryPropertyType_Distribution Center</th>\n      <th>PrimaryPropertyType_High-Rise Multifamily</th>\n      <th>...</th>\n      <th>Neighborhood_downtown</th>\n      <th>Neighborhood_east</th>\n      <th>Neighborhood_greater duwamish</th>\n      <th>Neighborhood_lake union</th>\n      <th>Neighborhood_magnolia / queen anne</th>\n      <th>Neighborhood_north</th>\n      <th>Neighborhood_northeast</th>\n      <th>Neighborhood_northwest</th>\n      <th>Neighborhood_southeast</th>\n      <th>Neighborhood_southwest</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3124</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3125</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3126</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3128</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3129</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>2191 rows × 44 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 0) creating instance of one-hot-encoder\n",
    "one_hot_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False) # if sparse=True (by default), we need to add .toarray() to encoded_categorical_data\n",
    "\n",
    "# 1) Fit the encoder on the training set\n",
    "one_hot_encoder.fit(X_train_std[categorical_columns])\n",
    "\n",
    "# 2) we get the encoded numpy array\n",
    "encoded_categorical_data = one_hot_encoder.transform(X_train_std[categorical_columns])\n",
    "\n",
    "# 3) we make a list of the columns names\n",
    "encoded_categorical_data_names = one_hot_encoder.get_feature_names_out().tolist()\n",
    "print(\"We have indeed :\", len(encoded_categorical_data_names), \"labels after encoding the categorical variables.\")\n",
    "\n",
    "# 4) we recreate a dataframe with the column names and the numpy array\n",
    "X_train_encoded = pd.DataFrame(columns=encoded_categorical_data_names,\n",
    "                               data=encoded_categorical_data,\n",
    "                               index=X_train_std.index)\n",
    "display(X_train_encoded.sort_index())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We need to add YearBuilt to the list of features.\n",
      "['NumberofFloors', 'PropertyGFATotal', 'PropertyGFAParking', 'SecondLargestPropertyUseTypeGFA', 'ThirdLargestPropertyUseTypeGFA', 'YearBuilt']\n",
      "\n",
      "ASK JEREMY : merge based on index ok ? or should I put back OSEBuildingID ??\n"
     ]
    },
    {
     "data": {
      "text/plain": "      NumberofFloors  PropertyGFATotal  PropertyGFAParking  \\\n1          -0.499734         -0.462226           -0.252566   \n2          -0.314688         -0.468417           -0.252566   \n3           1.905866         -0.106769           -0.252566   \n4          -0.314688         -0.384912           -0.042709   \n5          -0.129642         -0.365813           -0.252566   \n...              ...               ...                 ...   \n3124        0.055404         -0.264528           -0.252566   \n3125       -0.499734         -0.403766           -0.252566   \n3126       -0.314688         -0.344549            0.022846   \n3128        0.055404         -0.404507           -0.073157   \n3129       -0.499734         -0.502552           -0.252566   \n\n      SecondLargestPropertyUseTypeGFA  ThirdLargestPropertyUseTypeGFA  \\\n1                           -0.141522                        0.134019   \n2                           -0.382358                       -0.207072   \n3                           -0.382358                       -0.207072   \n4                           -0.266691                       -0.207072   \n5                           -0.382358                       -0.207072   \n...                               ...                             ...   \n3124                        -0.382358                       -0.207072   \n3125                        -0.006164                       -0.046558   \n3126                         0.006725                        0.871936   \n3128                        -0.141054                       -0.039870   \n3129                        -0.162039                       -0.207072   \n\n      YearBuilt  BuildingType_Campus  BuildingType_Multifamily HR (10+)  \\\n1          1928                  0.0                                0.0   \n2          1925                  0.0                                0.0   \n3          1971                  0.0                                1.0   \n4          2001                  0.0                                0.0   \n5          1996                  0.0                                0.0   \n...         ...                  ...                                ...   \n3124       1925                  0.0                                0.0   \n3125       1927                  0.0                                0.0   \n3126       2001                  0.0                                0.0   \n3128       2001                  0.0                                0.0   \n3129       1911                  0.0                                0.0   \n\n      BuildingType_Multifamily LR (1-4)  BuildingType_Multifamily MR (5-9)  \\\n1                                   0.0                                0.0   \n2                                   1.0                                0.0   \n3                                   0.0                                0.0   \n4                                   1.0                                0.0   \n5                                   0.0                                0.0   \n...                                 ...                                ...   \n3124                                0.0                                1.0   \n3125                                0.0                                0.0   \n3126                                0.0                                0.0   \n3128                                0.0                                0.0   \n3129                                0.0                                0.0   \n\n      ...  Neighborhood_downtown  Neighborhood_east  \\\n1     ...                    0.0                0.0   \n2     ...                    0.0                0.0   \n3     ...                    0.0                0.0   \n4     ...                    0.0                0.0   \n5     ...                    0.0                0.0   \n...   ...                    ...                ...   \n3124  ...                    0.0                1.0   \n3125  ...                    0.0                0.0   \n3126  ...                    0.0                0.0   \n3128  ...                    0.0                0.0   \n3129  ...                    0.0                0.0   \n\n      Neighborhood_greater duwamish  Neighborhood_lake union  \\\n1                               1.0                      0.0   \n2                               1.0                      0.0   \n3                               1.0                      0.0   \n4                               1.0                      0.0   \n5                               0.0                      0.0   \n...                             ...                      ...   \n3124                            0.0                      0.0   \n3125                            0.0                      1.0   \n3126                            0.0                      1.0   \n3128                            0.0                      1.0   \n3129                            0.0                      1.0   \n\n      Neighborhood_magnolia / queen anne  Neighborhood_north  \\\n1                                    0.0                 0.0   \n2                                    0.0                 0.0   \n3                                    0.0                 0.0   \n4                                    0.0                 0.0   \n5                                    0.0                 0.0   \n...                                  ...                 ...   \n3124                                 0.0                 0.0   \n3125                                 0.0                 0.0   \n3126                                 0.0                 0.0   \n3128                                 0.0                 0.0   \n3129                                 0.0                 0.0   \n\n      Neighborhood_northeast  Neighborhood_northwest  Neighborhood_southeast  \\\n1                        0.0                     0.0                     0.0   \n2                        0.0                     0.0                     0.0   \n3                        0.0                     0.0                     0.0   \n4                        0.0                     0.0                     0.0   \n5                        1.0                     0.0                     0.0   \n...                      ...                     ...                     ...   \n3124                     0.0                     0.0                     0.0   \n3125                     0.0                     0.0                     0.0   \n3126                     0.0                     0.0                     0.0   \n3128                     0.0                     0.0                     0.0   \n3129                     0.0                     0.0                     0.0   \n\n      Neighborhood_southwest  \n1                        0.0  \n2                        0.0  \n3                        0.0  \n4                        0.0  \n5                        0.0  \n...                      ...  \n3124                     0.0  \n3125                     0.0  \n3126                     0.0  \n3128                     0.0  \n3129                     0.0  \n\n[2191 rows x 50 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>NumberofFloors</th>\n      <th>PropertyGFATotal</th>\n      <th>PropertyGFAParking</th>\n      <th>SecondLargestPropertyUseTypeGFA</th>\n      <th>ThirdLargestPropertyUseTypeGFA</th>\n      <th>YearBuilt</th>\n      <th>BuildingType_Campus</th>\n      <th>BuildingType_Multifamily HR (10+)</th>\n      <th>BuildingType_Multifamily LR (1-4)</th>\n      <th>BuildingType_Multifamily MR (5-9)</th>\n      <th>...</th>\n      <th>Neighborhood_downtown</th>\n      <th>Neighborhood_east</th>\n      <th>Neighborhood_greater duwamish</th>\n      <th>Neighborhood_lake union</th>\n      <th>Neighborhood_magnolia / queen anne</th>\n      <th>Neighborhood_north</th>\n      <th>Neighborhood_northeast</th>\n      <th>Neighborhood_northwest</th>\n      <th>Neighborhood_southeast</th>\n      <th>Neighborhood_southwest</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>-0.499734</td>\n      <td>-0.462226</td>\n      <td>-0.252566</td>\n      <td>-0.141522</td>\n      <td>0.134019</td>\n      <td>1928</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.314688</td>\n      <td>-0.468417</td>\n      <td>-0.252566</td>\n      <td>-0.382358</td>\n      <td>-0.207072</td>\n      <td>1925</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.905866</td>\n      <td>-0.106769</td>\n      <td>-0.252566</td>\n      <td>-0.382358</td>\n      <td>-0.207072</td>\n      <td>1971</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.314688</td>\n      <td>-0.384912</td>\n      <td>-0.042709</td>\n      <td>-0.266691</td>\n      <td>-0.207072</td>\n      <td>2001</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>-0.129642</td>\n      <td>-0.365813</td>\n      <td>-0.252566</td>\n      <td>-0.382358</td>\n      <td>-0.207072</td>\n      <td>1996</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3124</th>\n      <td>0.055404</td>\n      <td>-0.264528</td>\n      <td>-0.252566</td>\n      <td>-0.382358</td>\n      <td>-0.207072</td>\n      <td>1925</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3125</th>\n      <td>-0.499734</td>\n      <td>-0.403766</td>\n      <td>-0.252566</td>\n      <td>-0.006164</td>\n      <td>-0.046558</td>\n      <td>1927</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3126</th>\n      <td>-0.314688</td>\n      <td>-0.344549</td>\n      <td>0.022846</td>\n      <td>0.006725</td>\n      <td>0.871936</td>\n      <td>2001</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3128</th>\n      <td>0.055404</td>\n      <td>-0.404507</td>\n      <td>-0.073157</td>\n      <td>-0.141054</td>\n      <td>-0.039870</td>\n      <td>2001</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3129</th>\n      <td>-0.499734</td>\n      <td>-0.502552</td>\n      <td>-0.252566</td>\n      <td>-0.162039</td>\n      <td>-0.207072</td>\n      <td>1911</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>2191 rows × 50 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 5) Concatenate the two dataframes for the training set\n",
    "\n",
    "print(\"We need to add YearBuilt to the list of features.\")\n",
    "numerical_columns.tolist()\n",
    "features_to_merge = numerical_columns.tolist().copy()\n",
    "features_to_merge.append(\"YearBuilt\")\n",
    "print(features_to_merge, end=\"\\n\\n\")\n",
    "\n",
    "print(\"ASK JEREMY : merge based on index ok ? or should I put back OSEBuildingID ??\")\n",
    "X_train_std_encoded = pd.merge(X_train_std[features_to_merge].sort_index(), X_train_encoded.sort_index(), left_index=True, right_index=True)\n",
    "display(X_train_std_encoded.sort_index())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Encoding the categorical features of the test set"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASK JEREMY for this method below ???\n"
     ]
    },
    {
     "data": {
      "text/plain": "      BuildingType_Campus  BuildingType_Multifamily HR (10+)  \\\n0                     0.0                                0.0   \n7                     0.0                                0.0   \n12                    0.0                                0.0   \n14                    0.0                                0.0   \n17                    0.0                                0.0   \n...                   ...                                ...   \n3116                  0.0                                0.0   \n3118                  0.0                                0.0   \n3121                  0.0                                0.0   \n3127                  0.0                                0.0   \n3130                  0.0                                0.0   \n\n      BuildingType_Multifamily LR (1-4)  BuildingType_Multifamily MR (5-9)  \\\n0                                   1.0                                0.0   \n7                                   1.0                                0.0   \n12                                  0.0                                0.0   \n14                                  1.0                                0.0   \n17                                  0.0                                0.0   \n...                                 ...                                ...   \n3116                                0.0                                1.0   \n3118                                0.0                                1.0   \n3121                                0.0                                0.0   \n3127                                1.0                                0.0   \n3130                                0.0                                0.0   \n\n      BuildingType_NonResidential  BuildingType_Nonresidential COS  \\\n0                             0.0                              0.0   \n7                             0.0                              0.0   \n12                            1.0                              0.0   \n14                            0.0                              0.0   \n17                            1.0                              0.0   \n...                           ...                              ...   \n3116                          0.0                              0.0   \n3118                          0.0                              0.0   \n3121                          1.0                              0.0   \n3127                          0.0                              0.0   \n3130                          0.0                              1.0   \n\n      BuildingType_Nonresidential WA  BuildingType_SPS-District K-12  \\\n0                                0.0                             0.0   \n7                                0.0                             0.0   \n12                               0.0                             0.0   \n14                               0.0                             0.0   \n17                               0.0                             0.0   \n...                              ...                             ...   \n3116                             0.0                             0.0   \n3118                             0.0                             0.0   \n3121                             0.0                             0.0   \n3127                             0.0                             0.0   \n3130                             0.0                             0.0   \n\n      PrimaryPropertyType_Distribution Center  \\\n0                                         0.0   \n7                                         0.0   \n12                                        0.0   \n14                                        0.0   \n17                                        0.0   \n...                                       ...   \n3116                                      0.0   \n3118                                      0.0   \n3121                                      0.0   \n3127                                      0.0   \n3130                                      0.0   \n\n      PrimaryPropertyType_High-Rise Multifamily  ...  Neighborhood_downtown  \\\n0                                           0.0  ...                    0.0   \n7                                           0.0  ...                    0.0   \n12                                          0.0  ...                    1.0   \n14                                          0.0  ...                    0.0   \n17                                          0.0  ...                    0.0   \n...                                         ...  ...                    ...   \n3116                                        0.0  ...                    1.0   \n3118                                        0.0  ...                    1.0   \n3121                                        0.0  ...                    0.0   \n3127                                        0.0  ...                    0.0   \n3130                                        0.0  ...                    0.0   \n\n      Neighborhood_east  Neighborhood_greater duwamish  \\\n0                   0.0                            0.0   \n7                   0.0                            0.0   \n12                  0.0                            0.0   \n14                  0.0                            0.0   \n17                  0.0                            0.0   \n...                 ...                            ...   \n3116                0.0                            0.0   \n3118                0.0                            0.0   \n3121                1.0                            0.0   \n3127                0.0                            0.0   \n3130                0.0                            1.0   \n\n      Neighborhood_lake union  Neighborhood_magnolia / queen anne  \\\n0                         0.0                                 0.0   \n7                         0.0                                 0.0   \n12                        0.0                                 0.0   \n14                        0.0                                 0.0   \n17                        0.0                                 0.0   \n...                       ...                                 ...   \n3116                      0.0                                 0.0   \n3118                      0.0                                 0.0   \n3121                      0.0                                 0.0   \n3127                      1.0                                 0.0   \n3130                      0.0                                 0.0   \n\n      Neighborhood_north  Neighborhood_northeast  Neighborhood_northwest  \\\n0                    0.0                     0.0                     0.0   \n7                    0.0                     1.0                     0.0   \n12                   0.0                     0.0                     0.0   \n14                   0.0                     0.0                     0.0   \n17                   0.0                     0.0                     0.0   \n...                  ...                     ...                     ...   \n3116                 0.0                     0.0                     0.0   \n3118                 0.0                     0.0                     0.0   \n3121                 0.0                     0.0                     0.0   \n3127                 0.0                     0.0                     0.0   \n3130                 0.0                     0.0                     0.0   \n\n      Neighborhood_southeast  Neighborhood_southwest  \n0                        0.0                     0.0  \n7                        0.0                     0.0  \n12                       0.0                     0.0  \n14                       0.0                     0.0  \n17                       0.0                     0.0  \n...                      ...                     ...  \n3116                     0.0                     0.0  \n3118                     0.0                     0.0  \n3121                     0.0                     0.0  \n3127                     0.0                     0.0  \n3130                     0.0                     0.0  \n\n[940 rows x 44 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>BuildingType_Campus</th>\n      <th>BuildingType_Multifamily HR (10+)</th>\n      <th>BuildingType_Multifamily LR (1-4)</th>\n      <th>BuildingType_Multifamily MR (5-9)</th>\n      <th>BuildingType_NonResidential</th>\n      <th>BuildingType_Nonresidential COS</th>\n      <th>BuildingType_Nonresidential WA</th>\n      <th>BuildingType_SPS-District K-12</th>\n      <th>PrimaryPropertyType_Distribution Center</th>\n      <th>PrimaryPropertyType_High-Rise Multifamily</th>\n      <th>...</th>\n      <th>Neighborhood_downtown</th>\n      <th>Neighborhood_east</th>\n      <th>Neighborhood_greater duwamish</th>\n      <th>Neighborhood_lake union</th>\n      <th>Neighborhood_magnolia / queen anne</th>\n      <th>Neighborhood_north</th>\n      <th>Neighborhood_northeast</th>\n      <th>Neighborhood_northwest</th>\n      <th>Neighborhood_southeast</th>\n      <th>Neighborhood_southwest</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3116</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3118</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3121</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3127</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3130</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>940 rows × 44 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASK JEREMY : merge based on index ok ? or should I put back OSEBuildingID ??\n"
     ]
    },
    {
     "data": {
      "text/plain": "      NumberofFloors  PropertyGFATotal  PropertyGFAParking  \\\n0          -0.314688         -0.500899           -0.252566   \n7          -0.314688          0.240235           -0.252566   \n12         -0.499734         -0.299056            0.385783   \n14         -0.129642          0.514730           -0.252566   \n17         -0.684781         -0.427565           -0.252566   \n...              ...               ...                 ...   \n3116        0.240450          0.064364           -0.252566   \n3118        0.055404         -0.413997           -0.252566   \n3121       -0.129642         -0.359874           -0.252566   \n3127       -0.129642         -0.382858           -0.252566   \n3130       -0.684781         -0.519293           -0.252566   \n\n      SecondLargestPropertyUseTypeGFA  ThirdLargestPropertyUseTypeGFA  \\\n0                           -0.382358                       -0.207072   \n7                            0.043078                       -0.207072   \n12                          -0.217119                       -0.207072   \n14                           0.201569                        0.245487   \n17                          -0.315106                       -0.207072   \n...                               ...                             ...   \n3116                        -0.382358                       -0.207072   \n3118                        -0.382358                       -0.207072   \n3121                        -0.382358                       -0.207072   \n3127                        -0.382358                       -0.207072   \n3130                        -0.162039                       -0.083566   \n\n      YearBuilt  BuildingType_Campus  BuildingType_Multifamily HR (10+)  \\\n0          1978                  0.0                                0.0   \n7          1977                  0.0                                0.0   \n12         1991                  0.0                                0.0   \n14         2010                  0.0                                0.0   \n17         1980                  0.0                                0.0   \n...         ...                  ...                                ...   \n3116       2007                  0.0                                0.0   \n3118       1915                  0.0                                0.0   \n3121       1925                  0.0                                0.0   \n3127       1907                  0.0                                0.0   \n3130       1938                  0.0                                0.0   \n\n      BuildingType_Multifamily LR (1-4)  BuildingType_Multifamily MR (5-9)  \\\n0                                   1.0                                0.0   \n7                                   1.0                                0.0   \n12                                  0.0                                0.0   \n14                                  1.0                                0.0   \n17                                  0.0                                0.0   \n...                                 ...                                ...   \n3116                                0.0                                1.0   \n3118                                0.0                                1.0   \n3121                                0.0                                0.0   \n3127                                1.0                                0.0   \n3130                                0.0                                0.0   \n\n      ...  Neighborhood_downtown  Neighborhood_east  \\\n0     ...                    0.0                0.0   \n7     ...                    0.0                0.0   \n12    ...                    1.0                0.0   \n14    ...                    0.0                0.0   \n17    ...                    0.0                0.0   \n...   ...                    ...                ...   \n3116  ...                    1.0                0.0   \n3118  ...                    1.0                0.0   \n3121  ...                    0.0                1.0   \n3127  ...                    0.0                0.0   \n3130  ...                    0.0                0.0   \n\n      Neighborhood_greater duwamish  Neighborhood_lake union  \\\n0                               0.0                      0.0   \n7                               0.0                      0.0   \n12                              0.0                      0.0   \n14                              0.0                      0.0   \n17                              0.0                      0.0   \n...                             ...                      ...   \n3116                            0.0                      0.0   \n3118                            0.0                      0.0   \n3121                            0.0                      0.0   \n3127                            0.0                      1.0   \n3130                            1.0                      0.0   \n\n      Neighborhood_magnolia / queen anne  Neighborhood_north  \\\n0                                    0.0                 0.0   \n7                                    0.0                 0.0   \n12                                   0.0                 0.0   \n14                                   0.0                 0.0   \n17                                   0.0                 0.0   \n...                                  ...                 ...   \n3116                                 0.0                 0.0   \n3118                                 0.0                 0.0   \n3121                                 0.0                 0.0   \n3127                                 0.0                 0.0   \n3130                                 0.0                 0.0   \n\n      Neighborhood_northeast  Neighborhood_northwest  Neighborhood_southeast  \\\n0                        0.0                     0.0                     0.0   \n7                        1.0                     0.0                     0.0   \n12                       0.0                     0.0                     0.0   \n14                       0.0                     0.0                     0.0   \n17                       0.0                     0.0                     0.0   \n...                      ...                     ...                     ...   \n3116                     0.0                     0.0                     0.0   \n3118                     0.0                     0.0                     0.0   \n3121                     0.0                     0.0                     0.0   \n3127                     0.0                     0.0                     0.0   \n3130                     0.0                     0.0                     0.0   \n\n      Neighborhood_southwest  \n0                        0.0  \n7                        0.0  \n12                       0.0  \n14                       0.0  \n17                       0.0  \n...                      ...  \n3116                     0.0  \n3118                     0.0  \n3121                     0.0  \n3127                     0.0  \n3130                     0.0  \n\n[940 rows x 50 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>NumberofFloors</th>\n      <th>PropertyGFATotal</th>\n      <th>PropertyGFAParking</th>\n      <th>SecondLargestPropertyUseTypeGFA</th>\n      <th>ThirdLargestPropertyUseTypeGFA</th>\n      <th>YearBuilt</th>\n      <th>BuildingType_Campus</th>\n      <th>BuildingType_Multifamily HR (10+)</th>\n      <th>BuildingType_Multifamily LR (1-4)</th>\n      <th>BuildingType_Multifamily MR (5-9)</th>\n      <th>...</th>\n      <th>Neighborhood_downtown</th>\n      <th>Neighborhood_east</th>\n      <th>Neighborhood_greater duwamish</th>\n      <th>Neighborhood_lake union</th>\n      <th>Neighborhood_magnolia / queen anne</th>\n      <th>Neighborhood_north</th>\n      <th>Neighborhood_northeast</th>\n      <th>Neighborhood_northwest</th>\n      <th>Neighborhood_southeast</th>\n      <th>Neighborhood_southwest</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.314688</td>\n      <td>-0.500899</td>\n      <td>-0.252566</td>\n      <td>-0.382358</td>\n      <td>-0.207072</td>\n      <td>1978</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>-0.314688</td>\n      <td>0.240235</td>\n      <td>-0.252566</td>\n      <td>0.043078</td>\n      <td>-0.207072</td>\n      <td>1977</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>-0.499734</td>\n      <td>-0.299056</td>\n      <td>0.385783</td>\n      <td>-0.217119</td>\n      <td>-0.207072</td>\n      <td>1991</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>-0.129642</td>\n      <td>0.514730</td>\n      <td>-0.252566</td>\n      <td>0.201569</td>\n      <td>0.245487</td>\n      <td>2010</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>-0.684781</td>\n      <td>-0.427565</td>\n      <td>-0.252566</td>\n      <td>-0.315106</td>\n      <td>-0.207072</td>\n      <td>1980</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3116</th>\n      <td>0.240450</td>\n      <td>0.064364</td>\n      <td>-0.252566</td>\n      <td>-0.382358</td>\n      <td>-0.207072</td>\n      <td>2007</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3118</th>\n      <td>0.055404</td>\n      <td>-0.413997</td>\n      <td>-0.252566</td>\n      <td>-0.382358</td>\n      <td>-0.207072</td>\n      <td>1915</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3121</th>\n      <td>-0.129642</td>\n      <td>-0.359874</td>\n      <td>-0.252566</td>\n      <td>-0.382358</td>\n      <td>-0.207072</td>\n      <td>1925</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3127</th>\n      <td>-0.129642</td>\n      <td>-0.382858</td>\n      <td>-0.252566</td>\n      <td>-0.382358</td>\n      <td>-0.207072</td>\n      <td>1907</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3130</th>\n      <td>-0.684781</td>\n      <td>-0.519293</td>\n      <td>-0.252566</td>\n      <td>-0.162039</td>\n      <td>-0.083566</td>\n      <td>1938</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>940 rows × 50 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 5) One Hot Encoding on the testing set\n",
    "\n",
    "# 5.1) we get the encoded numpy array\n",
    "TEST_encoded_categorical_data = one_hot_encoder.transform(X_test_std[categorical_columns])\n",
    "\n",
    "print(\"ASK JEREMY for this method below ???\")\n",
    "# 5.2) we recreate a dataframe with the column names and the numpy array\n",
    "X_test_encoded = pd.DataFrame(columns=encoded_categorical_data_names,\n",
    "                               data=TEST_encoded_categorical_data,\n",
    "                               index=X_test_std.index)\n",
    "display(X_test_encoded.sort_index())\n",
    "\n",
    "print(\"ASK JEREMY : merge based on index ok ? or should I put back OSEBuildingID ??\")\n",
    "X_test_std_encoded = pd.merge(X_test_std[features_to_merge].sort_index(), X_test_encoded.sort_index(), left_index=True, right_index=True)\n",
    "display(X_test_std_encoded.sort_index())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Save\n",
    "X_train_std_encoded.to_csv(\"dataset/cleaned/electricity/X_train.csv\", index=False)\n",
    "X_test_std_encoded.to_csv(\"dataset/cleaned/electricity/X_test.csv\", index=False)\n",
    "y_train.to_csv(\"dataset/cleaned/electricity/y_train.csv\", index=False)\n",
    "y_test.to_csv(\"dataset/cleaned/electricity/y_test.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## II) Modelisation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We can start now the modelling to predict the feature wanted.\n"
     ]
    },
    {
     "data": {
      "text/plain": "      NumberofFloors  PropertyGFATotal  PropertyGFAParking  \\\n1          -0.499734         -0.462226           -0.252566   \n2          -0.314688         -0.468417           -0.252566   \n3           1.905866         -0.106769           -0.252566   \n4          -0.314688         -0.384912           -0.042709   \n5          -0.129642         -0.365813           -0.252566   \n...              ...               ...                 ...   \n3124        0.055404         -0.264528           -0.252566   \n3125       -0.499734         -0.403766           -0.252566   \n3126       -0.314688         -0.344549            0.022846   \n3128        0.055404         -0.404507           -0.073157   \n3129       -0.499734         -0.502552           -0.252566   \n\n      SecondLargestPropertyUseTypeGFA  ThirdLargestPropertyUseTypeGFA  \\\n1                           -0.141522                        0.134019   \n2                           -0.382358                       -0.207072   \n3                           -0.382358                       -0.207072   \n4                           -0.266691                       -0.207072   \n5                           -0.382358                       -0.207072   \n...                               ...                             ...   \n3124                        -0.382358                       -0.207072   \n3125                        -0.006164                       -0.046558   \n3126                         0.006725                        0.871936   \n3128                        -0.141054                       -0.039870   \n3129                        -0.162039                       -0.207072   \n\n      YearBuilt  BuildingType_Campus  BuildingType_Multifamily HR (10+)  \\\n1          1928                  0.0                                0.0   \n2          1925                  0.0                                0.0   \n3          1971                  0.0                                1.0   \n4          2001                  0.0                                0.0   \n5          1996                  0.0                                0.0   \n...         ...                  ...                                ...   \n3124       1925                  0.0                                0.0   \n3125       1927                  0.0                                0.0   \n3126       2001                  0.0                                0.0   \n3128       2001                  0.0                                0.0   \n3129       1911                  0.0                                0.0   \n\n      BuildingType_Multifamily LR (1-4)  BuildingType_Multifamily MR (5-9)  \\\n1                                   0.0                                0.0   \n2                                   1.0                                0.0   \n3                                   0.0                                0.0   \n4                                   1.0                                0.0   \n5                                   0.0                                0.0   \n...                                 ...                                ...   \n3124                                0.0                                1.0   \n3125                                0.0                                0.0   \n3126                                0.0                                0.0   \n3128                                0.0                                0.0   \n3129                                0.0                                0.0   \n\n      ...  Neighborhood_downtown  Neighborhood_east  \\\n1     ...                    0.0                0.0   \n2     ...                    0.0                0.0   \n3     ...                    0.0                0.0   \n4     ...                    0.0                0.0   \n5     ...                    0.0                0.0   \n...   ...                    ...                ...   \n3124  ...                    0.0                1.0   \n3125  ...                    0.0                0.0   \n3126  ...                    0.0                0.0   \n3128  ...                    0.0                0.0   \n3129  ...                    0.0                0.0   \n\n      Neighborhood_greater duwamish  Neighborhood_lake union  \\\n1                               1.0                      0.0   \n2                               1.0                      0.0   \n3                               1.0                      0.0   \n4                               1.0                      0.0   \n5                               0.0                      0.0   \n...                             ...                      ...   \n3124                            0.0                      0.0   \n3125                            0.0                      1.0   \n3126                            0.0                      1.0   \n3128                            0.0                      1.0   \n3129                            0.0                      1.0   \n\n      Neighborhood_magnolia / queen anne  Neighborhood_north  \\\n1                                    0.0                 0.0   \n2                                    0.0                 0.0   \n3                                    0.0                 0.0   \n4                                    0.0                 0.0   \n5                                    0.0                 0.0   \n...                                  ...                 ...   \n3124                                 0.0                 0.0   \n3125                                 0.0                 0.0   \n3126                                 0.0                 0.0   \n3128                                 0.0                 0.0   \n3129                                 0.0                 0.0   \n\n      Neighborhood_northeast  Neighborhood_northwest  Neighborhood_southeast  \\\n1                        0.0                     0.0                     0.0   \n2                        0.0                     0.0                     0.0   \n3                        0.0                     0.0                     0.0   \n4                        0.0                     0.0                     0.0   \n5                        1.0                     0.0                     0.0   \n...                      ...                     ...                     ...   \n3124                     0.0                     0.0                     0.0   \n3125                     0.0                     0.0                     0.0   \n3126                     0.0                     0.0                     0.0   \n3128                     0.0                     0.0                     0.0   \n3129                     0.0                     0.0                     0.0   \n\n      Neighborhood_southwest  \n1                        0.0  \n2                        0.0  \n3                        0.0  \n4                        0.0  \n5                        0.0  \n...                      ...  \n3124                     0.0  \n3125                     0.0  \n3126                     0.0  \n3128                     0.0  \n3129                     0.0  \n\n[2191 rows x 50 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>NumberofFloors</th>\n      <th>PropertyGFATotal</th>\n      <th>PropertyGFAParking</th>\n      <th>SecondLargestPropertyUseTypeGFA</th>\n      <th>ThirdLargestPropertyUseTypeGFA</th>\n      <th>YearBuilt</th>\n      <th>BuildingType_Campus</th>\n      <th>BuildingType_Multifamily HR (10+)</th>\n      <th>BuildingType_Multifamily LR (1-4)</th>\n      <th>BuildingType_Multifamily MR (5-9)</th>\n      <th>...</th>\n      <th>Neighborhood_downtown</th>\n      <th>Neighborhood_east</th>\n      <th>Neighborhood_greater duwamish</th>\n      <th>Neighborhood_lake union</th>\n      <th>Neighborhood_magnolia / queen anne</th>\n      <th>Neighborhood_north</th>\n      <th>Neighborhood_northeast</th>\n      <th>Neighborhood_northwest</th>\n      <th>Neighborhood_southeast</th>\n      <th>Neighborhood_southwest</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>-0.499734</td>\n      <td>-0.462226</td>\n      <td>-0.252566</td>\n      <td>-0.141522</td>\n      <td>0.134019</td>\n      <td>1928</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.314688</td>\n      <td>-0.468417</td>\n      <td>-0.252566</td>\n      <td>-0.382358</td>\n      <td>-0.207072</td>\n      <td>1925</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.905866</td>\n      <td>-0.106769</td>\n      <td>-0.252566</td>\n      <td>-0.382358</td>\n      <td>-0.207072</td>\n      <td>1971</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.314688</td>\n      <td>-0.384912</td>\n      <td>-0.042709</td>\n      <td>-0.266691</td>\n      <td>-0.207072</td>\n      <td>2001</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>-0.129642</td>\n      <td>-0.365813</td>\n      <td>-0.252566</td>\n      <td>-0.382358</td>\n      <td>-0.207072</td>\n      <td>1996</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3124</th>\n      <td>0.055404</td>\n      <td>-0.264528</td>\n      <td>-0.252566</td>\n      <td>-0.382358</td>\n      <td>-0.207072</td>\n      <td>1925</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3125</th>\n      <td>-0.499734</td>\n      <td>-0.403766</td>\n      <td>-0.252566</td>\n      <td>-0.006164</td>\n      <td>-0.046558</td>\n      <td>1927</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3126</th>\n      <td>-0.314688</td>\n      <td>-0.344549</td>\n      <td>0.022846</td>\n      <td>0.006725</td>\n      <td>0.871936</td>\n      <td>2001</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3128</th>\n      <td>0.055404</td>\n      <td>-0.404507</td>\n      <td>-0.073157</td>\n      <td>-0.141054</td>\n      <td>-0.039870</td>\n      <td>2001</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3129</th>\n      <td>-0.499734</td>\n      <td>-0.502552</td>\n      <td>-0.252566</td>\n      <td>-0.162039</td>\n      <td>-0.207072</td>\n      <td>1911</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>2191 rows × 50 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "      NumberofFloors  PropertyGFATotal  PropertyGFAParking  \\\n0          -0.314688         -0.500899           -0.252566   \n7          -0.314688          0.240235           -0.252566   \n12         -0.499734         -0.299056            0.385783   \n14         -0.129642          0.514730           -0.252566   \n17         -0.684781         -0.427565           -0.252566   \n...              ...               ...                 ...   \n3116        0.240450          0.064364           -0.252566   \n3118        0.055404         -0.413997           -0.252566   \n3121       -0.129642         -0.359874           -0.252566   \n3127       -0.129642         -0.382858           -0.252566   \n3130       -0.684781         -0.519293           -0.252566   \n\n      SecondLargestPropertyUseTypeGFA  ThirdLargestPropertyUseTypeGFA  \\\n0                           -0.382358                       -0.207072   \n7                            0.043078                       -0.207072   \n12                          -0.217119                       -0.207072   \n14                           0.201569                        0.245487   \n17                          -0.315106                       -0.207072   \n...                               ...                             ...   \n3116                        -0.382358                       -0.207072   \n3118                        -0.382358                       -0.207072   \n3121                        -0.382358                       -0.207072   \n3127                        -0.382358                       -0.207072   \n3130                        -0.162039                       -0.083566   \n\n      YearBuilt  BuildingType_Campus  BuildingType_Multifamily HR (10+)  \\\n0          1978                  0.0                                0.0   \n7          1977                  0.0                                0.0   \n12         1991                  0.0                                0.0   \n14         2010                  0.0                                0.0   \n17         1980                  0.0                                0.0   \n...         ...                  ...                                ...   \n3116       2007                  0.0                                0.0   \n3118       1915                  0.0                                0.0   \n3121       1925                  0.0                                0.0   \n3127       1907                  0.0                                0.0   \n3130       1938                  0.0                                0.0   \n\n      BuildingType_Multifamily LR (1-4)  BuildingType_Multifamily MR (5-9)  \\\n0                                   1.0                                0.0   \n7                                   1.0                                0.0   \n12                                  0.0                                0.0   \n14                                  1.0                                0.0   \n17                                  0.0                                0.0   \n...                                 ...                                ...   \n3116                                0.0                                1.0   \n3118                                0.0                                1.0   \n3121                                0.0                                0.0   \n3127                                1.0                                0.0   \n3130                                0.0                                0.0   \n\n      ...  Neighborhood_downtown  Neighborhood_east  \\\n0     ...                    0.0                0.0   \n7     ...                    0.0                0.0   \n12    ...                    1.0                0.0   \n14    ...                    0.0                0.0   \n17    ...                    0.0                0.0   \n...   ...                    ...                ...   \n3116  ...                    1.0                0.0   \n3118  ...                    1.0                0.0   \n3121  ...                    0.0                1.0   \n3127  ...                    0.0                0.0   \n3130  ...                    0.0                0.0   \n\n      Neighborhood_greater duwamish  Neighborhood_lake union  \\\n0                               0.0                      0.0   \n7                               0.0                      0.0   \n12                              0.0                      0.0   \n14                              0.0                      0.0   \n17                              0.0                      0.0   \n...                             ...                      ...   \n3116                            0.0                      0.0   \n3118                            0.0                      0.0   \n3121                            0.0                      0.0   \n3127                            0.0                      1.0   \n3130                            1.0                      0.0   \n\n      Neighborhood_magnolia / queen anne  Neighborhood_north  \\\n0                                    0.0                 0.0   \n7                                    0.0                 0.0   \n12                                   0.0                 0.0   \n14                                   0.0                 0.0   \n17                                   0.0                 0.0   \n...                                  ...                 ...   \n3116                                 0.0                 0.0   \n3118                                 0.0                 0.0   \n3121                                 0.0                 0.0   \n3127                                 0.0                 0.0   \n3130                                 0.0                 0.0   \n\n      Neighborhood_northeast  Neighborhood_northwest  Neighborhood_southeast  \\\n0                        0.0                     0.0                     0.0   \n7                        1.0                     0.0                     0.0   \n12                       0.0                     0.0                     0.0   \n14                       0.0                     0.0                     0.0   \n17                       0.0                     0.0                     0.0   \n...                      ...                     ...                     ...   \n3116                     0.0                     0.0                     0.0   \n3118                     0.0                     0.0                     0.0   \n3121                     0.0                     0.0                     0.0   \n3127                     0.0                     0.0                     0.0   \n3130                     0.0                     0.0                     0.0   \n\n      Neighborhood_southwest  \n0                        0.0  \n7                        0.0  \n12                       0.0  \n14                       0.0  \n17                       0.0  \n...                      ...  \n3116                     0.0  \n3118                     0.0  \n3121                     0.0  \n3127                     0.0  \n3130                     0.0  \n\n[940 rows x 50 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>NumberofFloors</th>\n      <th>PropertyGFATotal</th>\n      <th>PropertyGFAParking</th>\n      <th>SecondLargestPropertyUseTypeGFA</th>\n      <th>ThirdLargestPropertyUseTypeGFA</th>\n      <th>YearBuilt</th>\n      <th>BuildingType_Campus</th>\n      <th>BuildingType_Multifamily HR (10+)</th>\n      <th>BuildingType_Multifamily LR (1-4)</th>\n      <th>BuildingType_Multifamily MR (5-9)</th>\n      <th>...</th>\n      <th>Neighborhood_downtown</th>\n      <th>Neighborhood_east</th>\n      <th>Neighborhood_greater duwamish</th>\n      <th>Neighborhood_lake union</th>\n      <th>Neighborhood_magnolia / queen anne</th>\n      <th>Neighborhood_north</th>\n      <th>Neighborhood_northeast</th>\n      <th>Neighborhood_northwest</th>\n      <th>Neighborhood_southeast</th>\n      <th>Neighborhood_southwest</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.314688</td>\n      <td>-0.500899</td>\n      <td>-0.252566</td>\n      <td>-0.382358</td>\n      <td>-0.207072</td>\n      <td>1978</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>-0.314688</td>\n      <td>0.240235</td>\n      <td>-0.252566</td>\n      <td>0.043078</td>\n      <td>-0.207072</td>\n      <td>1977</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>-0.499734</td>\n      <td>-0.299056</td>\n      <td>0.385783</td>\n      <td>-0.217119</td>\n      <td>-0.207072</td>\n      <td>1991</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>-0.129642</td>\n      <td>0.514730</td>\n      <td>-0.252566</td>\n      <td>0.201569</td>\n      <td>0.245487</td>\n      <td>2010</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>-0.684781</td>\n      <td>-0.427565</td>\n      <td>-0.252566</td>\n      <td>-0.315106</td>\n      <td>-0.207072</td>\n      <td>1980</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3116</th>\n      <td>0.240450</td>\n      <td>0.064364</td>\n      <td>-0.252566</td>\n      <td>-0.382358</td>\n      <td>-0.207072</td>\n      <td>2007</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3118</th>\n      <td>0.055404</td>\n      <td>-0.413997</td>\n      <td>-0.252566</td>\n      <td>-0.382358</td>\n      <td>-0.207072</td>\n      <td>1915</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3121</th>\n      <td>-0.129642</td>\n      <td>-0.359874</td>\n      <td>-0.252566</td>\n      <td>-0.382358</td>\n      <td>-0.207072</td>\n      <td>1925</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3127</th>\n      <td>-0.129642</td>\n      <td>-0.382858</td>\n      <td>-0.252566</td>\n      <td>-0.382358</td>\n      <td>-0.207072</td>\n      <td>1907</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3130</th>\n      <td>-0.684781</td>\n      <td>-0.519293</td>\n      <td>-0.252566</td>\n      <td>-0.162039</td>\n      <td>-0.083566</td>\n      <td>1938</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>940 rows × 50 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2191,) (940,)\n"
     ]
    }
   ],
   "source": [
    "print(\"We can start now the modelling to predict the feature wanted.\")\n",
    "\n",
    "display(X_train_std_encoded)\n",
    "display(X_test_std_encoded)\n",
    "print(y_train.shape, y_test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We rename X_train_std_encoded to X_train, the same for X_test.\n"
     ]
    },
    {
     "data": {
      "text/plain": "      NumberofFloors  PropertyGFATotal  PropertyGFAParking  \\\n0          -0.314688         -0.500899           -0.252566   \n7          -0.314688          0.240235           -0.252566   \n12         -0.499734         -0.299056            0.385783   \n14         -0.129642          0.514730           -0.252566   \n17         -0.684781         -0.427565           -0.252566   \n...              ...               ...                 ...   \n3116        0.240450          0.064364           -0.252566   \n3118        0.055404         -0.413997           -0.252566   \n3121       -0.129642         -0.359874           -0.252566   \n3127       -0.129642         -0.382858           -0.252566   \n3130       -0.684781         -0.519293           -0.252566   \n\n      SecondLargestPropertyUseTypeGFA  ThirdLargestPropertyUseTypeGFA  \\\n0                           -0.382358                       -0.207072   \n7                            0.043078                       -0.207072   \n12                          -0.217119                       -0.207072   \n14                           0.201569                        0.245487   \n17                          -0.315106                       -0.207072   \n...                               ...                             ...   \n3116                        -0.382358                       -0.207072   \n3118                        -0.382358                       -0.207072   \n3121                        -0.382358                       -0.207072   \n3127                        -0.382358                       -0.207072   \n3130                        -0.162039                       -0.083566   \n\n      YearBuilt  BuildingType_Campus  BuildingType_Multifamily HR (10+)  \\\n0          1978                  0.0                                0.0   \n7          1977                  0.0                                0.0   \n12         1991                  0.0                                0.0   \n14         2010                  0.0                                0.0   \n17         1980                  0.0                                0.0   \n...         ...                  ...                                ...   \n3116       2007                  0.0                                0.0   \n3118       1915                  0.0                                0.0   \n3121       1925                  0.0                                0.0   \n3127       1907                  0.0                                0.0   \n3130       1938                  0.0                                0.0   \n\n      BuildingType_Multifamily LR (1-4)  BuildingType_Multifamily MR (5-9)  \\\n0                                   1.0                                0.0   \n7                                   1.0                                0.0   \n12                                  0.0                                0.0   \n14                                  1.0                                0.0   \n17                                  0.0                                0.0   \n...                                 ...                                ...   \n3116                                0.0                                1.0   \n3118                                0.0                                1.0   \n3121                                0.0                                0.0   \n3127                                1.0                                0.0   \n3130                                0.0                                0.0   \n\n      ...  Neighborhood_downtown  Neighborhood_east  \\\n0     ...                    0.0                0.0   \n7     ...                    0.0                0.0   \n12    ...                    1.0                0.0   \n14    ...                    0.0                0.0   \n17    ...                    0.0                0.0   \n...   ...                    ...                ...   \n3116  ...                    1.0                0.0   \n3118  ...                    1.0                0.0   \n3121  ...                    0.0                1.0   \n3127  ...                    0.0                0.0   \n3130  ...                    0.0                0.0   \n\n      Neighborhood_greater duwamish  Neighborhood_lake union  \\\n0                               0.0                      0.0   \n7                               0.0                      0.0   \n12                              0.0                      0.0   \n14                              0.0                      0.0   \n17                              0.0                      0.0   \n...                             ...                      ...   \n3116                            0.0                      0.0   \n3118                            0.0                      0.0   \n3121                            0.0                      0.0   \n3127                            0.0                      1.0   \n3130                            1.0                      0.0   \n\n      Neighborhood_magnolia / queen anne  Neighborhood_north  \\\n0                                    0.0                 0.0   \n7                                    0.0                 0.0   \n12                                   0.0                 0.0   \n14                                   0.0                 0.0   \n17                                   0.0                 0.0   \n...                                  ...                 ...   \n3116                                 0.0                 0.0   \n3118                                 0.0                 0.0   \n3121                                 0.0                 0.0   \n3127                                 0.0                 0.0   \n3130                                 0.0                 0.0   \n\n      Neighborhood_northeast  Neighborhood_northwest  Neighborhood_southeast  \\\n0                        0.0                     0.0                     0.0   \n7                        1.0                     0.0                     0.0   \n12                       0.0                     0.0                     0.0   \n14                       0.0                     0.0                     0.0   \n17                       0.0                     0.0                     0.0   \n...                      ...                     ...                     ...   \n3116                     0.0                     0.0                     0.0   \n3118                     0.0                     0.0                     0.0   \n3121                     0.0                     0.0                     0.0   \n3127                     0.0                     0.0                     0.0   \n3130                     0.0                     0.0                     0.0   \n\n      Neighborhood_southwest  \n0                        0.0  \n7                        0.0  \n12                       0.0  \n14                       0.0  \n17                       0.0  \n...                      ...  \n3116                     0.0  \n3118                     0.0  \n3121                     0.0  \n3127                     0.0  \n3130                     0.0  \n\n[940 rows x 50 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>NumberofFloors</th>\n      <th>PropertyGFATotal</th>\n      <th>PropertyGFAParking</th>\n      <th>SecondLargestPropertyUseTypeGFA</th>\n      <th>ThirdLargestPropertyUseTypeGFA</th>\n      <th>YearBuilt</th>\n      <th>BuildingType_Campus</th>\n      <th>BuildingType_Multifamily HR (10+)</th>\n      <th>BuildingType_Multifamily LR (1-4)</th>\n      <th>BuildingType_Multifamily MR (5-9)</th>\n      <th>...</th>\n      <th>Neighborhood_downtown</th>\n      <th>Neighborhood_east</th>\n      <th>Neighborhood_greater duwamish</th>\n      <th>Neighborhood_lake union</th>\n      <th>Neighborhood_magnolia / queen anne</th>\n      <th>Neighborhood_north</th>\n      <th>Neighborhood_northeast</th>\n      <th>Neighborhood_northwest</th>\n      <th>Neighborhood_southeast</th>\n      <th>Neighborhood_southwest</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.314688</td>\n      <td>-0.500899</td>\n      <td>-0.252566</td>\n      <td>-0.382358</td>\n      <td>-0.207072</td>\n      <td>1978</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>-0.314688</td>\n      <td>0.240235</td>\n      <td>-0.252566</td>\n      <td>0.043078</td>\n      <td>-0.207072</td>\n      <td>1977</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>-0.499734</td>\n      <td>-0.299056</td>\n      <td>0.385783</td>\n      <td>-0.217119</td>\n      <td>-0.207072</td>\n      <td>1991</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>-0.129642</td>\n      <td>0.514730</td>\n      <td>-0.252566</td>\n      <td>0.201569</td>\n      <td>0.245487</td>\n      <td>2010</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>-0.684781</td>\n      <td>-0.427565</td>\n      <td>-0.252566</td>\n      <td>-0.315106</td>\n      <td>-0.207072</td>\n      <td>1980</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3116</th>\n      <td>0.240450</td>\n      <td>0.064364</td>\n      <td>-0.252566</td>\n      <td>-0.382358</td>\n      <td>-0.207072</td>\n      <td>2007</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3118</th>\n      <td>0.055404</td>\n      <td>-0.413997</td>\n      <td>-0.252566</td>\n      <td>-0.382358</td>\n      <td>-0.207072</td>\n      <td>1915</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3121</th>\n      <td>-0.129642</td>\n      <td>-0.359874</td>\n      <td>-0.252566</td>\n      <td>-0.382358</td>\n      <td>-0.207072</td>\n      <td>1925</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3127</th>\n      <td>-0.129642</td>\n      <td>-0.382858</td>\n      <td>-0.252566</td>\n      <td>-0.382358</td>\n      <td>-0.207072</td>\n      <td>1907</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3130</th>\n      <td>-0.684781</td>\n      <td>-0.519293</td>\n      <td>-0.252566</td>\n      <td>-0.162039</td>\n      <td>-0.083566</td>\n      <td>1938</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>940 rows × 50 columns</p>\n</div>"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"We rename X_train_std_encoded to X_train, the same for X_test.\")\n",
    "X_train = X_train_std_encoded.copy()\n",
    "X_test = X_test_std_encoded.copy()\n",
    "\n",
    "X_train\n",
    "X_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1) Linear modelling : Linear Regression / Ridge Regression / Lasso / Elastic Net\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "(2191, 50)"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "(940, 50)"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1) Linear Regression : baseline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is : -1%\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "# 0) We create a linear regression model\n",
    "lr = linear_model.LinearRegression()\n",
    "\n",
    "# 1) Training Linear Regression and Evaluating\n",
    "reg = lr.fit(X_train, y_train)\n",
    "\n",
    "prediction_score = lr.score(X_test, y_test)\n",
    "#print(\"Accuracy is : %.2f\" % (100 * prediction_score))\n",
    "print('Accuracy is : {:.0%}'.format(prediction_score))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8705343565897277\n"
     ]
    }
   ],
   "source": [
    "# On récupère l'erreur de norme 2 sur le jeu de données test comme baseline\n",
    "y_pred = lr.predict(X_test)\n",
    "baseline_error = np.mean((y_pred - y_test) ** 2)\n",
    "\n",
    "#On obtient l'erreur quadratique ci-dessous\n",
    "print(baseline_error)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² :  -0.014164466789544194\n",
      "MAE : 1.3242592502300008\n",
      "RMSE: 1.694265137630391\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error,r2_score,mean_squared_error\n",
    "\n",
    "def run_experiment(model):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(\"R² : \", r2_score(y_test, y_pred))\n",
    "    print(\"MAE :\", mean_absolute_error(y_test,y_pred))\n",
    "    print(\"RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "\n",
    "run_experiment(lr)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Electricity prediction\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If the prediction was good, we would see a line which is not the case here .\n"
     ]
    }
   ],
   "source": [
    "print(\"Electricity prediction\")\n",
    "plt.plot(y_pred, y_test, \"ro\", markersize=4)\n",
    "plt.show()\n",
    "\n",
    "print(\"If the prediction was good, we would see a line which is not the case here .\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2) Linear Model : Ridge"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "n_alphas = 50 #hyperparametre alpha\n",
    "alphas = np.logspace(-5, 5, n_alphas)\n",
    "\n",
    "ridge = linear_model.Ridge()\n",
    "\n",
    "coefs = []\n",
    "errors = []\n",
    "for a in alphas:\n",
    "    ridge.set_params(alpha=a)\n",
    "    ridge.fit(X_train, y_train)\n",
    "    coefs.append(ridge.coef_)\n",
    "    errors.append(np.mean((ridge.predict(X_test) - y_test) ** 2))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# observation du comportement de l'erreur\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.plot(alphas, errors, [10**-5, 10**5], [baseline_error, baseline_error])\n",
    "ax.set_xscale('log')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAELCAYAAADZW/HeAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAiV0lEQVR4nO3deXxU5aH/8c+ZySQhCyQkk4QlLAo8YTGAImpVtIK41lZa26rYurZ2+7W3trVaba9VX7e91W7X1q0iWlu1eHGpGxSxVmrVK4LIkod9kS1hCSF7MjO/P2awMSIOZCZnzsz3/XrxCnPOJPN9XkPmy/OcOWecSCSCiIiIz+0AIiKSGlQIIiICqBBERCRGhSAiIoAKQUREYrLcDtAT4XA4Egp5611Sfr+D1zL3lMacGTRm7wgE/LuAYPftni6EUChCfX2z2zEOS1FRnucy95TGnBk0Zu8IBgs3HWy7loxERARQIYiISIwKQUREABWCiIjEqBBERARQIYiISIwKQUREAI+fh3Ck3tm6j/k1da48dk5OFm1tnTjOkf8Mp8s3Ox/YfpD74uA40fv9e/8Htzmxn+kAPie678BXB/D7HBzHwRfb7ov93e9zyPI573/99999BPwO2X4fgSwf/Vs6aWtuJzvLR5+Aj9yAn9ws3wfGISLuS3ghGGMCwCxgGJAD3GatfabL/kuB64AQMMtae7cx5nLg8thdcoEJQIW1tj7R+QBW7NjPvJraZPzoj+U4DuHD/AyKrnePEDno9oPdP0KESAQiH9gX/Qnvb4/dDrtwsmVulo8+AT99Aj4KcrLom5tFYW6AvjlZFOZGb5fkZVNakE1ZQQ6lBdn0y81SkYgkSTJmCDOB3dbay4wxJcAS4Jku++8AxgKNwEpjzGPW2tnAbABjzO+IFkV9ErIBcMlxg7nkuMHJ+vGHlOpnNkYiEcKRf38NxwojFI6WSygSIRKJEIpEt4XCETpjX6N/D9MZjtAeCtPRGf2anRugvqGVts4wrZ0hWjrCtHSEaOkI0dYZpqk9RGNbJ/tbO9m4p5n9rZ3sb+ukrTP8oXwBv0MwP5uB/XIZ2j+PYf3zGNq/D8P651FemINPZSFyxJJRCHOAJ7rc7uy2fxnQL7bdoct/YI0xk4Cx1tpvJCGXxMFxHPwOfHAxqmeOtARbO0Lsbm5nV2M7dY3t1DW1s6uxjdrGdrbWtzC/po79bf/+55WT5ePo0nyqB/Zl/MC+VA/sS1lhTsLGIZLuEl4I1tpGAGNMIdFiuKnbXZYDi4EmYG63mcCNwC3xPpbf71BUlNejvL3N7/d5LnNP9WTMFYfYF4lE2NPUzrpdTayva2L9rkZWbGvgqXe389jbWwEYVJTLxMpiJg8vZmpVGWWFuUeU43Dpec4M6TZmJxmfqWyMqQSeBH5vrZ3VZXs18BfgBKJLRo8QLYU5xpgi4DVr7Zh4H6ejIxRJ5eWXg0n1JaNk6O0xd4bC2Lomlm1rYNnWfbyzrYG6xnYcoHpgX84YVcoZI0up6Ju8ctDznBm8OuZgsHAxMKn79mQcVC4H5gPftNa+1G33PqAFaLHWhowxtUBxbN8UYEGi80jmyfL7GFtRyNiKQi4+dhCRSIQNe5pZuHoXC9fs4ld/X8+v/r6eMRWFTB1Zyvnjyumfl+12bBHXJeMYwo1EX+RvNsbcHNt2P5Bvrb3PGHMvsMgY0w6sI3YwGTDA+iTkkQznOA5HleRz1En5XH3SULbsbWHhmmg5/M+rG7j3tY2cPbqMi48dzIhgvttxRVyTlCWj3qIlI29I5TFv3NPMY29v5bkVO2ntDDN5SBEXHzeITwzv36N3LKXymJNFY/aOj1oy0pnKktGG9c/jh9NG8uxXTuCbpw5n455m/uPJFVz04Fs8v3LnYZ8zIuJlKgQRoF+fAF+eXMnTV0/m9vOq6BPw85MXLJf/aQmLt9S7HU+kV6gQRLrI8vuYXlXGwzMncss5hj3NHVz7l2V8/+kVbNrjvaUBkcOhQhA5CJ/jcO6Ycp64YhJfP2UYb26q5wsPLeaOhWupb+lwO55IUqgQRA4hN+DnihOGMPeq4/n0uArmLN3G5x98i4Wr3bk4okgyqRBE4lCSn80NZ47kkcuOpbwwh+v/uoobn11FfbNmC5I+VAgih2FksIAHL5nAtScP5eU1u/jCQ2+xcM0ut2OJJIQKQeQwZfl9XHXiUB6eOZGyghyuf2YlP9JsQdKACkHkCHWdLSxcs4svPrxYb1EVT1MhiPTAgdnCQ5dOJD/bz9fnLGP2G5sJu/GJQyI9pEIQSYBRZQU8PHMiU0cF+d2ijVz757fZp7eniseoEEQSJD87i9vPq+L7Z4xg0dpdXPbI26zYsd/tWCJxUyGIJJDjOHx+4kAevfoEAK5+dCl/WbINL19EUjKHCkEkCcYPLuKPM4/lxGHF/GLhWn7+0lo6dVxBUpwKQSRJ+vUJcOdnxvKl4yv533e2890nl9PY1v0jxkVShwpBJIl8jsO3pgznxjNH8uamvXzl8XfY0dDqdiyRg1IhiPSCC6sH8OsZ49i2r5UrH12K3dnodiSRD1EhiPSSE4f15w9fnIDPcbjm8aW8um6325FEPkCFINKLRgTzefCSCQwtzuN7T6/g2RU73I4k8j4VgkgvCxbkcN8XxzOpsoifvrhapSApQ4Ug4oI+AT93fmYsxw9RKUjqUCGIuCRXpSApRoUg4iKVgqQSFYKIy1QKkipUCCIpoHspzFtV63YkyUAqBJEUcaAUJgzux0/nWZZvb3A7kmQYFYJICskN+PnvT42htCCH7z+9ktr9bW5HkgyiQhBJMUV50YviNbeH+N7TK2jtCLkdSTKECkEkBY0ozeen51ZRs7OR2+av1ucpSK9QIYikqNNGlPC1U4Yxr6aO2W9ucTuOZIAstwOIyEe7fHIl63Y1cfeijRxVks9pI0rcjiRpTDMEkRTmOA43TR/F6IpCfvx8DWvrmtyOJGlMhSCS4nIDfn5xwRjysv3c8OxK2jrDbkeSNKVCEPGAssIcfnz2KDbuaWHWG5vdjiNpSoUg4hEnDevPeWPKeOjNLayp0yeuSeKpEEQ85DunH02/3CxunbeazrDeiiqJpUIQ8ZCiPgG+f8YIVu1s5NHF77kdR9KMCkHEY6aOKuX0ESXc+9omtuxtcTuOpBEVgojHOI7DD6aOIOB3uG3+asI6i1kSJOEnphljAsAsYBiQA9xmrX2my/5LgeuAEDDLWnt3bPsNwAVANvB7a+0Dic4mki6CBTl8e8pR3P63NTz17g5mVA9wO5KkgWTMEGYCu621pwLnAHd1238HMA04GbjOGFNsjDkd+ERs22lAZRJyiaSVTx9TwaTKfvz2lfXs1FVRJQGScemKOcATXW53dtu/DOgX2+4AEeAs4F3gSaAv8P14Hsjvdygqyutp3l7l9/s8l7mnNObk+dnnxnP+XYv41T82cM+lxyb98Q5Fz7P3JbwQrLWNAMaYQqLFcFO3uywHFgNNwFxrbb0xphQYCpwPDAeeMcZUWWsPuTgaCkWor29O9BCSqqgoz3OZe0pjTp5+PrjqhCH8btFGXlmxnfGD+iX9MT+KnmfvCAYLD7o9KQeVjTGVwMvAH621f+6yvRo4j+iL/jCgzBhzEbAbmGetbbfWWqAVCCYjm0i6+cKxg+ifF+C+1za5HUU8LuGFYIwpB+YD11trZ3XbvQ9oAVqstSGgFigGFgFnG2McY8xAIJ9oSYjIx+gT8HPZ8ZW8ubmepe/tczuOeFgyZgg3En2Rv9kY8/fYn0uNMV+x1m4C7gUWGWMWAUXAbGvts8AS4E3gr8A3YoUhInH47PgB0VnCvzRLkCPnePmTmDo6QhGvrd95dc2xJzTm3vGnt97j16+s574vjGfi4N4/lqDn2TuCwcLFwKTu23Vimkia0CxBekqFIJImcgN+vnR8JW9truft9+rdjiMepEIQSSMHZgn36x1HcgRUCCJpJDfg58uTK3lryz4Wb6l3O454jApBJM3MqB5ASX429+tYghwmFYJImokeSxjMYs0S5DCpEETSkGYJciRUCCJpqOssYfn2BrfjiEeoEETS1AXjKugT8DH3ne1uRxGPUCGIpKmCnCzOqipjvq1jf2v3q9CLfJgKQSSNzRg/gLbOMC+s2ul2FPEAFYJIGhtdXsjo8gLmLtuOl69bJr1DhSCS5i6sHsC6Xc0s26aDy3JoKgSRNDe9KkhewM+T7+5wO4qkOBWCSJrLz87i7NFlLLB1NLR2uB1HUpgKQSQDzKiOHlx+fmWt21EkhakQRDKAKS9gTEWhDi7LIakQRDLEjOoKNuxu5p2tOrgsB6dCEMkQ06vKyM/2M3eZzlyWg1MhiGSIPgE/54wu46XVddS36OCyfJgKQSSDzBg/gPZQhOdX6sxl+TAVgkgGGRks4JgBhcx9RweX5cNUCCIZ5sLqAWza28KSrfvcjiIpRoUgkmHONNEzl1/QOQnSjQpBJMPkBvxMGVHCwjW76AiF3Y4jKUSFIJKBzqoK0tDayesb97odRVKICkEkA504tJh+uVnMq9GykfybCkEkA2X5fUwdFeSVtbtp6Qi5HUdShApBJENNrwrS2hnm1XW73Y4iKUKFIJKhJg7uR1lBNvNq6tyOIilChSCSoXyOwzQT5LUNe/Q5CQKoEEQy2tmjy+gMR1i4epfbUSQFqBBEMlhVWQFDivswz2rZSFQIIhnNcRymmyCLN9ezq7HN7TjiMhWCSIY7q6qMCPA3LRtlPBWCSIYbVpKHKStg3iqdpJbp4ioEY4xJdhARcc9ZVUFW7NjPe/UtbkcRF8U7Q3ggqSlExFVnmiAA83VOQkbLivN+TcaYXwEWCANYa+872B2NMQFgFjAMyAFus9Y+02X/pcB1QAiYZa29O7Z9CXDgAu0brLVXHPZoROSIVPTNZcKgvrxYU8sVJ1TiOI7bkcQF8RbCa7Gv5XHcdyaw21p7mTGmBFgCPNNl/x3AWKARWGmMeQxoAbDWnh5nHhFJsLOqyvj5S2tZu6uJkcECt+OIC+JaMrLW3gK8RfSFe2ns9keZA9zc5XZnt/3LgH5ALuAAEWA8kGeMmW+MWWiMOTHO/CKSIFNHleJ30KUsMlhcMwRjzH8BI4FFwJeNMadaa793sPtaaxtj31MIPAHc1O0uy4HFQBMw11pbb4xpJjpz+EPscV4wxhhrbfcy+QC/36GoKC+eIaQMv9/nucw9pTF7Q1FRHicdXcLLa3fzo/PHHPaykRfH3FPpNuZ4l4ymWGtPBjDG/AZ4/VB3NsZUAk8Cv7fW/rnL9mrgPGA40SWjR4wxFxFdUlprrY0Aq40xu4EBwJZDPU4oFKG+vjnOIaSGoqI8z2XuKY3ZO04b3p/b167hzdV1mPLDWzby6ph7wqtjDgYLD7o93ncZBYwxB+57YJnnoIwx5cB84Hpr7axuu/cRXXZqsdaGgFqgGLgSuDP2/QOBvsD2OLOJSIKcPiK6bLRgtZaNMlG8M4THgX8aY14HTgAeO8R9byT6In+zMebAsYT7gXxr7X3GmHuBRcaYdmAdMDt2n9nGmEVEy+bKj1suEpHEK8oLMGlIEQtW1/H1U4bp3UYZJt5CeBaYB1QBD1hrl3/UHa213wa+fYj99wD3HGTXJXFmEZEkmjYqyO1/W8Pq2qbDXjYSb4u3EB6w1p5C9ICwiKSx00eU8rMFa1hwBMcRxNsSfmKaiHjbgWWjl7RslHHiPaj8GlBP9MS0AUBFsgKJiPumjgqypb6V1XVNbkeRXhTvDGGUtfbSpCYRkZTxyRGl/HzBGl5aXYcp07JRpoi3EHJi5xCs5t9LRu1JSyUirirKC3BcZRELbB1fO1nLRpki3iUjAzwF7CRaCjXJCiQiqWGq0bJRpom3EL4JNBM9WeyPwO1JSyQiKeGTI0rwO/CSTlLLGPEWwq3AFGAb0TL4etISiUhKKM7L5rjKIl5avYtI5CMvTiBpJN5CCFtr9wBYa1uB/cmLJCKpYqoJsnlvC2u0bJQR4i2EtbErnpYYY34IbEpiJhFJEQeWjXRto8wQbyFcS7QEFhG9bPU1SUskIimjOC+bY7VslDHiettp7EJzB7v+kIikuWmjSvmvBWtZU9fEKJ2TkNbinSGISIY6fWQpPr3bKCOoEETkkPrH3m20QMtGaU+FICIfa3rs3Ua2ttHtKJJEKgQR+VifHFmK3+cwv0bLRulMhSAiH6tfnwAnDSvmb7aOsJaN0pYKQUTicqYJsmN/G+9ua3A7iiSJCkFE4jLl6BJysnxaNkpjKgQRiUtBThYnD+/PgtV1dIa1bJSOVAgiErfpVUH2NHfw9pZ6t6NIEqgQRCRuJw/vT17Az3yrZaN0pEIQkbjlBvycNqKEl9fsoiMUdjuOJJgKQUQOy/SqIA2tnby+ca/bUSTBVAgiclhOGFpM39wsLRulIRWCiByWgN/HJ0eW8o+1u2ntCLkdRxJIhSAih226CdLcEeKfG/a4HUUSSIUgIoftuMoi+ucFdJJamlEhiMhh8/scpo0K8s8Ne2hs63Q7jiSICkFEjsj0qiBtnWH+sW6321EkQVQIInJEjhnYl4rCHC0bpREVgogcEZ/jcKYJ8vqmvextbnc7jiSACkFEjti5Y8sJhSO8qFlCWlAhiMgRG1Gaz+jyAp5dvsPtKJIAKgQR6ZHzx1awuq6Jldv1wTlep0IQkR6ZXhUk4Hd4cslWt6NID6kQRKRHivoEmHJ0CU+/s01XQPU4FYKI9Nj5Y8vZ29zBa7qUhaepEESkx04c1p/SgmyeXbHT7SjSA1mJ/oHGmAAwCxgG5AC3WWuf6bL/UuA6IATMstbe3WVfGbAYONNaW5PobCKSHFk+h0+PH8jsf21ib3M7xXnZbkeSI5CMGcJMYLe19lTgHOCubvvvAKYBJwPXGWOK4f0iuRdoSUImEUmyGRMH6ZwEj0v4DAGYAzzR5Xb3K18tA/rFtjtAJLb9DuAe4IZ4H8jvdygqyjvypC7w+32ey9xTGnNmKPH7OGZQX15YVcvXzhjpdpxekW7Pc8ILwVrbCGCMKSRaDDd1u8tyostCTcBca229MeZyoM5aO88YE3chhEIR6uubExO8lxQV5Xkuc09pzJmhqCiPs00Zv1i4ljdW12LKCtyOlHRefZ6DwcKDbk/KQWVjTCXwMvBHa+2fu2yvBs4DhhM9xlBmjLkIuBI40xjzd2AC8LAxpiIZ2UQkeQ6ck/CcDi57UsILwRhTDswHrrfWzuq2ex/RYwQt1toQUAsUW2unWGtPs9aeDiwFvmSt1bnwIh5z4JyEF1bV6pwED0rGMYQbgWLgZmPMzbFt9wP51tr7jDH3AouMMe3AOmB2EjKIiEvOH1vOS6t38dqGPZw2otTtOHIYnEgk8vH3SlEdHaGI19bvvLrm2BMac2Y4MObOcITz7n2d6oF9+cWnx7odK6m8+jwHg4WLgUndt+vENBFJqCyfw7ljynl1/R726HMSPEWFICIJd8G4CkLhCM+8q0OBXqJCEJGEG16Sx6TKfsxdtp1Q2LvL0plGhSAiSXHRhIFsb2hj0Xpd8M4rVAgikhRTRpRSVpDNnKX6nASvUCGISFJk+RwurB7AG5vq2bTHe+/EyUQqBBFJms9UDyDL5/DEO9vdjiJxUCGISNKU5mczdVQpz67YQUtHyO048jFUCCKSVBdNGEhjW4gXVtW6HUU+hgpBRJKqemBfRgbzeWLpNrx8ZYRMoEIQkaRyHIeLJgxkTV0T72xtcDuOHIIKQUSS7uzRZRTk+JmzdJvbUeQQVAgiknR9An4+NbaChWt2satJ1zdKVSoEEekVn5swkM5whKeW6S2oqUqFICK9YkhxH04cWszcZdvp1IfnpCQVgoj0mosmDqSusZ2X1+52O4ochApBRHrNycP7M6S4Dw+9uUVvQU1BKgQR6TV+n8OXJ1diaxt5bcNet+NINyoEEelV544uo6Iwhwde36xZQopRIYhIr8ry+/jS5Ere3d7A4i373I4jXWS5HUBEMs8F4yp44PXNPPDGZiYNKXI7TkoLRyJs3tvCyh37WbF9Pyt37qexrZNHLjuOnKzE/p9ehSAivS4ny8fMSYP5zSvrWbatgeqBfd2OlFJ2NbXz4qpaXtuwh5U79tPUHr1SbJ+Aj9HlhZw7ppwsn5Pwx1UhiIgrZlQPYPYbm3nwjc386sJxbsdxXVtnmFfX7ebZFTt5feMeQhEYGczn7NFljKkoZGxFIcP65+FPQhEcoEIQEVfkZfu5+LhB3PPPTdidjZjyArcjuWJ1bSNzl21nfk0d+9s6KSvIZubxlZw/ppxhJXm9mkWFICKu+fyEQfzx/97jwTc387NPjXE7Tq/a3tDK3Ys28sKqWnKyfHxyZCnnjyln0pCipM4CDkWFICKuKczN4vMTBzL7jS1s2N3M8F7+H7EbGlo7ePCNLTy+ZCs+x+HyyZV86fhKCnPdfzl2P4GIZLSLjx3Eo4u3MvvNzdxyTpXbcZKmvTPMX5Zu48E3NrO/tZPzxpZz7cnDKC/McTva+1QIIuKq4rxsZowfwONvb+Wak4YyuKiP25ESbtm2Bn7yQg3v1bdy0rBivjVlOCODqXfMRCemiYjrZk4ajM/n8IfXN7sdJaFC4Qh/+NcmvvLYUsLhCHd99hh++9ljUrIMQDMEEUkBwYIcLj52EA//33vMqB6QFuclbG9o5cfP17B0awNnjy7j+qkjKMhJ7ZdczRBEJCVcdeJQygqy+e+X1hIKe/saR/Nrarnk4cWsqWvilnMMt55blfJlACoEEUkRedl+vnP60djY+/K9qLUjxH++aPnRczUM75/HI5cdy7ljyt2OFbfUrywRyRjTRpUyd0gRdy/ayLRRpRTnZbsdKW4797fxvadWYGsbuerEIVx90tCkXF4imTRDEJGU4TgOPzhjBM0dIe56dYPbceK2YnsDl/9pCVvqW/jlhWO59uRhnisDUCGISIoZXpLHJccO4pnlO1m2rcHtOB9rfk0tX/3LMrKzfDxw8QROOarE7UhHTIUgIinnqpOGpPwB5nAkwq8WrOFHz9UwpryA2ZdM4OjSfLdj9YgKQURSTn52Ft8+7aiUPcDc0hHihr+u4vevrOOCceX87qJqTx3v+CgqBBFJSWeaIJNiB5j3Nre7Hed9dY1tfPXxd3h5zS5uONtw0/RRBPzp8VKa8HcZGWMCwCxgGJAD3GatfabL/kuB64AQMMtae7cxxg/cD5jY9iustesSnU1EvMNxHL5/xtFc8vDb/OaV9fzkbIPjuHug1u5s5LtPLWd/Wyd3fmYsnzqukvr6ZlczJVIyam0msNtaeypwDnBXt/13ANOAk4HrjDHFwKcArLUnAz8GfpmEXCLiMUeV5HP55EqeW1nLo29vdTXLK2t3c83jSwH4wxcncOrR3j14/FGScR7CHOCJLrc7u+1fBvSLbXeAiLX2KWPMs7H9Q4GdScglIh70lU8MZcPuZn799/VU9M3ljJGlvfr4kUiEPy3eym9fWU9VeQG//MxYSgtS5wqliZTwQrDWNgIYYwqJFsNN3e6yHFgMNAFzrbX1se/rNMY8BFwIfC6ex/L7HYqKvHX9dL/f57nMPaUxZ4Zkjvk3F0/ksgff5MfP1zD8yslMrCxKyuN01xEKc8uzK3n8rfc4a0w5v/hsNX2y/e/vT7fn2YlEEv+WLmNMJfAk8Htr7awu26uBvwAnAI3AI0RLYU6X+1QAbwBjrLVNh3qcjo5QxGvrd0VFeWm15hgPjTkzJHvMe5vbufLRpTS1hZh1yYSkXyZ7R0MrN8cuTnf55Eq+dsowfN2OYXj1eQ4GCxcDk7pvT/gxBGNMOTAfuL5rGcTsA1qAFmttCKgFio0xlxljbojdpxkIEz24LCICRD834dcXjiMcifDtucvZ19KRtMdaYOu4OHZxulvPreIbpw7/UBmko4TPEIwxvwG+ANR02Xw/kG+tvc8Ycy1wJdAOrAOuAQLAg0BF7O8/s9Y+/XGPpRmCN2jMmaG3xrz0vX18/YlljKso5K7PVZOdlbj/1za3h7jz5bU8s3wn4wYUcuu5VYeciXj1ef6oGUJSlox6iwrBGzTmzNCbY55fU8uPnqth2qhSbj7LkNdlXf9Irdq5n5ueq2HL3hauOKGSa04aStbHnF/g1ef5owpBVzsVEc+ZXlXGzv1t/PYfG1iytYGvnzKM88eWH9GyTn1LB3OWbGPWG5vpnxfg7s9Xc1wvHbRONSoEEfGky46vZOLgfvzy5XXcOm81c5Zs4z8+eRTHDi6K6/vX1jXx2JKtvLiqlrbOMNNGlfLDaSPp1yeQ3OApTIUgIp41bkBfHrh4AvNr6vifVzfw1ceXccbIUr41ZfhB1/5D4QivrtvN40u28taWfeRk+Th3TBmfnziIER6/MF0iqBBExNMcx+Gs0WWcNqKER956j4fe3MLCNbvI8jn4fQ5+x8HnA7/j0BmO0NQeoqIwh2+dOpxPH1OR0TOC7lQIIpIWcgN+rj5pKBeMq+CvK3bQ0hEmFI4QjkQIhaN/IsDkIUVMGVHqyQ+wSTYVgoiklbLCHK46cajbMTwpPa7ZKiIiPaZCEBERQIUgIiIxKgQREQFUCCIiEqNCEBERQIUgIiIxKgQREQE8fvlroA7Y5HYIERGPGQoEu2/0eiGIiEiCaMlIREQAFYKIiMSoEEREBFAhiIhIjApBREQAFYKIiMSoEEREBNAnpqUUY0wZ8Ly1dpLbWXqDMWYq8GUgD7jVWvuOy5GSxhjzCeCrsZvfttbWuxinV2TS89uVl3+PNUNIEcYYB/gBmXXmdR7RF4zbgekuZ0m2rxAthAeAL7icpbdk0vMLeP/3WDMElxhjvgNMi938F7AH+BNwnVuZkq37mK21txtj8oH/B1zvWrDe4bfWthpjtgNnuB2mN1hr/5pBz+8B1+Lh32NduiJFGGPmArVEXyx+ZK2d43KkpDPGlAA/B26x1m5xO08yGWPuJfrCeAIwxlp7j8uRki6Tnt8DvP57rEJIAmPMCcDPrbWnG2N8wO+B8UAbcLW1du0hvvcRa+3MXoqaMEcyZmPMw0QvsLUbeMpa+0RvZk6UeMZujDkO+BYQAL5qrW10L3HPxTnmtHh+Dzicf+Ne/T3WklGCGWN+AFwGNMU2fQbItdaeZIw5EbgT+PRHfb8X/xEd6ZittV/qtZBJEu/YrbWLgctdCZlghzFmzz+/Bxzuv3Ev/h6DDionwzpgRpfbpwAvAlhrXwc8986DOGTimA/IxLFrzGk6ZhVCgllr/xfo6LKpL7Cvy+2QMSatZmaZOOYDMnHsGjOQpmNWISRfA1DY5bbPWtvpVphekoljPiATx64xp8mYVQjJ90/gXIDYWuO77sbpFZk45gMycewac5qM2fNTHA94EjjTGPMa4ABXuJynN2TimA/IxLFrzGkyZr3tVEREAC0ZiYhIjApBREQAFYKIiMSoEEREBFAhiIhIjApBREQAFYKIiMSoEESOkDHm78aYqkPs39GbeUR6SoUgIiKALl0hEhdjTF/gD0ARUArc32XffwJVQBlQDHzLWrsIyDHG/BkYQvRDYj4HlAN3A7lACfBTa+1TvTUOkUPRDEEkPiOAx6y104Hzge92299srT0DmAn8LratALjRWnsK0A+YSLQ47rTWngl8E/hGb4QXiYdmCCLx2QF8xxgzg+iljwPd9i8EsNauMMZUxLbtsdZu7PL9ecB24CZjzFVA5CA/R8Q1miGIxOd7wL9iH404h+gVLrs6DsAYMw7YGtt2sCtH3go8bK29DHj5ID9HxDWaIYjE56/A3caYS4keD+gEcrrsn2iMeQnIB645xM+ZA/w29g6kLUSPR4ikBF3+WqSHYgeVd1hr73E7i0hPaMlIREQAzRBERCRGMwQREQFUCCIiEqNCEBERQIUgIiIxKgQREQHg/wO1FceO2ksF6QAAAABJRU5ErkJggg==\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = plt.gca()\n",
    "\n",
    "ax.plot(alphas, errors)\n",
    "ax.set_xscale('log')\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('error')\n",
    "plt.axis('tight')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "41"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# index du min des erreurs\n",
    "np.argmin(errors)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "2.8280417253090797"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# recupere l'erreur min\n",
    "errors[np.argmin(errors)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "2329.951810515372"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# recup alpha associé à cet erreur min\n",
    "alphas[np.argmin(errors)]\n",
    "# alphas[35]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# chemin de régularisation\n",
    "ax = plt.gca()\n",
    "ax.plot(alphas, coefs)\n",
    "ax.set_xscale('log')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = plt.gca()\n",
    "\n",
    "ax.plot(alphas, coefs)\n",
    "ax.set_xscale('log')\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('weights')\n",
    "plt.title('Ridge coefficients as a function of the regularization')\n",
    "plt.axis('tight')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "2.8280417253090797"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(errors)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3) Linear Model : LASSO"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "n_alphas = 1000\n",
    "alphas = np.logspace(-5, 5, 50)\n",
    "\n",
    "lasso = linear_model.Lasso()\n",
    "\n",
    "coefs = []\n",
    "errors = []\n",
    "for a in alphas:\n",
    "    lasso.set_params(alpha=a)\n",
    "    lasso.fit(X_train, y_train)\n",
    "    coefs.append(lasso.coef_)\n",
    "    errors.append(np.mean((lasso.predict(X_test) - y_test) ** 2))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% raw\n"
    }
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "n_alphas = 50\n",
    "alphas = np.logspace(-10, 10, n_alphas)\n",
    "lasso = linear_model.Lasso(fit_intercept=False)\n",
    "\n",
    "\"\"\"\n",
    "fit_intercept : bool, default=True\n",
    "Whether to calculate the intercept for this model. If set to False, no intercept will be used in calculations (i.e. data is expected to be centered).\n",
    "\"\"\"\n",
    "\n",
    "coefs = []\n",
    "errors = []\n",
    "for a in alphas:\n",
    "    lasso.set_params(alpha=a)\n",
    "    lasso.fit(X_train, y_train)\n",
    "    coefs.append(lasso.coef_)\n",
    "    errors.append([baseline_error, np.mean((lasso.predict(X_test) - y_test) ** 2)])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% raw\n"
    }
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "# observation du comportement de l'erreur\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.plot(alphas, errors, [10**-5, 10**5], [baseline_error, baseline_error])\n",
    "ax.set_xscale('log')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% raw\n"
    }
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "# recupere l'erreur min\n",
    "errors[np.argmin(errors)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% raw\n"
    }
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "# recup alpha associé à cet erreur min\n",
    "alphas[np.argmin(errors)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% raw\n"
    }
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "# chemin de régularisation\n",
    "ax = plt.gca()\n",
    "ax.plot(alphas, coefs)\n",
    "ax.set_xscale('log')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% raw\n"
    }
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "ax = plt.gca()\n",
    "\n",
    "ax.plot(alphas, coefs)\n",
    "ax.set_xscale('log')\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('weights')\n",
    "plt.axis('tight')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% raw\n"
    }
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.matrix([-0.78768, -1.51760513, 0.74416271, -0.62288928])\n",
    "X = X.T\n",
    "print(X)\n",
    "\n",
    "y = np.matrix([-34.59703199, -30.79543532, 19.31018182, -19.44809959])\n",
    "y = y.T\n",
    "print(y)\n",
    "print(np.linalg.inv(X.T.dot(X)).dot(X.T))\n",
    "beta = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y)\n",
    "beta"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% raw\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4) Linear Model : Elastic Net"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.561e+03, tolerance: 5.245e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.582e+03, tolerance: 5.288e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.594e+03, tolerance: 5.299e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.737e+03, tolerance: 5.600e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.736e+03, tolerance: 5.610e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.561e+03, tolerance: 5.245e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.582e+03, tolerance: 5.288e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.594e+03, tolerance: 5.299e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.737e+03, tolerance: 5.600e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.736e+03, tolerance: 5.610e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.561e+03, tolerance: 5.245e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.582e+03, tolerance: 5.288e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.594e+03, tolerance: 5.299e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.737e+03, tolerance: 5.600e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.736e+03, tolerance: 5.610e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.561e+03, tolerance: 5.245e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.582e+03, tolerance: 5.288e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.594e+03, tolerance: 5.299e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.737e+03, tolerance: 5.600e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.736e+03, tolerance: 5.610e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.617e+01, tolerance: 5.288e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.313e+02, tolerance: 5.299e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.301e+01, tolerance: 5.245e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.617e+01, tolerance: 5.288e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.313e+02, tolerance: 5.299e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.698e+01, tolerance: 5.600e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.301e+01, tolerance: 5.245e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.617e+01, tolerance: 5.288e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.313e+02, tolerance: 5.299e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.698e+01, tolerance: 5.600e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.227e+00, tolerance: 5.610e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.369e+01, tolerance: 5.288e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.116e+01, tolerance: 5.299e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.369e+01, tolerance: 5.288e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.116e+01, tolerance: 5.299e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.302e+00, tolerance: 5.610e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.623e+00, tolerance: 5.288e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.010e+01, tolerance: 5.299e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.623e+00, tolerance: 5.288e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.010e+01, tolerance: 5.299e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.752e-01, tolerance: 5.610e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.083e+01, tolerance: 5.299e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.083e+01, tolerance: 5.299e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.318e+00, tolerance: 5.600e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.046e-01, tolerance: 5.610e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.533e+01, tolerance: 5.299e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.533e+01, tolerance: 5.299e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.050e-01, tolerance: 5.610e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.127e+01, tolerance: 5.299e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.127e+01, tolerance: 5.299e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.785e+00, tolerance: 5.299e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.785e+00, tolerance: 5.299e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.627e+00, tolerance: 5.245e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.451e+00, tolerance: 5.299e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.506e+00, tolerance: 5.299e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.564e+03, tolerance: 5.245e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.585e+03, tolerance: 5.288e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.597e+03, tolerance: 5.299e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.741e+03, tolerance: 5.600e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.740e+03, tolerance: 5.610e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.564e+03, tolerance: 5.245e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.585e+03, tolerance: 5.288e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.597e+03, tolerance: 5.299e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.741e+03, tolerance: 5.600e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.740e+03, tolerance: 5.610e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.564e+03, tolerance: 5.245e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.585e+03, tolerance: 5.288e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.597e+03, tolerance: 5.299e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.741e+03, tolerance: 5.600e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.740e+03, tolerance: 5.610e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.564e+03, tolerance: 5.245e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.585e+03, tolerance: 5.288e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.597e+03, tolerance: 5.299e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.741e+03, tolerance: 5.600e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.740e+03, tolerance: 5.610e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.575e+03, tolerance: 5.245e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.598e+03, tolerance: 5.288e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.609e+03, tolerance: 5.299e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.754e+03, tolerance: 5.600e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.754e+03, tolerance: 5.610e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.575e+03, tolerance: 5.245e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.598e+03, tolerance: 5.288e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.609e+03, tolerance: 5.299e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.754e+03, tolerance: 5.600e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.754e+03, tolerance: 5.610e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.575e+03, tolerance: 5.245e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.598e+03, tolerance: 5.288e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.609e+03, tolerance: 5.299e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.754e+03, tolerance: 5.600e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.754e+03, tolerance: 5.610e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.575e+03, tolerance: 5.245e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.598e+03, tolerance: 5.288e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.609e+03, tolerance: 5.299e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.754e+03, tolerance: 5.600e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.754e+03, tolerance: 5.610e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.597e+03, tolerance: 5.245e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.618e+03, tolerance: 5.288e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.630e+03, tolerance: 5.299e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.776e+03, tolerance: 5.600e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.776e+03, tolerance: 5.610e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.597e+03, tolerance: 5.245e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.618e+03, tolerance: 5.288e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.630e+03, tolerance: 5.299e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.776e+03, tolerance: 5.600e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.776e+03, tolerance: 5.610e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.597e+03, tolerance: 5.245e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.618e+03, tolerance: 5.288e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.630e+03, tolerance: 5.299e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.776e+03, tolerance: 5.600e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.776e+03, tolerance: 5.610e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.597e+03, tolerance: 5.245e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.618e+03, tolerance: 5.288e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.630e+03, tolerance: 5.299e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.776e+03, tolerance: 5.600e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.776e+03, tolerance: 5.610e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.611e+03, tolerance: 5.245e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.632e+03, tolerance: 5.288e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.642e+03, tolerance: 5.299e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.790e+03, tolerance: 5.600e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.791e+03, tolerance: 5.610e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.611e+03, tolerance: 5.245e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.632e+03, tolerance: 5.288e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.642e+03, tolerance: 5.299e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.790e+03, tolerance: 5.600e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.791e+03, tolerance: 5.610e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.611e+03, tolerance: 5.245e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.632e+03, tolerance: 5.288e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.642e+03, tolerance: 5.299e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.790e+03, tolerance: 5.600e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.791e+03, tolerance: 5.610e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.611e+03, tolerance: 5.245e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.632e+03, tolerance: 5.288e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.642e+03, tolerance: 5.299e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.790e+03, tolerance: 5.600e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.791e+03, tolerance: 5.610e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.617e+03, tolerance: 5.245e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.638e+03, tolerance: 5.288e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.648e+03, tolerance: 5.299e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.794e+03, tolerance: 5.600e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.798e+03, tolerance: 5.610e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.617e+03, tolerance: 5.245e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.638e+03, tolerance: 5.288e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.648e+03, tolerance: 5.299e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.794e+03, tolerance: 5.600e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.798e+03, tolerance: 5.610e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.617e+03, tolerance: 5.245e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.638e+03, tolerance: 5.288e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.648e+03, tolerance: 5.299e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.794e+03, tolerance: 5.600e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.798e+03, tolerance: 5.610e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.617e+03, tolerance: 5.245e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.638e+03, tolerance: 5.288e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.648e+03, tolerance: 5.299e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.794e+03, tolerance: 5.600e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.798e+03, tolerance: 5.610e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.619e+03, tolerance: 5.245e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.640e+03, tolerance: 5.288e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.649e+03, tolerance: 5.299e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.795e+03, tolerance: 5.600e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.799e+03, tolerance: 5.610e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.619e+03, tolerance: 5.245e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.640e+03, tolerance: 5.288e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.649e+03, tolerance: 5.299e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.795e+03, tolerance: 5.600e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.799e+03, tolerance: 5.610e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.619e+03, tolerance: 5.245e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.640e+03, tolerance: 5.288e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.649e+03, tolerance: 5.299e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.795e+03, tolerance: 5.600e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.799e+03, tolerance: 5.610e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.619e+03, tolerance: 5.245e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.640e+03, tolerance: 5.288e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.649e+03, tolerance: 5.299e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.795e+03, tolerance: 5.600e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.799e+03, tolerance: 5.610e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.369e+03, tolerance: 6.761e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/plain": "GridSearchCV(cv=5, estimator=ElasticNet(),\n             param_grid={'alpha': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100],\n                         'l1_ratio': array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]),\n                         'tol': [0.1, 0.01, 0.001, 0.0001]},\n             scoring='neg_mean_squared_error')",
      "text/html": "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=ElasticNet(),\n             param_grid={&#x27;alpha&#x27;: [0.0001, 0.001, 0.01, 0.1, 1, 10, 100],\n                         &#x27;l1_ratio&#x27;: array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]),\n                         &#x27;tol&#x27;: [0.1, 0.01, 0.001, 0.0001]},\n             scoring=&#x27;neg_mean_squared_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=ElasticNet(),\n             param_grid={&#x27;alpha&#x27;: [0.0001, 0.001, 0.01, 0.1, 1, 10, 100],\n                         &#x27;l1_ratio&#x27;: array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]),\n                         &#x27;tol&#x27;: [0.1, 0.01, 0.001, 0.0001]},\n             scoring=&#x27;neg_mean_squared_error&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: ElasticNet</label><div class=\"sk-toggleable__content\"><pre>ElasticNet()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ElasticNet</label><div class=\"sk-toggleable__content\"><pre>ElasticNet()</pre></div></div></div></div></div></div></div></div></div></div>"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "#rappel de la fonction de coût du elasticnet\n",
    "#1 / (2 * n_samples) * ||y - Xw||^2_2 + alpha * l1_ratio * ||w||_1 + 0.5 * alpha * (1 - l1_ratio) * ||w||^2_2\n",
    "\n",
    "parameters = {'tol' : [0.1,0.01,0.001,0.0001],\n",
    "              \"alpha\": [0.0001, 0.001, 0.01, 0.1, 1, 10, 100],  #alpha, coef qui multiplie le terme de pénalité)\n",
    "              \"l1_ratio\": np.arange(0.0, 1.0, 0.1)}#L1 ratio , =1 équivaut à un Lasso, 0 à un Ridge\n",
    "\n",
    "\n",
    "elastic_grid = GridSearchCV(estimator = ElasticNet(),\n",
    "                            param_grid = parameters,\n",
    "                            scoring = 'neg_mean_squared_error',\n",
    "                            cv=5,\n",
    "                            verbose=0\n",
    "                            )\n",
    "\n",
    "elastic_grid.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "data": {
      "text/plain": "{'alpha': 1, 'l1_ratio': 0.0, 'tol': 0.1}"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elastic_grid.best_params_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "results = pd.DataFrame({})\n",
    "\n",
    "import math\n",
    "results = results.append(pd.DataFrame({\n",
    "    'Modèle' : ['Elasticnet Regression'],\n",
    "    'Score_RMSE' : [math.sqrt(mean_squared_error(elastic_grid.predict(X_test), y_test))]}),\n",
    "    ignore_index=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2) Ensemble learning methods"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1) Parallelized Implementation : Random Forest"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rfr = RandomForestRegressor(n_estimators=1000) # nb of trees 1000 for the forest"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "data": {
      "text/plain": "      NumberofFloors  PropertyGFATotal  PropertyGFAParking  \\\n1          -0.499734         -0.462226           -0.252566   \n2          -0.314688         -0.468417           -0.252566   \n3           1.905866         -0.106769           -0.252566   \n4          -0.314688         -0.384912           -0.042709   \n5          -0.129642         -0.365813           -0.252566   \n...              ...               ...                 ...   \n3124        0.055404         -0.264528           -0.252566   \n3125       -0.499734         -0.403766           -0.252566   \n3126       -0.314688         -0.344549            0.022846   \n3128        0.055404         -0.404507           -0.073157   \n3129       -0.499734         -0.502552           -0.252566   \n\n      SecondLargestPropertyUseTypeGFA  ThirdLargestPropertyUseTypeGFA  \\\n1                           -0.141522                        0.134019   \n2                           -0.382358                       -0.207072   \n3                           -0.382358                       -0.207072   \n4                           -0.266691                       -0.207072   \n5                           -0.382358                       -0.207072   \n...                               ...                             ...   \n3124                        -0.382358                       -0.207072   \n3125                        -0.006164                       -0.046558   \n3126                         0.006725                        0.871936   \n3128                        -0.141054                       -0.039870   \n3129                        -0.162039                       -0.207072   \n\n      YearBuilt  BuildingType_Campus  BuildingType_Multifamily HR (10+)  \\\n1          1928                  0.0                                0.0   \n2          1925                  0.0                                0.0   \n3          1971                  0.0                                1.0   \n4          2001                  0.0                                0.0   \n5          1996                  0.0                                0.0   \n...         ...                  ...                                ...   \n3124       1925                  0.0                                0.0   \n3125       1927                  0.0                                0.0   \n3126       2001                  0.0                                0.0   \n3128       2001                  0.0                                0.0   \n3129       1911                  0.0                                0.0   \n\n      BuildingType_Multifamily LR (1-4)  BuildingType_Multifamily MR (5-9)  \\\n1                                   0.0                                0.0   \n2                                   1.0                                0.0   \n3                                   0.0                                0.0   \n4                                   1.0                                0.0   \n5                                   0.0                                0.0   \n...                                 ...                                ...   \n3124                                0.0                                1.0   \n3125                                0.0                                0.0   \n3126                                0.0                                0.0   \n3128                                0.0                                0.0   \n3129                                0.0                                0.0   \n\n      ...  Neighborhood_downtown  Neighborhood_east  \\\n1     ...                    0.0                0.0   \n2     ...                    0.0                0.0   \n3     ...                    0.0                0.0   \n4     ...                    0.0                0.0   \n5     ...                    0.0                0.0   \n...   ...                    ...                ...   \n3124  ...                    0.0                1.0   \n3125  ...                    0.0                0.0   \n3126  ...                    0.0                0.0   \n3128  ...                    0.0                0.0   \n3129  ...                    0.0                0.0   \n\n      Neighborhood_greater duwamish  Neighborhood_lake union  \\\n1                               1.0                      0.0   \n2                               1.0                      0.0   \n3                               1.0                      0.0   \n4                               1.0                      0.0   \n5                               0.0                      0.0   \n...                             ...                      ...   \n3124                            0.0                      0.0   \n3125                            0.0                      1.0   \n3126                            0.0                      1.0   \n3128                            0.0                      1.0   \n3129                            0.0                      1.0   \n\n      Neighborhood_magnolia / queen anne  Neighborhood_north  \\\n1                                    0.0                 0.0   \n2                                    0.0                 0.0   \n3                                    0.0                 0.0   \n4                                    0.0                 0.0   \n5                                    0.0                 0.0   \n...                                  ...                 ...   \n3124                                 0.0                 0.0   \n3125                                 0.0                 0.0   \n3126                                 0.0                 0.0   \n3128                                 0.0                 0.0   \n3129                                 0.0                 0.0   \n\n      Neighborhood_northeast  Neighborhood_northwest  Neighborhood_southeast  \\\n1                        0.0                     0.0                     0.0   \n2                        0.0                     0.0                     0.0   \n3                        0.0                     0.0                     0.0   \n4                        0.0                     0.0                     0.0   \n5                        1.0                     0.0                     0.0   \n...                      ...                     ...                     ...   \n3124                     0.0                     0.0                     0.0   \n3125                     0.0                     0.0                     0.0   \n3126                     0.0                     0.0                     0.0   \n3128                     0.0                     0.0                     0.0   \n3129                     0.0                     0.0                     0.0   \n\n      Neighborhood_southwest  \n1                        0.0  \n2                        0.0  \n3                        0.0  \n4                        0.0  \n5                        0.0  \n...                      ...  \n3124                     0.0  \n3125                     0.0  \n3126                     0.0  \n3128                     0.0  \n3129                     0.0  \n\n[2191 rows x 50 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>NumberofFloors</th>\n      <th>PropertyGFATotal</th>\n      <th>PropertyGFAParking</th>\n      <th>SecondLargestPropertyUseTypeGFA</th>\n      <th>ThirdLargestPropertyUseTypeGFA</th>\n      <th>YearBuilt</th>\n      <th>BuildingType_Campus</th>\n      <th>BuildingType_Multifamily HR (10+)</th>\n      <th>BuildingType_Multifamily LR (1-4)</th>\n      <th>BuildingType_Multifamily MR (5-9)</th>\n      <th>...</th>\n      <th>Neighborhood_downtown</th>\n      <th>Neighborhood_east</th>\n      <th>Neighborhood_greater duwamish</th>\n      <th>Neighborhood_lake union</th>\n      <th>Neighborhood_magnolia / queen anne</th>\n      <th>Neighborhood_north</th>\n      <th>Neighborhood_northeast</th>\n      <th>Neighborhood_northwest</th>\n      <th>Neighborhood_southeast</th>\n      <th>Neighborhood_southwest</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>-0.499734</td>\n      <td>-0.462226</td>\n      <td>-0.252566</td>\n      <td>-0.141522</td>\n      <td>0.134019</td>\n      <td>1928</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.314688</td>\n      <td>-0.468417</td>\n      <td>-0.252566</td>\n      <td>-0.382358</td>\n      <td>-0.207072</td>\n      <td>1925</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.905866</td>\n      <td>-0.106769</td>\n      <td>-0.252566</td>\n      <td>-0.382358</td>\n      <td>-0.207072</td>\n      <td>1971</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.314688</td>\n      <td>-0.384912</td>\n      <td>-0.042709</td>\n      <td>-0.266691</td>\n      <td>-0.207072</td>\n      <td>2001</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>-0.129642</td>\n      <td>-0.365813</td>\n      <td>-0.252566</td>\n      <td>-0.382358</td>\n      <td>-0.207072</td>\n      <td>1996</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3124</th>\n      <td>0.055404</td>\n      <td>-0.264528</td>\n      <td>-0.252566</td>\n      <td>-0.382358</td>\n      <td>-0.207072</td>\n      <td>1925</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3125</th>\n      <td>-0.499734</td>\n      <td>-0.403766</td>\n      <td>-0.252566</td>\n      <td>-0.006164</td>\n      <td>-0.046558</td>\n      <td>1927</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3126</th>\n      <td>-0.314688</td>\n      <td>-0.344549</td>\n      <td>0.022846</td>\n      <td>0.006725</td>\n      <td>0.871936</td>\n      <td>2001</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3128</th>\n      <td>0.055404</td>\n      <td>-0.404507</td>\n      <td>-0.073157</td>\n      <td>-0.141054</td>\n      <td>-0.039870</td>\n      <td>2001</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3129</th>\n      <td>-0.499734</td>\n      <td>-0.502552</td>\n      <td>-0.252566</td>\n      <td>-0.162039</td>\n      <td>-0.207072</td>\n      <td>1911</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>2191 rows × 50 columns</p>\n</div>"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "rfr = rfr.fit(X_train.values, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy -0.10 time 0.25s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import timeit\n",
    "\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "pred = rfr.predict(X_test.values)\n",
    "\n",
    "elapsed = timeit.default_timer() - start_time\n",
    "\n",
    "accuracy = rfr.score(X_test.values, y_test)\n",
    "\n",
    "print(\"accuracy {:.2f} time {:.2f}s\".format(accuracy, elapsed))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "(2191, 15)"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "model = SelectFromModel(rfr, prefit=True, threshold=0.01)\n",
    "X_train2 = model.transform(X_train.values)\n",
    "X_train2.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-0.49973446, -0.46222641, -0.25256596, ...,  0.        ,\n         0.        ,  0.        ],\n       [-0.31468828, -0.46841723, -0.25256596, ...,  0.        ,\n         0.        ,  0.        ],\n       [ 1.90586576, -0.1067694 , -0.25256596, ...,  0.        ,\n         0.        ,  0.        ],\n       ...,\n       [-0.31468828, -0.34454889,  0.02284583, ...,  0.        ,\n         0.        ,  0.        ],\n       [ 0.05540406, -0.40450719, -0.07315724, ...,  0.        ,\n         0.        ,  0.        ],\n       [-0.49973446, -0.50255202, -0.25256596, ...,  0.        ,\n         0.        ,  0.        ]])"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "rfr2 = RandomForestRegressor(n_estimators=1000) # nb of trees 1000 for the forest\n",
    "rfr2 = rfr.fit(X_train2, y_train)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² :  -0.1063675003796849\n",
      "MAE : 1.384857045047696\n",
      "RMSE: 1.7696072318255691\n"
     ]
    },
    {
     "data": {
      "text/plain": "'\\nR² :  -0.036410020297567236\\nMAE : 1.3407748367227499\\nRMSE: 1.698681454232116\\n'"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_experiment(rfr)\n",
    "\n",
    "\"\"\"\n",
    "R² :  -0.036410020297567236\n",
    "MAE : 1.3407748367227499\n",
    "RMSE: 1.698681454232116\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² :  -0.10641785322343456\n",
      "MAE : 1.384402771464533\n",
      "RMSE: 1.7696475004264651\n"
     ]
    }
   ],
   "source": [
    "run_experiment(rfr2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "parameters = {\n",
    "    'n_estimators' : [10,50,100,300,500], #nombre d'arbres de décision\n",
    "    'min_samples_leaf' : [1,3,5,10], #nombre de feuilles minimales dans un noeud\n",
    "    'max_features': ['auto', 'sqrt'] #nombre de features observées pour chaque arbre\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "[CV] END max_features=auto, min_samples_leaf=1, n_estimators=10; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=1, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=auto, min_samples_leaf=1, n_estimators=10; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=1, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=auto, min_samples_leaf=1, n_estimators=10; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=1, n_estimators=50; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=1, n_estimators=50; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=1, n_estimators=50; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=1, n_estimators=50; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=1, n_estimators=50; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=1, n_estimators=100; total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=1, n_estimators=100; total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=1, n_estimators=100; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=1, n_estimators=100; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=1, n_estimators=100; total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=1, n_estimators=300; total time=   4.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=1, n_estimators=300; total time=   5.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=1, n_estimators=300; total time=   5.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=1, n_estimators=300; total time=   4.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=1, n_estimators=300; total time=   4.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=1, n_estimators=500; total time=   6.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=1, n_estimators=500; total time=   5.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=1, n_estimators=500; total time=   5.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=1, n_estimators=500; total time=   5.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=1, n_estimators=500; total time=   5.8s\n",
      "[CV] END max_features=auto, min_samples_leaf=3, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=auto, min_samples_leaf=3, n_estimators=10; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=3, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=auto, min_samples_leaf=3, n_estimators=10; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=3, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=auto, min_samples_leaf=3, n_estimators=50; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=3, n_estimators=50; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=3, n_estimators=50; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=3, n_estimators=50; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=3, n_estimators=50; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=3, n_estimators=100; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=3, n_estimators=100; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=3, n_estimators=100; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=3, n_estimators=100; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=3, n_estimators=100; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=3, n_estimators=300; total time=   2.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=3, n_estimators=300; total time=   2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=3, n_estimators=300; total time=   2.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=3, n_estimators=300; total time=   2.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=3, n_estimators=300; total time=   2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=3, n_estimators=500; total time=   4.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=3, n_estimators=500; total time=   4.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=3, n_estimators=500; total time=   4.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=3, n_estimators=500; total time=   3.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=3, n_estimators=500; total time=   4.0s\n",
      "[CV] END max_features=auto, min_samples_leaf=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=auto, min_samples_leaf=5, n_estimators=10; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=auto, min_samples_leaf=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=auto, min_samples_leaf=5, n_estimators=10; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=5, n_estimators=50; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=5, n_estimators=50; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=5, n_estimators=50; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=5, n_estimators=50; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=5, n_estimators=50; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=5, n_estimators=100; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=5, n_estimators=100; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=5, n_estimators=100; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=5, n_estimators=100; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=5, n_estimators=100; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=5, n_estimators=300; total time=   2.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=5, n_estimators=300; total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=5, n_estimators=300; total time=   2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=5, n_estimators=300; total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=5, n_estimators=300; total time=   2.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=5, n_estimators=500; total time=   3.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=5, n_estimators=500; total time=   3.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=5, n_estimators=500; total time=   3.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=5, n_estimators=500; total time=   4.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=5, n_estimators=500; total time=   3.3s\n",
      "[CV] END max_features=auto, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=auto, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=auto, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=auto, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=10, n_estimators=50; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=10, n_estimators=50; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=10, n_estimators=50; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=10, n_estimators=50; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=10, n_estimators=50; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=10, n_estimators=100; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=10, n_estimators=100; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=10, n_estimators=100; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=10, n_estimators=100; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=10, n_estimators=100; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=10, n_estimators=300; total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=10, n_estimators=300; total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=10, n_estimators=300; total time=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=10, n_estimators=300; total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=10, n_estimators=300; total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=10, n_estimators=500; total time=   3.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=10, n_estimators=500; total time=   4.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=10, n_estimators=500; total time=   3.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=10, n_estimators=500; total time=   3.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=10, n_estimators=500; total time=   2.6s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=1, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=1, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=1, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=1, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=1, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=1, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=1, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=1, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=1, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=1, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=1, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=1, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=1, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=1, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=1, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=1, n_estimators=300; total time=   1.5s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=1, n_estimators=300; total time=   1.2s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=1, n_estimators=300; total time=   1.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=1, n_estimators=300; total time=   1.1s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=1, n_estimators=300; total time=   1.1s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=1, n_estimators=500; total time=   2.1s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=1, n_estimators=500; total time=   2.1s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=1, n_estimators=500; total time=   1.9s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=1, n_estimators=500; total time=   1.9s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=1, n_estimators=500; total time=   2.1s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=3, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=3, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=3, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=3, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=3, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=3, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=3, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=3, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=3, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=3, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=3, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=3, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=3, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=3, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=3, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=3, n_estimators=300; total time=   0.7s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=3, n_estimators=300; total time=   0.6s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=3, n_estimators=300; total time=   0.6s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=3, n_estimators=300; total time=   0.6s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=3, n_estimators=300; total time=   0.5s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=3, n_estimators=500; total time=   1.1s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=3, n_estimators=500; total time=   1.2s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=3, n_estimators=500; total time=   1.2s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=3, n_estimators=500; total time=   2.4s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=3, n_estimators=500; total time=   1.5s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=5, n_estimators=300; total time=   1.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=5, n_estimators=300; total time=   0.8s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=5, n_estimators=300; total time=   0.8s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=5, n_estimators=300; total time=   0.7s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=5, n_estimators=300; total time=   0.6s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=5, n_estimators=500; total time=   1.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=5, n_estimators=500; total time=   1.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=5, n_estimators=500; total time=   1.1s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=5, n_estimators=500; total time=   1.3s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=5, n_estimators=500; total time=   1.3s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=10, n_estimators=300; total time=   0.8s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=10, n_estimators=300; total time=   0.9s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=10, n_estimators=300; total time=   0.5s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=10, n_estimators=300; total time=   0.5s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=10, n_estimators=300; total time=   0.5s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=10, n_estimators=500; total time=   1.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=10, n_estimators=500; total time=   1.6s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=10, n_estimators=500; total time=   0.9s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=10, n_estimators=500; total time=   0.9s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=10, n_estimators=500; total time=   1.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": "GridSearchCV(cv=5, estimator=RandomForestRegressor(),\n             param_grid={'max_features': ['auto', 'sqrt'],\n                         'min_samples_leaf': [1, 3, 5, 10],\n                         'n_estimators': [10, 50, 100, 300, 500]},\n             verbose=2)",
      "text/html": "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=RandomForestRegressor(),\n             param_grid={&#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;],\n                         &#x27;min_samples_leaf&#x27;: [1, 3, 5, 10],\n                         &#x27;n_estimators&#x27;: [10, 50, 100, 300, 500]},\n             verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=RandomForestRegressor(),\n             param_grid={&#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;],\n                         &#x27;min_samples_leaf&#x27;: [1, 3, 5, 10],\n                         &#x27;n_estimators&#x27;: [10, 50, 100, 300, 500]},\n             verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfr_search = GridSearchCV(RandomForestRegressor(),\n",
    "                          param_grid = parameters,\n",
    "                          #scoring='mean_squared_error',\n",
    "                          verbose=2,\n",
    "                          cv=5)\n",
    "\n",
    "rfr_search.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "data": {
      "text/plain": "{'max_features': 'sqrt', 'min_samples_leaf': 10, 'n_estimators': 100}"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfr_search.best_params_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "import math\n",
    "results = results.append(pd.DataFrame({\n",
    "    'Modèle' : ['Random Forest Regressor'],\n",
    "    'Score_RMSE' : [math.sqrt(mean_squared_error(rfr_search.predict(X_test), y_test))]}),\n",
    "    ignore_index=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "coefficients = abs(rfr_search.best_estimator_.feature_importances_)\n",
    "liste_coefs_rer = pd.concat((pd.DataFrame(X.columns, columns = ['Variable']),\n",
    "                             pd.DataFrame(coefficients, columns = ['Coefficient'])), axis = 1).sort_values(by='Coefficient', ascending = False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 576x576 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.title('RandomForestRegressor - Importance des 20 premières Features')\n",
    "sns.barplot(y = liste_coefs_rer['Variable'].head(20),\n",
    "            x = liste_coefs_rer['Coefficient'].head(20))\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2) Sequence Tree : XGBoost"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.matrix([-0.78768, -1.51760513, 0.74416271, -0.62288928])\n",
    "X = X.T\n",
    "print(X)\n",
    "\n",
    "y = np.matrix([-34.59703199, -30.79543532, 19.31018182, -19.44809959])\n",
    "y = y.T\n",
    "print(y)\n",
    "print(np.linalg.inv(X.T.dot(X)).dot(X.T))\n",
    "beta = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y)\n",
    "beta"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% raw\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4) Linear Model : Elastic Net"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "#rappel de la fonction de coût du elasticnet\n",
    "#1 / (2 * n_samples) * ||y - Xw||^2_2 + alpha * l1_ratio * ||w||_1 + 0.5 * alpha * (1 - l1_ratio) * ||w||^2_2\n",
    "\n",
    "parameters = {'tol' : [0.1,0.01,0.001,0.0001],\n",
    "              \"alpha\": [0.0001, 0.001, 0.01, 0.1, 1, 10, 100],  #alpha, coef qui multiplie le terme de pénalité)\n",
    "              \"l1_ratio\": np.arange(0.0, 1.0, 0.1)}#L1 ratio , =1 équivaut à un Lasso, 0 à un Ridge\n",
    "\n",
    "\n",
    "elastic_grid = GridSearchCV(estimator = ElasticNet(),\n",
    "                            param_grid = parameters,\n",
    "                            scoring = 'neg_mean_squared_error',\n",
    "                            cv=5,\n",
    "                            verbose=0\n",
    "                            )\n",
    "\n",
    "elastic_grid.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% raw\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2) Ensemble learning methods"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1) Parallelized Implementation : Random Forest"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rfr = RandomForestRegressor(n_estimators=1000) # nb of trees 1000 for the forest"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "data": {
      "text/plain": "      NumberofFloors  PropertyGFATotal  PropertyGFAParking  \\\n1          -0.499734         -0.462226           -0.252566   \n2          -0.314688         -0.468417           -0.252566   \n3           1.905866         -0.106769           -0.252566   \n4          -0.314688         -0.384912           -0.042709   \n5          -0.129642         -0.365813           -0.252566   \n...              ...               ...                 ...   \n3124        0.055404         -0.264528           -0.252566   \n3125       -0.499734         -0.403766           -0.252566   \n3126       -0.314688         -0.344549            0.022846   \n3128        0.055404         -0.404507           -0.073157   \n3129       -0.499734         -0.502552           -0.252566   \n\n      SecondLargestPropertyUseTypeGFA  ThirdLargestPropertyUseTypeGFA  \\\n1                           -0.141522                        0.134019   \n2                           -0.382358                       -0.207072   \n3                           -0.382358                       -0.207072   \n4                           -0.266691                       -0.207072   \n5                           -0.382358                       -0.207072   \n...                               ...                             ...   \n3124                        -0.382358                       -0.207072   \n3125                        -0.006164                       -0.046558   \n3126                         0.006725                        0.871936   \n3128                        -0.141054                       -0.039870   \n3129                        -0.162039                       -0.207072   \n\n      YearBuilt  BuildingType_Campus  BuildingType_Multifamily HR (10+)  \\\n1          1928                  0.0                                0.0   \n2          1925                  0.0                                0.0   \n3          1971                  0.0                                1.0   \n4          2001                  0.0                                0.0   \n5          1996                  0.0                                0.0   \n...         ...                  ...                                ...   \n3124       1925                  0.0                                0.0   \n3125       1927                  0.0                                0.0   \n3126       2001                  0.0                                0.0   \n3128       2001                  0.0                                0.0   \n3129       1911                  0.0                                0.0   \n\n      BuildingType_Multifamily LR (1-4)  BuildingType_Multifamily MR (5-9)  \\\n1                                   0.0                                0.0   \n2                                   1.0                                0.0   \n3                                   0.0                                0.0   \n4                                   1.0                                0.0   \n5                                   0.0                                0.0   \n...                                 ...                                ...   \n3124                                0.0                                1.0   \n3125                                0.0                                0.0   \n3126                                0.0                                0.0   \n3128                                0.0                                0.0   \n3129                                0.0                                0.0   \n\n      ...  Neighborhood_downtown  Neighborhood_east  \\\n1     ...                    0.0                0.0   \n2     ...                    0.0                0.0   \n3     ...                    0.0                0.0   \n4     ...                    0.0                0.0   \n5     ...                    0.0                0.0   \n...   ...                    ...                ...   \n3124  ...                    0.0                1.0   \n3125  ...                    0.0                0.0   \n3126  ...                    0.0                0.0   \n3128  ...                    0.0                0.0   \n3129  ...                    0.0                0.0   \n\n      Neighborhood_greater duwamish  Neighborhood_lake union  \\\n1                               1.0                      0.0   \n2                               1.0                      0.0   \n3                               1.0                      0.0   \n4                               1.0                      0.0   \n5                               0.0                      0.0   \n...                             ...                      ...   \n3124                            0.0                      0.0   \n3125                            0.0                      1.0   \n3126                            0.0                      1.0   \n3128                            0.0                      1.0   \n3129                            0.0                      1.0   \n\n      Neighborhood_magnolia / queen anne  Neighborhood_north  \\\n1                                    0.0                 0.0   \n2                                    0.0                 0.0   \n3                                    0.0                 0.0   \n4                                    0.0                 0.0   \n5                                    0.0                 0.0   \n...                                  ...                 ...   \n3124                                 0.0                 0.0   \n3125                                 0.0                 0.0   \n3126                                 0.0                 0.0   \n3128                                 0.0                 0.0   \n3129                                 0.0                 0.0   \n\n      Neighborhood_northeast  Neighborhood_northwest  Neighborhood_southeast  \\\n1                        0.0                     0.0                     0.0   \n2                        0.0                     0.0                     0.0   \n3                        0.0                     0.0                     0.0   \n4                        0.0                     0.0                     0.0   \n5                        1.0                     0.0                     0.0   \n...                      ...                     ...                     ...   \n3124                     0.0                     0.0                     0.0   \n3125                     0.0                     0.0                     0.0   \n3126                     0.0                     0.0                     0.0   \n3128                     0.0                     0.0                     0.0   \n3129                     0.0                     0.0                     0.0   \n\n      Neighborhood_southwest  \n1                        0.0  \n2                        0.0  \n3                        0.0  \n4                        0.0  \n5                        0.0  \n...                      ...  \n3124                     0.0  \n3125                     0.0  \n3126                     0.0  \n3128                     0.0  \n3129                     0.0  \n\n[2191 rows x 50 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>NumberofFloors</th>\n      <th>PropertyGFATotal</th>\n      <th>PropertyGFAParking</th>\n      <th>SecondLargestPropertyUseTypeGFA</th>\n      <th>ThirdLargestPropertyUseTypeGFA</th>\n      <th>YearBuilt</th>\n      <th>BuildingType_Campus</th>\n      <th>BuildingType_Multifamily HR (10+)</th>\n      <th>BuildingType_Multifamily LR (1-4)</th>\n      <th>BuildingType_Multifamily MR (5-9)</th>\n      <th>...</th>\n      <th>Neighborhood_downtown</th>\n      <th>Neighborhood_east</th>\n      <th>Neighborhood_greater duwamish</th>\n      <th>Neighborhood_lake union</th>\n      <th>Neighborhood_magnolia / queen anne</th>\n      <th>Neighborhood_north</th>\n      <th>Neighborhood_northeast</th>\n      <th>Neighborhood_northwest</th>\n      <th>Neighborhood_southeast</th>\n      <th>Neighborhood_southwest</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>-0.499734</td>\n      <td>-0.462226</td>\n      <td>-0.252566</td>\n      <td>-0.141522</td>\n      <td>0.134019</td>\n      <td>1928</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.314688</td>\n      <td>-0.468417</td>\n      <td>-0.252566</td>\n      <td>-0.382358</td>\n      <td>-0.207072</td>\n      <td>1925</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.905866</td>\n      <td>-0.106769</td>\n      <td>-0.252566</td>\n      <td>-0.382358</td>\n      <td>-0.207072</td>\n      <td>1971</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.314688</td>\n      <td>-0.384912</td>\n      <td>-0.042709</td>\n      <td>-0.266691</td>\n      <td>-0.207072</td>\n      <td>2001</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>-0.129642</td>\n      <td>-0.365813</td>\n      <td>-0.252566</td>\n      <td>-0.382358</td>\n      <td>-0.207072</td>\n      <td>1996</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3124</th>\n      <td>0.055404</td>\n      <td>-0.264528</td>\n      <td>-0.252566</td>\n      <td>-0.382358</td>\n      <td>-0.207072</td>\n      <td>1925</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3125</th>\n      <td>-0.499734</td>\n      <td>-0.403766</td>\n      <td>-0.252566</td>\n      <td>-0.006164</td>\n      <td>-0.046558</td>\n      <td>1927</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3126</th>\n      <td>-0.314688</td>\n      <td>-0.344549</td>\n      <td>0.022846</td>\n      <td>0.006725</td>\n      <td>0.871936</td>\n      <td>2001</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3128</th>\n      <td>0.055404</td>\n      <td>-0.404507</td>\n      <td>-0.073157</td>\n      <td>-0.141054</td>\n      <td>-0.039870</td>\n      <td>2001</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3129</th>\n      <td>-0.499734</td>\n      <td>-0.502552</td>\n      <td>-0.252566</td>\n      <td>-0.162039</td>\n      <td>-0.207072</td>\n      <td>1911</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>2191 rows × 50 columns</p>\n</div>"
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "rfr = rfr.fit(X_train.values, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy -0.11 time 0.23s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import timeit\n",
    "\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "pred = rfr.predict(X_test.values)\n",
    "\n",
    "elapsed = timeit.default_timer() - start_time\n",
    "\n",
    "accuracy = rfr.score(X_test.values, y_test)\n",
    "\n",
    "print(\"accuracy {:.2f} time {:.2f}s\".format(accuracy, elapsed))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "data": {
      "text/plain": "(2191, 15)"
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "model = SelectFromModel(rfr, prefit=True, threshold=0.01)\n",
    "X_train2 = model.transform(X_train.values)\n",
    "X_train2.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-0.49973446, -0.46222641, -0.25256596, ...,  0.        ,\n         0.        ,  0.        ],\n       [-0.31468828, -0.46841723, -0.25256596, ...,  0.        ,\n         0.        ,  0.        ],\n       [ 1.90586576, -0.1067694 , -0.25256596, ...,  0.        ,\n         0.        ,  0.        ],\n       ...,\n       [-0.31468828, -0.34454889,  0.02284583, ...,  0.        ,\n         0.        ,  0.        ],\n       [ 0.05540406, -0.40450719, -0.07315724, ...,  0.        ,\n         0.        ,  0.        ],\n       [-0.49973446, -0.50255202, -0.25256596, ...,  0.        ,\n         0.        ,  0.        ]])"
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "rfr2 = RandomForestRegressor(n_estimators=1000) # nb of trees 1000 for the forest\n",
    "rfr2 = rfr.fit(X_train2, y_train)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "run_experiment(rfr)\n",
    "\n",
    "\"\"\"\n",
    "R² :  -0.036410020297567236\n",
    "MAE : 1.3407748367227499\n",
    "RMSE: 1.698681454232116\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "run_experiment(rfr2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train_tryout = X_train.copy()\n",
    "X_test_tryout = X_test.copy()\n",
    "\n",
    "X_train_tryout = X_train_tryout[X_train_tryout.columns[:6]]\n",
    "\n",
    "X_train_tryout\n",
    "\n",
    "X_test_tryout = X_test_tryout[X_test_tryout.columns[:6]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rfr_try = rfr.fit(X_train_tryout.values, y_train)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "start_time = timeit.default_timer()\n",
    "pred = rfr_try.predict(X_test_tryout.values)\n",
    "elapsed = timeit.default_timer() - start_time\n",
    "\n",
    "accuracy = rfr_try.score(X_test_tryout.values, y_test)\n",
    "print(\"accuracy {:.2f} time {:.2f}s\".format(accuracy, elapsed))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "run_experiment(rfr_try)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2) Sequence Tree : XGBoost"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Export des modèles pour réutilisation ultérieure\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Chargement des modèles\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Comparaison des modèles\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "plt.title('Comparaison des RMSE relatives des modèles (en %)')\n",
    "chart = sns.barplot(x = results['Modèle'],\n",
    "                    y = results['RMSE_%']*100)\n",
    "chart.set_xticklabels(labels = results['Modèle'],\n",
    "                      rotation=45,\n",
    "                      horizontalalignment='right',\n",
    "                      size=12,\n",
    "                      )\n",
    "ax = plt.gca()\n",
    "ax.set_ylim([0, 5])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% raw\n"
    }
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "plt.title('Temps d\\'exécution des algorithmes pour la prédiction \\n(jeu d\\'entrainement) - échelle logarithmique')\n",
    "sns.barplot(x=nom_modeles,\n",
    "            y = [5.32, 640, 2.14, 145])\n",
    "ax = plt.gca()\n",
    "ax.set_yscale('log')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% raw\n"
    }
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "sns.barplot(x = comparaison_score_melt['index'],\n",
    "            y = comparaison_score_melt['score'], hue = comparaison_score_melt['variable'])\n",
    "plt.title('Comparaison des performances des modèles (jeu de test)')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% raw\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### III) Evaluation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Vérification des prédictions\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Intérêt du Energy Star Score\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}